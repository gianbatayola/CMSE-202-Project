{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerprinting Presidential Speeches\n",
    "\n",
    "The goal of this project is to create a model that can predict which president gave a speech, based solely on a transcript of that speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we will import all the modules and functions we need in this notebook. Most of these have been used before in this class, except for `import_ipynb`. This module allows us to import functions from Jupyter notebooks. If any of these modules get an import error, you may need to run `pip install [name]` in your command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are nltk packages required for the code to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TriCityPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\TriCityPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\TriCityPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\TriCityPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TriCityPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we import the functions we wrote in other notebooks that are used here. Some of the functions are imported from notebooks with `functions_only` in the name - these are functions whose original notebooks include code that tests the functions and takes a long time to run (`import_ipynb` imports functions by running the entire notebook containing those functions), so a separate notebook containing only the functions themselves was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from word_frequency.ipynb\n",
      "importing Jupyter notebook from average_named_years.ipynb\n",
      "importing Jupyter notebook from year_from_wars_functions_only.ipynb\n",
      "importing Jupyter notebook from Sentiment_Analysis_functions_only.ipynb\n",
      "importing Jupyter notebook from simple_functions_functions_only.ipynb\n",
      "importing Jupyter notebook from word_pca_functions_only.ipynb\n",
      "importing Jupyter notebook from Confusion_Image.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TriCityPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TriCityPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Function Imports\n",
    "from word_frequency import word_frequency\n",
    "from average_named_years import named_years\n",
    "from year_from_wars_functions_only import year_from_wars\n",
    "from Sentiment_Analysis_functions_only import positivity_score, build_sentiment_model\n",
    "from simple_functions_functions_only import mreplace, sentlen, wordlen, avesylls, SWprop, readlvl, sentcount, wordcount\n",
    "from word_pca_functions_only import PCAphrases\n",
    "from Confusion_Image import confusion_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what each function imported above does (and where you can find more details, such as the function's definition and any code used to test it):\n",
    "\n",
    "`word_frequency` takes in a data frame and a number $n$. The data frame must have a column called \"Transcripts\". It returns a series of the percentage of each transcript that consists of the $n$ most common words in the transcript. It is found in the notebook `word_frequency.ipynb`\n",
    "\n",
    "`named_years` also takes in a data frame with a \"Transcripts\" column. It returns a series of the average year mentioned in each speech, scaled by dividing by 2020. If no years are mentioned in the speech, a NaN is put in that speech's row. It can be found in `average_named_years.ipynb`.\n",
    "\n",
    "`year_from_wars` is similar - it returns an average year based on the wars mentioned in the speech. In this case, it is a scaled version of the start date of all wars mentioned in the speech. It is found in `year_from_wars.ipynb`.\n",
    "\n",
    "`positivity_score`, found in `Sentiment_Analysis.ipynb`, takes in the transcript of a single speech, as well as a classifier, which is generated by `build_sentiment_model`. It returns an estimate of how positive the sentiment expressed in the speech is.\n",
    "\n",
    "The following functions are all found in `simple_functions.ipynb`.\n",
    "- `mreplace` takes in a string of text and two lists of strings (which must be of equal length). It replaces every occurence of a string in the first list with the corresponding string from the second list and returns the result. There is also an optional parameter that allows you to set a maximum number of times for each string to be replaced.\n",
    "- `sentlen` takes in a series of strings and returns a series of the average sentence length of each string.\n",
    "- `wordlen` takes in a series of strings and returns a series of the average word length of each string.\n",
    "- `avesylls` takes in a series of strings and returns a series of the average number of syllables per word for each string.\n",
    "- `SWprop` takes in a series of strings and returns a series of the proportion of stop words in each string.\n",
    "- `readlvl` takes in a series of strings and returns a series of Flesch Reading Ease scores of each string. The Flesch Reading Ease score is a measure of how easy or confusing a text is to read.\n",
    "- `sentcount` takes in a series of strings and returns a series of the number of sentences in each string.\n",
    "- `wordcount` takes in a series of strings and returns a series of the number of words in each string.\n",
    "\n",
    "`PCAphrases` takes in a data frame that includes only a \"Presidents\" and \"Transcripts\" column, as well as a number $n$ (the length of each phrase), and the number of features you want. It creates a list of all $n$-word phrases (also known as $n$-grams) in any of the transcripts, and then finds how many times each phrase appears in each transcript. This creates hundreds of features, which is reduced to the desired number of features via principle component analysis. The output is a data frame of the resulting PCA features. The function can be found in the `word_pca.ipynb` notebook. Because of this function's long run time, we were unable to use it for any phrases with 2 or more words - in other words, we only used it to find PCA features based on the frequency of individual words, rather than the frequency of $n$-grams with $n\\geq2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>Speech Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks about the US Southern Border</td>\n",
       "      <td>President Donald Trump speaks about what he se...</td>\n",
       "      <td>Just a short time ago, I had the honor of pres...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>In his second State of the Union Address, Pres...</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech Declaring a National Emergency</td>\n",
       "      <td>President Donald Trump declares a national eme...</td>\n",
       "      <td>Thank you very much, everybody. Before we begi...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks at the United Nations General Assembly</td>\n",
       "      <td>President Donald Trump speaks to the 74th sess...</td>\n",
       "      <td>Thank you very much. Mr. President, Mr. Secret...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Press Conference</td>\n",
       "      <td>President Donald Trump holds a press conferenc...</td>\n",
       "      <td>Thank you very much. Thank you. Well, thank yo...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     President       Party  \\\n",
       "35  2019-01-19  Donald Trump  Republican   \n",
       "36  2019-02-05  Donald Trump  Republican   \n",
       "37  2019-02-15  Donald Trump  Republican   \n",
       "38  2019-09-24  Donald Trump  Republican   \n",
       "39  2019-09-25  Donald Trump  Republican   \n",
       "\n",
       "                                      Speech Title  \\\n",
       "35            Remarks about the US Southern Border   \n",
       "36                      State of the Union Address   \n",
       "37           Speech Declaring a National Emergency   \n",
       "38  Remarks at the United Nations General Assembly   \n",
       "39                                Press Conference   \n",
       "\n",
       "                                              Summary  \\\n",
       "35  President Donald Trump speaks about what he se...   \n",
       "36  In his second State of the Union Address, Pres...   \n",
       "37  President Donald Trump declares a national eme...   \n",
       "38  President Donald Trump speaks to the 74th sess...   \n",
       "39  President Donald Trump holds a press conferenc...   \n",
       "\n",
       "                                           Transcript  \\\n",
       "35  Just a short time ago, I had the honor of pres...   \n",
       "36  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "37  Thank you very much, everybody. Before we begi...   \n",
       "38  Thank you very much. Mr. President, Mr. Secret...   \n",
       "39  Thank you very much. Thank you. Well, thank yo...   \n",
       "\n",
       "                                                  URL  \n",
       "35  https://millercenter.org/the-presidency/presid...  \n",
       "36  https://millercenter.org/the-presidency/presid...  \n",
       "37  https://millercenter.org/the-presidency/presid...  \n",
       "38  https://millercenter.org/the-presidency/presid...  \n",
       "39  https://millercenter.org/the-presidency/presid...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set variable equal to data\n",
    "orig_data = pd.read_csv(\"archive/presidential_speeches.csv\")\n",
    "\n",
    "# Set variable equal to presidents we will use\n",
    "names = ['George Washington', 'Donald Trump'] \n",
    "\n",
    "# Mask data to only show presidents choosen\n",
    "data = orig_data[orig_data['President'].isin(names)]\n",
    "\n",
    "# Reset index values starting from zero\n",
    "data = data.reset_index(drop = True)\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Features to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the functions imported previously to add numerical features to our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Word Frequency'] = word_frequency(data, n = 10, remove_stopwords = True)\n",
    "data['Named Years'] = named_years(data)\n",
    "data['Years from Wars'] = year_from_wars(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = build_sentiment_model()\n",
    "#Since the positivity_score function only takes in one transcript and returns a single value, we make a list of \n",
    "#this function applied to every value in the series of transcripts.\n",
    "data['Positivity Score'] = [positivity_score(x, classifier) for x in data['Transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentence Length'] = sentlen(data['Transcript'])\n",
    "data['Word Length'] = wordlen(data['Transcript'])\n",
    "data['Syllables per word'] = avesylls(data['Transcript'])\n",
    "data['Stop Word Proportion'] = SWprop(data['Transcript'])\n",
    "data['No. of Words'] = wordcount(data['Transcript'])\n",
    "data['No. of Sentences'] = sentcount(data['Transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Reading Level'] = readlvl(data['Transcript'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell takes a while to run, usually in the range of 5 to 10 minutes, so don't worry if it doesn't finish right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.602673</td>\n",
       "      <td>0.481389</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>-0.149919</td>\n",
       "      <td>-0.118753</td>\n",
       "      <td>0.292454</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>-0.195946</td>\n",
       "      <td>0.293637</td>\n",
       "      <td>-0.322661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.213641</td>\n",
       "      <td>-0.167044</td>\n",
       "      <td>-0.182145</td>\n",
       "      <td>-0.074037</td>\n",
       "      <td>0.209590</td>\n",
       "      <td>0.888286</td>\n",
       "      <td>0.203182</td>\n",
       "      <td>-0.196372</td>\n",
       "      <td>-0.436881</td>\n",
       "      <td>0.321110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.902582</td>\n",
       "      <td>0.265165</td>\n",
       "      <td>0.052168</td>\n",
       "      <td>-0.086841</td>\n",
       "      <td>-0.036712</td>\n",
       "      <td>0.414887</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>-0.105305</td>\n",
       "      <td>-0.260012</td>\n",
       "      <td>-0.164483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.544502</td>\n",
       "      <td>0.540240</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.201296</td>\n",
       "      <td>-0.107202</td>\n",
       "      <td>-0.084313</td>\n",
       "      <td>0.159097</td>\n",
       "      <td>0.390601</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.603059</td>\n",
       "      <td>0.196260</td>\n",
       "      <td>0.540785</td>\n",
       "      <td>0.976761</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>-0.384000</td>\n",
       "      <td>-0.083146</td>\n",
       "      <td>-0.215440</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-1.442258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.602673  0.481389  0.222224 -0.149919 -0.118753  0.292454  0.012771   \n",
       "1 -1.213641 -0.167044 -0.182145 -0.074037  0.209590  0.888286  0.203182   \n",
       "2 -0.902582  0.265165  0.052168 -0.086841 -0.036712  0.414887  0.130578   \n",
       "3 -0.544502  0.540240  0.166418 -0.201296 -0.107202 -0.084313  0.159097   \n",
       "4 -0.603059  0.196260  0.540785  0.976761  0.260800 -0.384000 -0.083146   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.195946  0.293637 -0.322661  \n",
       "1 -0.196372 -0.436881  0.321110  \n",
       "2 -0.105305 -0.260012 -0.164483  \n",
       "3  0.390601 -0.012455 -0.408206  \n",
       "4 -0.215440  0.003518 -1.442258  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_PCA = data[['President', 'Transcript']] #PCA for single-word phrases (i.e. individual words)\n",
    "PCAfeatures = PCAphrases(data_PCA, n = 1, numfeatures = 10)\n",
    "\n",
    "PCAfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending the PCA features to the original data frame\n",
    "for i in range(10):\n",
    "    data[f'Word PCA {i}'] = PCAfeatures[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have added all of the features to the data frame, this is what we are left with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>Speech Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>URL</th>\n",
       "      <th>Word Frequency</th>\n",
       "      <th>Named Years</th>\n",
       "      <th>Years from Wars</th>\n",
       "      <th>...</th>\n",
       "      <th>Word PCA 0</th>\n",
       "      <th>Word PCA 1</th>\n",
       "      <th>Word PCA 2</th>\n",
       "      <th>Word PCA 3</th>\n",
       "      <th>Word PCA 4</th>\n",
       "      <th>Word PCA 5</th>\n",
       "      <th>Word PCA 6</th>\n",
       "      <th>Word PCA 7</th>\n",
       "      <th>Word PCA 8</th>\n",
       "      <th>Word PCA 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1789-04-30</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Inaugural Address</td>\n",
       "      <td>Washington calls on Congress to avoid local an...</td>\n",
       "      <td>Fellow Citizens of the Senate and the House of...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.090491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602673</td>\n",
       "      <td>0.481389</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>-0.149919</td>\n",
       "      <td>-0.118753</td>\n",
       "      <td>0.292454</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>-0.195946</td>\n",
       "      <td>0.293637</td>\n",
       "      <td>-0.322661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789-10-03</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Thanksgiving Proclamation</td>\n",
       "      <td>At the request of Congress, Washington establi...</td>\n",
       "      <td>Whereas it is the duty of all Nations to ackno...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.213641</td>\n",
       "      <td>-0.167044</td>\n",
       "      <td>-0.182145</td>\n",
       "      <td>-0.074037</td>\n",
       "      <td>0.209590</td>\n",
       "      <td>0.888286</td>\n",
       "      <td>0.203182</td>\n",
       "      <td>-0.196372</td>\n",
       "      <td>-0.436881</td>\n",
       "      <td>0.321110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790-01-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Annual Message to Congress</td>\n",
       "      <td>In a wide ranging speech, President Washington...</td>\n",
       "      <td>Fellow Citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902582</td>\n",
       "      <td>0.265165</td>\n",
       "      <td>0.052168</td>\n",
       "      <td>-0.086841</td>\n",
       "      <td>-0.036712</td>\n",
       "      <td>0.414887</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>-0.105305</td>\n",
       "      <td>-0.260012</td>\n",
       "      <td>-0.164483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1790-12-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Second Annual Message to Congress</td>\n",
       "      <td>Washington focuses on commerce in his second a...</td>\n",
       "      <td>Fellow citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.087025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544502</td>\n",
       "      <td>0.540240</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.201296</td>\n",
       "      <td>-0.107202</td>\n",
       "      <td>-0.084313</td>\n",
       "      <td>0.159097</td>\n",
       "      <td>0.390601</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1790-12-29</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Talk to the Chiefs and Counselors of the Senec...</td>\n",
       "      <td>The President reassures the Seneca Nation that...</td>\n",
       "      <td>I the President of the United States, by my ow...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.187107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.603059</td>\n",
       "      <td>0.196260</td>\n",
       "      <td>0.540785</td>\n",
       "      <td>0.976761</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>-0.384000</td>\n",
       "      <td>-0.083146</td>\n",
       "      <td>-0.215440</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-1.442258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1791-10-25</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Third Annual Message to Congress</td>\n",
       "      <td>Washington praises the success of the new bank...</td>\n",
       "      <td>I meet you, upon the present occasion, with th...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.101808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221484</td>\n",
       "      <td>1.346507</td>\n",
       "      <td>0.405504</td>\n",
       "      <td>0.405072</td>\n",
       "      <td>-0.249228</td>\n",
       "      <td>-1.342746</td>\n",
       "      <td>0.347795</td>\n",
       "      <td>0.551307</td>\n",
       "      <td>0.964376</td>\n",
       "      <td>-0.420548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1792-04-05</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Veto Message on Congressional Redistricting</td>\n",
       "      <td>President Washington returns a congressional r...</td>\n",
       "      <td>Gentlemen of the House of Representatives: I h...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.420890</td>\n",
       "      <td>-0.066899</td>\n",
       "      <td>-0.116238</td>\n",
       "      <td>-0.173991</td>\n",
       "      <td>0.129888</td>\n",
       "      <td>0.398741</td>\n",
       "      <td>-0.048008</td>\n",
       "      <td>-0.387403</td>\n",
       "      <td>-0.213353</td>\n",
       "      <td>-0.145249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1792-11-06</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Fourth Annual Message to Congress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fellow Citizens of the Senate, and of the Hous...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.079670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>1.197036</td>\n",
       "      <td>0.340118</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>-0.163484</td>\n",
       "      <td>-0.997563</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.330827</td>\n",
       "      <td>0.809046</td>\n",
       "      <td>-0.361696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1792-12-12</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation Against Crimes Against the Cherok...</td>\n",
       "      <td>Offering a reward for the capture of American ...</td>\n",
       "      <td>Whereas I have received authentic information,...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.402423</td>\n",
       "      <td>-0.092744</td>\n",
       "      <td>-0.111781</td>\n",
       "      <td>-0.153797</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.491491</td>\n",
       "      <td>-0.054533</td>\n",
       "      <td>-0.314530</td>\n",
       "      <td>-0.181659</td>\n",
       "      <td>0.015971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1793-03-04</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Second Inaugural Address</td>\n",
       "      <td>In a simple, brief speech, Washington expresse...</td>\n",
       "      <td>Fellow Citizens: I am again called upon by the...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447830</td>\n",
       "      <td>-0.072192</td>\n",
       "      <td>-0.072251</td>\n",
       "      <td>-0.262555</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>0.473331</td>\n",
       "      <td>-0.120551</td>\n",
       "      <td>-0.317832</td>\n",
       "      <td>-0.194689</td>\n",
       "      <td>-0.133141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1793-04-22</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation of Neutrality</td>\n",
       "      <td>Washington declares United States neutrality i...</td>\n",
       "      <td>Whereas it appears that a state of war exists ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.363897</td>\n",
       "      <td>-0.037849</td>\n",
       "      <td>-0.093930</td>\n",
       "      <td>-0.128423</td>\n",
       "      <td>0.187971</td>\n",
       "      <td>0.445611</td>\n",
       "      <td>-0.063824</td>\n",
       "      <td>-0.400134</td>\n",
       "      <td>-0.258049</td>\n",
       "      <td>-0.012972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1793-12-03</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Fifth Annual Message to Congress</td>\n",
       "      <td>Devoting much of his message to foreign affair...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.096413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284045</td>\n",
       "      <td>0.926447</td>\n",
       "      <td>0.212986</td>\n",
       "      <td>-0.257947</td>\n",
       "      <td>-0.191511</td>\n",
       "      <td>-0.858323</td>\n",
       "      <td>-0.207462</td>\n",
       "      <td>0.311487</td>\n",
       "      <td>-0.315844</td>\n",
       "      <td>-0.122620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1794-08-07</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation against Opposition to Execution o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whereas combinations to defeat the execution o...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.156894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.536063</td>\n",
       "      <td>0.753197</td>\n",
       "      <td>0.097249</td>\n",
       "      <td>0.283388</td>\n",
       "      <td>-0.012478</td>\n",
       "      <td>-0.352915</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>-1.414140</td>\n",
       "      <td>-0.198859</td>\n",
       "      <td>1.009537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1794-09-25</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation of Militia Service</td>\n",
       "      <td>Washington calls on the militias of other stat...</td>\n",
       "      <td>Whereas, from a hope that the combinations aga...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.133758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.103667</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>-0.093900</td>\n",
       "      <td>-0.022543</td>\n",
       "      <td>0.191394</td>\n",
       "      <td>0.317326</td>\n",
       "      <td>-0.119859</td>\n",
       "      <td>-0.636200</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.137426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1794-11-19</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Sixth Annual Message to Congress</td>\n",
       "      <td>The President outlines his response to the Whi...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.091648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612290</td>\n",
       "      <td>1.531057</td>\n",
       "      <td>0.396976</td>\n",
       "      <td>-0.051058</td>\n",
       "      <td>-0.467224</td>\n",
       "      <td>-1.437298</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>-1.106374</td>\n",
       "      <td>-0.482157</td>\n",
       "      <td>2.197091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1795-07-10</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation of Pardons in Western Pennsylvania</td>\n",
       "      <td>Washington issues a pardon to those accused of...</td>\n",
       "      <td>Whereas the commissioners appointed by the Pre...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.263682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.291943</td>\n",
       "      <td>0.041735</td>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.053547</td>\n",
       "      <td>0.124517</td>\n",
       "      <td>0.281384</td>\n",
       "      <td>-0.132887</td>\n",
       "      <td>-0.491463</td>\n",
       "      <td>-0.040964</td>\n",
       "      <td>-0.096747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1795-12-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Seventh Annual Message to Congress</td>\n",
       "      <td>Washington's 1795 speech is imbued with a sens...</td>\n",
       "      <td>I trust I do not deceive myself when I indulge...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.070740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117104</td>\n",
       "      <td>0.786382</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>-0.351968</td>\n",
       "      <td>-0.641085</td>\n",
       "      <td>-0.570803</td>\n",
       "      <td>0.303837</td>\n",
       "      <td>1.531395</td>\n",
       "      <td>-0.166181</td>\n",
       "      <td>-0.220151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1796-03-30</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Message to the House of Representatives, Decli...</td>\n",
       "      <td>In 1796, the House and the Senate were battlin...</td>\n",
       "      <td>Gentlemen of the House of Representatives: Wit...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.164530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715615</td>\n",
       "      <td>0.503754</td>\n",
       "      <td>0.083713</td>\n",
       "      <td>-0.088134</td>\n",
       "      <td>-0.017218</td>\n",
       "      <td>-0.457877</td>\n",
       "      <td>-0.308880</td>\n",
       "      <td>-0.321505</td>\n",
       "      <td>-0.035268</td>\n",
       "      <td>-0.216945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1796-08-29</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Talk to the Cherokee Nation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beloved Cherokees, Many years have passed sinc...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567416</td>\n",
       "      <td>-0.151446</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.334188</td>\n",
       "      <td>0.122242</td>\n",
       "      <td>0.903933</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>-0.514979</td>\n",
       "      <td>0.135584</td>\n",
       "      <td>-0.074483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1796-09-19</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Farewell Address</td>\n",
       "      <td>In one of the most famous addresses in America...</td>\n",
       "      <td>The period for a new election of a citizen to ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.080164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.523043</td>\n",
       "      <td>2.137527</td>\n",
       "      <td>1.499401</td>\n",
       "      <td>-1.042733</td>\n",
       "      <td>0.617589</td>\n",
       "      <td>3.425763</td>\n",
       "      <td>0.121435</td>\n",
       "      <td>-0.455202</td>\n",
       "      <td>-0.256009</td>\n",
       "      <td>-0.429088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1796-12-07</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Eighth Annual Message to Congress</td>\n",
       "      <td>Making his last public appearance as President...</td>\n",
       "      <td>Fellow Citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584515</td>\n",
       "      <td>1.420371</td>\n",
       "      <td>0.178036</td>\n",
       "      <td>0.035579</td>\n",
       "      <td>-0.351023</td>\n",
       "      <td>-0.965372</td>\n",
       "      <td>-0.204024</td>\n",
       "      <td>0.805118</td>\n",
       "      <td>0.572409</td>\n",
       "      <td>0.155616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Inaugural Address</td>\n",
       "      <td>Donald J. Trump was inaugurated on January 20,...</td>\n",
       "      <td>Chief Justice Roberts, President Carter, Presi...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.141643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706742</td>\n",
       "      <td>-0.454865</td>\n",
       "      <td>-0.660413</td>\n",
       "      <td>-0.043599</td>\n",
       "      <td>-0.314543</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>0.314407</td>\n",
       "      <td>1.246656</td>\n",
       "      <td>-1.250291</td>\n",
       "      <td>-0.213077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address to Joint Session of Congress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.089457</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036076</td>\n",
       "      <td>-0.649739</td>\n",
       "      <td>-1.499224</td>\n",
       "      <td>-0.641936</td>\n",
       "      <td>-1.784353</td>\n",
       "      <td>0.218131</td>\n",
       "      <td>0.177854</td>\n",
       "      <td>3.133021</td>\n",
       "      <td>-1.627366</td>\n",
       "      <td>0.776127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech at the Unleashing American Energy Event</td>\n",
       "      <td>President Donald Trump talks about his adminis...</td>\n",
       "      <td>Thank you, everybody. Thank you very much. How...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.141720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294973</td>\n",
       "      <td>-0.829687</td>\n",
       "      <td>0.482819</td>\n",
       "      <td>-0.623056</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>-0.155973</td>\n",
       "      <td>-0.356286</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>-0.903432</td>\n",
       "      <td>1.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech at the Boy Scout Jamboree</td>\n",
       "      <td>President Trump addresses the Boy Scout Jambor...</td>\n",
       "      <td>TRUMP: Thank you, everybody. Thank you very mu...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.160517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562729</td>\n",
       "      <td>-1.761190</td>\n",
       "      <td>2.919205</td>\n",
       "      <td>3.191327</td>\n",
       "      <td>-2.091153</td>\n",
       "      <td>0.472647</td>\n",
       "      <td>-0.190002</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>-0.354417</td>\n",
       "      <td>-0.102733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address to the United Nations General Assembly</td>\n",
       "      <td>President Trump addresses the 72nd session of ...</td>\n",
       "      <td>Mr. Secretary General, Mr. President, world le...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.128937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977588</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370246</td>\n",
       "      <td>0.048445</td>\n",
       "      <td>-1.636938</td>\n",
       "      <td>2.357328</td>\n",
       "      <td>2.551341</td>\n",
       "      <td>-0.600974</td>\n",
       "      <td>-0.322088</td>\n",
       "      <td>-0.399373</td>\n",
       "      <td>-1.821331</td>\n",
       "      <td>0.232609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks on National Security Strategy</td>\n",
       "      <td>President Donald Trump addresses the issue of ...</td>\n",
       "      <td>Thank you very much. Thank you. Please. I want...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.978702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212836</td>\n",
       "      <td>-0.938793</td>\n",
       "      <td>-1.104370</td>\n",
       "      <td>-0.144477</td>\n",
       "      <td>-0.190479</td>\n",
       "      <td>0.313582</td>\n",
       "      <td>0.343761</td>\n",
       "      <td>1.026754</td>\n",
       "      <td>-0.475595</td>\n",
       "      <td>0.078614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address at the World Economic Forum</td>\n",
       "      <td>In Davos, Switzerland, President Trump address...</td>\n",
       "      <td>Thank you, Klaus, very much. It's a privilege ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.099658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355073</td>\n",
       "      <td>-1.164612</td>\n",
       "      <td>-0.083866</td>\n",
       "      <td>-0.079907</td>\n",
       "      <td>0.605903</td>\n",
       "      <td>0.662464</td>\n",
       "      <td>-1.638339</td>\n",
       "      <td>0.337702</td>\n",
       "      <td>3.369281</td>\n",
       "      <td>2.914420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>In the 2018 State of the Union Address, Presid...</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.994059</td>\n",
       "      <td>0.981179</td>\n",
       "      <td>...</td>\n",
       "      <td>1.149949</td>\n",
       "      <td>-1.035773</td>\n",
       "      <td>-1.500794</td>\n",
       "      <td>-0.552592</td>\n",
       "      <td>-1.605261</td>\n",
       "      <td>0.468818</td>\n",
       "      <td>1.106263</td>\n",
       "      <td>-2.345172</td>\n",
       "      <td>-1.065402</td>\n",
       "      <td>1.079229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks at the House and Senate Republican Mem...</td>\n",
       "      <td>President Trump addresses the Republican membe...</td>\n",
       "      <td>Thank you, Paul and Mitch, for the introductio...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.114221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.317972</td>\n",
       "      <td>-2.297750</td>\n",
       "      <td>0.849963</td>\n",
       "      <td>-1.859532</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>-1.068846</td>\n",
       "      <td>-1.361623</td>\n",
       "      <td>-0.471691</td>\n",
       "      <td>0.166442</td>\n",
       "      <td>1.826226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Statement on the School Shooting in Parkland, ...</td>\n",
       "      <td>President Trump makes a statement about the sc...</td>\n",
       "      <td>My fellow Americans, today I speak to a nation...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.160254</td>\n",
       "      <td>-0.445237</td>\n",
       "      <td>-0.169965</td>\n",
       "      <td>-0.191840</td>\n",
       "      <td>0.059832</td>\n",
       "      <td>1.069719</td>\n",
       "      <td>0.246031</td>\n",
       "      <td>-0.203168</td>\n",
       "      <td>-0.129385</td>\n",
       "      <td>-0.338684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks at the Conservative Political Action C...</td>\n",
       "      <td>President Trump addresses the Conservative Pol...</td>\n",
       "      <td>Thank you very much. Thank you everybody. Than...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.119075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968301</td>\n",
       "      <td>...</td>\n",
       "      <td>2.701455</td>\n",
       "      <td>-3.643289</td>\n",
       "      <td>2.929717</td>\n",
       "      <td>-2.635601</td>\n",
       "      <td>1.290117</td>\n",
       "      <td>-2.519264</td>\n",
       "      <td>-3.089910</td>\n",
       "      <td>-0.709101</td>\n",
       "      <td>-0.371139</td>\n",
       "      <td>0.775122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks on Combating the Opioid Crisis</td>\n",
       "      <td>President Trump speaks in New Hampshire about ...</td>\n",
       "      <td>Thank you to our First Lady, Melania, who has ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.141314</td>\n",
       "      <td>0.999257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645473</td>\n",
       "      <td>-1.668165</td>\n",
       "      <td>1.229262</td>\n",
       "      <td>-0.950613</td>\n",
       "      <td>1.747661</td>\n",
       "      <td>-1.005997</td>\n",
       "      <td>4.097099</td>\n",
       "      <td>0.253958</td>\n",
       "      <td>0.751260</td>\n",
       "      <td>0.170571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech at the Veterans of Foreign Wars Nationa...</td>\n",
       "      <td>President Trump addresses American veterans fr...</td>\n",
       "      <td>Thank you, Lee. Thank you, Lee. Thank you. And...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.103634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088831</td>\n",
       "      <td>-1.883187</td>\n",
       "      <td>1.495723</td>\n",
       "      <td>-2.376744</td>\n",
       "      <td>1.093570</td>\n",
       "      <td>-1.445323</td>\n",
       "      <td>-2.673176</td>\n",
       "      <td>-0.482940</td>\n",
       "      <td>-1.116234</td>\n",
       "      <td>-1.232997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address at the 73rd Session of the United Nati...</td>\n",
       "      <td>President Donald Trump addresses the General A...</td>\n",
       "      <td>Madam President, Mr. Secretary-General, world ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.113730</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.978950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530063</td>\n",
       "      <td>-0.432077</td>\n",
       "      <td>-1.353240</td>\n",
       "      <td>1.149851</td>\n",
       "      <td>1.317329</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.492235</td>\n",
       "      <td>0.272894</td>\n",
       "      <td>0.226301</td>\n",
       "      <td>-0.166533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks about the US Southern Border</td>\n",
       "      <td>President Donald Trump speaks about what he se...</td>\n",
       "      <td>Just a short time ago, I had the honor of pres...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.121803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.791974</td>\n",
       "      <td>-0.497804</td>\n",
       "      <td>-0.486455</td>\n",
       "      <td>-0.780311</td>\n",
       "      <td>-0.253916</td>\n",
       "      <td>1.103095</td>\n",
       "      <td>-0.053177</td>\n",
       "      <td>0.582886</td>\n",
       "      <td>0.081854</td>\n",
       "      <td>-0.401975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>In his second State of the Union Address, Pres...</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.089081</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.982665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.225100</td>\n",
       "      <td>-0.559258</td>\n",
       "      <td>-1.738326</td>\n",
       "      <td>-0.418414</td>\n",
       "      <td>-1.955465</td>\n",
       "      <td>-0.738919</td>\n",
       "      <td>-0.029820</td>\n",
       "      <td>-1.649664</td>\n",
       "      <td>1.813444</td>\n",
       "      <td>-2.135830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech Declaring a National Emergency</td>\n",
       "      <td>President Donald Trump declares a national eme...</td>\n",
       "      <td>Thank you very much, everybody. Before we begi...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>0.978713</td>\n",
       "      <td>0.967476</td>\n",
       "      <td>...</td>\n",
       "      <td>2.442493</td>\n",
       "      <td>-2.518877</td>\n",
       "      <td>3.527798</td>\n",
       "      <td>-2.766293</td>\n",
       "      <td>0.678564</td>\n",
       "      <td>-3.621157</td>\n",
       "      <td>-4.068689</td>\n",
       "      <td>1.308829</td>\n",
       "      <td>2.759447</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks at the United Nations General Assembly</td>\n",
       "      <td>President Donald Trump speaks to the 74th sess...</td>\n",
       "      <td>Thank you very much. Mr. President, Mr. Secret...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.107126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567791</td>\n",
       "      <td>-0.402856</td>\n",
       "      <td>-1.003847</td>\n",
       "      <td>0.913858</td>\n",
       "      <td>0.792552</td>\n",
       "      <td>0.973236</td>\n",
       "      <td>-0.064205</td>\n",
       "      <td>1.112880</td>\n",
       "      <td>1.283768</td>\n",
       "      <td>-1.506140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Press Conference</td>\n",
       "      <td>President Donald Trump holds a press conferenc...</td>\n",
       "      <td>Thank you very much. Thank you. Well, thank yo...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.095827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.548871</td>\n",
       "      <td>-1.845280</td>\n",
       "      <td>2.493448</td>\n",
       "      <td>-1.006538</td>\n",
       "      <td>1.079595</td>\n",
       "      <td>-1.776464</td>\n",
       "      <td>-2.442889</td>\n",
       "      <td>0.348755</td>\n",
       "      <td>0.893941</td>\n",
       "      <td>1.277160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          President         Party  \\\n",
       "0   1789-04-30  George Washington  Unaffiliated   \n",
       "1   1789-10-03  George Washington  Unaffiliated   \n",
       "2   1790-01-08  George Washington  Unaffiliated   \n",
       "3   1790-12-08  George Washington  Unaffiliated   \n",
       "4   1790-12-29  George Washington  Unaffiliated   \n",
       "5   1791-10-25  George Washington  Unaffiliated   \n",
       "6   1792-04-05  George Washington  Unaffiliated   \n",
       "7   1792-11-06  George Washington  Unaffiliated   \n",
       "8   1792-12-12  George Washington  Unaffiliated   \n",
       "9   1793-03-04  George Washington  Unaffiliated   \n",
       "10  1793-04-22  George Washington  Unaffiliated   \n",
       "11  1793-12-03  George Washington  Unaffiliated   \n",
       "12  1794-08-07  George Washington  Unaffiliated   \n",
       "13  1794-09-25  George Washington  Unaffiliated   \n",
       "14  1794-11-19  George Washington  Unaffiliated   \n",
       "15  1795-07-10  George Washington  Unaffiliated   \n",
       "16  1795-12-08  George Washington  Unaffiliated   \n",
       "17  1796-03-30  George Washington  Unaffiliated   \n",
       "18  1796-08-29  George Washington  Unaffiliated   \n",
       "19  1796-09-19  George Washington  Unaffiliated   \n",
       "20  1796-12-07  George Washington  Unaffiliated   \n",
       "21  2017-01-20       Donald Trump    Republican   \n",
       "22  2017-02-28       Donald Trump    Republican   \n",
       "23  2017-06-29       Donald Trump    Republican   \n",
       "24  2017-07-24       Donald Trump    Republican   \n",
       "25  2017-09-19       Donald Trump    Republican   \n",
       "26  2017-12-18       Donald Trump    Republican   \n",
       "27  2018-01-26       Donald Trump    Republican   \n",
       "28  2018-01-30       Donald Trump    Republican   \n",
       "29  2018-02-01       Donald Trump    Republican   \n",
       "30  2018-02-15       Donald Trump    Republican   \n",
       "31  2018-02-23       Donald Trump    Republican   \n",
       "32  2018-03-19       Donald Trump    Republican   \n",
       "33  2018-07-24       Donald Trump    Republican   \n",
       "34  2018-09-25       Donald Trump    Republican   \n",
       "35  2019-01-19       Donald Trump    Republican   \n",
       "36  2019-02-05       Donald Trump    Republican   \n",
       "37  2019-02-15       Donald Trump    Republican   \n",
       "38  2019-09-24       Donald Trump    Republican   \n",
       "39  2019-09-25       Donald Trump    Republican   \n",
       "\n",
       "                                         Speech Title  \\\n",
       "0                             First Inaugural Address   \n",
       "1                           Thanksgiving Proclamation   \n",
       "2                    First Annual Message to Congress   \n",
       "3                   Second Annual Message to Congress   \n",
       "4   Talk to the Chiefs and Counselors of the Senec...   \n",
       "5                    Third Annual Message to Congress   \n",
       "6         Veto Message on Congressional Redistricting   \n",
       "7                   Fourth Annual Message to Congress   \n",
       "8   Proclamation Against Crimes Against the Cherok...   \n",
       "9                            Second Inaugural Address   \n",
       "10                         Proclamation of Neutrality   \n",
       "11                   Fifth Annual Message to Congress   \n",
       "12  Proclamation against Opposition to Execution o...   \n",
       "13                    Proclamation of Militia Service   \n",
       "14                   Sixth Annual Message to Congress   \n",
       "15    Proclamation of Pardons in Western Pennsylvania   \n",
       "16                 Seventh Annual Message to Congress   \n",
       "17  Message to the House of Representatives, Decli...   \n",
       "18                        Talk to the Cherokee Nation   \n",
       "19                                   Farewell Address   \n",
       "20                  Eighth Annual Message to Congress   \n",
       "21                                  Inaugural Address   \n",
       "22               Address to Joint Session of Congress   \n",
       "23     Speech at the Unleashing American Energy Event   \n",
       "24                   Speech at the Boy Scout Jamboree   \n",
       "25     Address to the United Nations General Assembly   \n",
       "26              Remarks on National Security Strategy   \n",
       "27                Address at the World Economic Forum   \n",
       "28                         State of the Union Address   \n",
       "29  Remarks at the House and Senate Republican Mem...   \n",
       "30  Statement on the School Shooting in Parkland, ...   \n",
       "31  Remarks at the Conservative Political Action C...   \n",
       "32             Remarks on Combating the Opioid Crisis   \n",
       "33  Speech at the Veterans of Foreign Wars Nationa...   \n",
       "34  Address at the 73rd Session of the United Nati...   \n",
       "35               Remarks about the US Southern Border   \n",
       "36                         State of the Union Address   \n",
       "37              Speech Declaring a National Emergency   \n",
       "38     Remarks at the United Nations General Assembly   \n",
       "39                                   Press Conference   \n",
       "\n",
       "                                              Summary  \\\n",
       "0   Washington calls on Congress to avoid local an...   \n",
       "1   At the request of Congress, Washington establi...   \n",
       "2   In a wide ranging speech, President Washington...   \n",
       "3   Washington focuses on commerce in his second a...   \n",
       "4   The President reassures the Seneca Nation that...   \n",
       "5   Washington praises the success of the new bank...   \n",
       "6   President Washington returns a congressional r...   \n",
       "7                                                 NaN   \n",
       "8   Offering a reward for the capture of American ...   \n",
       "9   In a simple, brief speech, Washington expresse...   \n",
       "10  Washington declares United States neutrality i...   \n",
       "11  Devoting much of his message to foreign affair...   \n",
       "12                                                NaN   \n",
       "13  Washington calls on the militias of other stat...   \n",
       "14  The President outlines his response to the Whi...   \n",
       "15  Washington issues a pardon to those accused of...   \n",
       "16  Washington's 1795 speech is imbued with a sens...   \n",
       "17  In 1796, the House and the Senate were battlin...   \n",
       "18                                                NaN   \n",
       "19  In one of the most famous addresses in America...   \n",
       "20  Making his last public appearance as President...   \n",
       "21  Donald J. Trump was inaugurated on January 20,...   \n",
       "22                                                NaN   \n",
       "23  President Donald Trump talks about his adminis...   \n",
       "24  President Trump addresses the Boy Scout Jambor...   \n",
       "25  President Trump addresses the 72nd session of ...   \n",
       "26  President Donald Trump addresses the issue of ...   \n",
       "27  In Davos, Switzerland, President Trump address...   \n",
       "28  In the 2018 State of the Union Address, Presid...   \n",
       "29  President Trump addresses the Republican membe...   \n",
       "30  President Trump makes a statement about the sc...   \n",
       "31  President Trump addresses the Conservative Pol...   \n",
       "32  President Trump speaks in New Hampshire about ...   \n",
       "33  President Trump addresses American veterans fr...   \n",
       "34  President Donald Trump addresses the General A...   \n",
       "35  President Donald Trump speaks about what he se...   \n",
       "36  In his second State of the Union Address, Pres...   \n",
       "37  President Donald Trump declares a national eme...   \n",
       "38  President Donald Trump speaks to the 74th sess...   \n",
       "39  President Donald Trump holds a press conferenc...   \n",
       "\n",
       "                                           Transcript  \\\n",
       "0   Fellow Citizens of the Senate and the House of...   \n",
       "1   Whereas it is the duty of all Nations to ackno...   \n",
       "2   Fellow Citizens of the Senate and House of Rep...   \n",
       "3   Fellow citizens of the Senate and House of Rep...   \n",
       "4   I the President of the United States, by my ow...   \n",
       "5   I meet you, upon the present occasion, with th...   \n",
       "6   Gentlemen of the House of Representatives: I h...   \n",
       "7   Fellow Citizens of the Senate, and of the Hous...   \n",
       "8   Whereas I have received authentic information,...   \n",
       "9   Fellow Citizens: I am again called upon by the...   \n",
       "10  Whereas it appears that a state of war exists ...   \n",
       "11  Fellow Citizens of the Senate and of the House...   \n",
       "12  Whereas combinations to defeat the execution o...   \n",
       "13  Whereas, from a hope that the combinations aga...   \n",
       "14  Fellow Citizens of the Senate and of the House...   \n",
       "15  Whereas the commissioners appointed by the Pre...   \n",
       "16  I trust I do not deceive myself when I indulge...   \n",
       "17  Gentlemen of the House of Representatives: Wit...   \n",
       "18  Beloved Cherokees, Many years have passed sinc...   \n",
       "19  The period for a new election of a citizen to ...   \n",
       "20  Fellow Citizens of the Senate and House of Rep...   \n",
       "21  Chief Justice Roberts, President Carter, Presi...   \n",
       "22  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "23  Thank you, everybody. Thank you very much. How...   \n",
       "24  TRUMP: Thank you, everybody. Thank you very mu...   \n",
       "25  Mr. Secretary General, Mr. President, world le...   \n",
       "26  Thank you very much. Thank you. Please. I want...   \n",
       "27  Thank you, Klaus, very much. It's a privilege ...   \n",
       "28  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "29  Thank you, Paul and Mitch, for the introductio...   \n",
       "30  My fellow Americans, today I speak to a nation...   \n",
       "31  Thank you very much. Thank you everybody. Than...   \n",
       "32  Thank you to our First Lady, Melania, who has ...   \n",
       "33  Thank you, Lee. Thank you, Lee. Thank you. And...   \n",
       "34  Madam President, Mr. Secretary-General, world ...   \n",
       "35  Just a short time ago, I had the honor of pres...   \n",
       "36  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "37  Thank you very much, everybody. Before we begi...   \n",
       "38  Thank you very much. Mr. President, Mr. Secret...   \n",
       "39  Thank you very much. Thank you. Well, thank yo...   \n",
       "\n",
       "                                                  URL  Word Frequency  \\\n",
       "0   https://millercenter.org/the-presidency/presid...        0.090491   \n",
       "1   https://millercenter.org/the-presidency/presid...        0.166667   \n",
       "2   https://millercenter.org/the-presidency/presid...        0.088608   \n",
       "3   https://millercenter.org/the-presidency/presid...        0.087025   \n",
       "4   https://millercenter.org/the-presidency/presid...        0.187107   \n",
       "5   https://millercenter.org/the-presidency/presid...        0.101808   \n",
       "6   https://millercenter.org/the-presidency/presid...        0.400000   \n",
       "7   https://millercenter.org/the-presidency/presid...        0.079670   \n",
       "8   https://millercenter.org/the-presidency/presid...        0.212121   \n",
       "9   https://millercenter.org/the-presidency/presid...        0.213115   \n",
       "10  https://millercenter.org/the-presidency/presid...        0.289474   \n",
       "11  https://millercenter.org/the-presidency/presid...        0.096413   \n",
       "12  https://millercenter.org/the-presidency/presid...        0.156894   \n",
       "13  https://millercenter.org/the-presidency/presid...        0.133758   \n",
       "14  https://millercenter.org/the-presidency/presid...        0.091648   \n",
       "15  https://millercenter.org/the-presidency/presid...        0.263682   \n",
       "16  https://millercenter.org/the-presidency/presid...        0.070740   \n",
       "17  https://millercenter.org/the-presidency/presid...        0.164530   \n",
       "18  https://millercenter.org/the-presidency/presid...        0.145455   \n",
       "19  https://millercenter.org/the-presidency/presid...        0.080164   \n",
       "20  https://millercenter.org/the-presidency/presid...        0.089520   \n",
       "21  https://millercenter.org/the-presidency/presid...        0.141643   \n",
       "22  https://millercenter.org/the-presidency/presid...        0.089457   \n",
       "23  https://millercenter.org/the-presidency/presid...        0.141720   \n",
       "24  https://millercenter.org/the-presidency/presid...        0.160517   \n",
       "25  https://millercenter.org/the-presidency/presid...        0.128937   \n",
       "26  https://millercenter.org/the-presidency/presid...        0.119093   \n",
       "27  https://millercenter.org/the-presidency/presid...        0.099658   \n",
       "28  https://millercenter.org/the-presidency/presid...        0.093414   \n",
       "29  https://millercenter.org/the-presidency/presid...        0.114221   \n",
       "30  https://millercenter.org/the-presidency/presid...        0.136612   \n",
       "31  https://millercenter.org/the-presidency/presid...        0.119075   \n",
       "32  https://millercenter.org/the-presidency/presid...        0.141314   \n",
       "33  https://millercenter.org/the-presidency/presid...        0.103634   \n",
       "34  https://millercenter.org/the-presidency/presid...        0.113730   \n",
       "35  https://millercenter.org/the-presidency/presid...        0.121803   \n",
       "36  https://millercenter.org/the-presidency/presid...        0.089081   \n",
       "37  https://millercenter.org/the-presidency/presid...        0.106131   \n",
       "38  https://millercenter.org/the-presidency/presid...        0.107126   \n",
       "39  https://millercenter.org/the-presidency/presid...        0.095827   \n",
       "\n",
       "    Named Years  Years from Wars  ...  Word PCA 0  Word PCA 1  Word PCA 2  \\\n",
       "0           NaN              NaN  ...   -0.602673    0.481389    0.222224   \n",
       "1           NaN              NaN  ...   -1.213641   -0.167044   -0.182145   \n",
       "2           NaN              NaN  ...   -0.902582    0.265165    0.052168   \n",
       "3           NaN              NaN  ...   -0.544502    0.540240    0.166418   \n",
       "4           NaN              NaN  ...   -0.603059    0.196260    0.540785   \n",
       "5           NaN              NaN  ...    0.221484    1.346507    0.405504   \n",
       "6           NaN              NaN  ...   -1.420890   -0.066899   -0.116238   \n",
       "7           NaN              NaN  ...    0.170300    1.197036    0.340118   \n",
       "8           NaN              NaN  ...   -1.402423   -0.092744   -0.111781   \n",
       "9           NaN              NaN  ...   -1.447830   -0.072192   -0.072251   \n",
       "10          NaN              NaN  ...   -1.363897   -0.037849   -0.093930   \n",
       "11          NaN              NaN  ...   -0.284045    0.926447    0.212986   \n",
       "12          NaN              NaN  ...   -0.536063    0.753197    0.097249   \n",
       "13          NaN              NaN  ...   -1.103667    0.105616   -0.093900   \n",
       "14          NaN              NaN  ...    0.612290    1.531057    0.396976   \n",
       "15          NaN              NaN  ...   -1.291943    0.041735   -0.116523   \n",
       "16          NaN              NaN  ...   -0.117104    0.786382   -0.007090   \n",
       "17          NaN              NaN  ...   -0.715615    0.503754    0.083713   \n",
       "18          NaN              NaN  ...   -0.567416   -0.151446    0.745053   \n",
       "19          NaN              NaN  ...    2.523043    2.137527    1.499401   \n",
       "20          NaN              NaN  ...    0.584515    1.420371    0.178036   \n",
       "21          NaN              NaN  ...   -0.706742   -0.454865   -0.660413   \n",
       "22     0.997525              NaN  ...    1.036076   -0.649739   -1.499224   \n",
       "23          NaN              NaN  ...   -0.294973   -0.829687    0.482819   \n",
       "24          NaN              NaN  ...    0.562729   -1.761190    2.919205   \n",
       "25          NaN         0.977588  ...    1.370246    0.048445   -1.636938   \n",
       "26          NaN         0.978702  ...    0.212836   -0.938793   -1.104370   \n",
       "27          NaN         0.982995  ...    0.355073   -1.164612   -0.083866   \n",
       "28     0.994059         0.981179  ...    1.149949   -1.035773   -1.500794   \n",
       "29          NaN              NaN  ...    1.317972   -2.297750    0.849963   \n",
       "30          NaN              NaN  ...   -1.160254   -0.445237   -0.169965   \n",
       "31          NaN         0.968301  ...    2.701455   -3.643289    2.929717   \n",
       "32     0.999257              NaN  ...    0.645473   -1.668165    1.229262   \n",
       "33          NaN         0.972759  ...    1.088831   -1.883187    1.495723   \n",
       "34     0.997525         0.978950  ...    0.530063   -0.432077   -1.353240   \n",
       "35          NaN              NaN  ...   -0.791974   -0.497804   -0.486455   \n",
       "36     0.999010         0.982665  ...    1.225100   -0.559258   -1.738326   \n",
       "37     0.978713         0.967476  ...    2.442493   -2.518877    3.527798   \n",
       "38          NaN         0.982665  ...    0.567791   -0.402856   -1.003847   \n",
       "39          NaN         0.992075  ...    1.548871   -1.845280    2.493448   \n",
       "\n",
       "    Word PCA 3  Word PCA 4  Word PCA 5  Word PCA 6  Word PCA 7  Word PCA 8  \\\n",
       "0    -0.149919   -0.118753    0.292454    0.012771   -0.195946    0.293637   \n",
       "1    -0.074037    0.209590    0.888286    0.203182   -0.196372   -0.436881   \n",
       "2    -0.086841   -0.036712    0.414887    0.130578   -0.105305   -0.260012   \n",
       "3    -0.201296   -0.107202   -0.084313    0.159097    0.390601   -0.012455   \n",
       "4     0.976761    0.260800   -0.384000   -0.083146   -0.215440    0.003518   \n",
       "5     0.405072   -0.249228   -1.342746    0.347795    0.551307    0.964376   \n",
       "6    -0.173991    0.129888    0.398741   -0.048008   -0.387403   -0.213353   \n",
       "7    -0.033980   -0.163484   -0.997563    0.075277    0.330827    0.809046   \n",
       "8    -0.153797    0.167700    0.491491   -0.054533   -0.314530   -0.181659   \n",
       "9    -0.262555    0.091304    0.473331   -0.120551   -0.317832   -0.194689   \n",
       "10   -0.128423    0.187971    0.445611   -0.063824   -0.400134   -0.258049   \n",
       "11   -0.257947   -0.191511   -0.858323   -0.207462    0.311487   -0.315844   \n",
       "12    0.283388   -0.012478   -0.352915    0.072869   -1.414140   -0.198859   \n",
       "13   -0.022543    0.191394    0.317326   -0.119859   -0.636200    0.055197   \n",
       "14   -0.051058   -0.467224   -1.437298   -0.119224   -1.106374   -0.482157   \n",
       "15   -0.053547    0.124517    0.281384   -0.132887   -0.491463   -0.040964   \n",
       "16   -0.351968   -0.641085   -0.570803    0.303837    1.531395   -0.166181   \n",
       "17   -0.088134   -0.017218   -0.457877   -0.308880   -0.321505   -0.035268   \n",
       "18    0.334188    0.122242    0.903933   -0.004251   -0.514979    0.135584   \n",
       "19   -1.042733    0.617589    3.425763    0.121435   -0.455202   -0.256009   \n",
       "20    0.035579   -0.351023   -0.965372   -0.204024    0.805118    0.572409   \n",
       "21   -0.043599   -0.314543    0.494561    0.314407    1.246656   -1.250291   \n",
       "22   -0.641936   -1.784353    0.218131    0.177854    3.133021   -1.627366   \n",
       "23   -0.623056    0.061071   -0.155973   -0.356286    0.871874   -0.903432   \n",
       "24    3.191327   -2.091153    0.472647   -0.190002    0.002237   -0.354417   \n",
       "25    2.357328    2.551341   -0.600974   -0.322088   -0.399373   -1.821331   \n",
       "26   -0.144477   -0.190479    0.313582    0.343761    1.026754   -0.475595   \n",
       "27   -0.079907    0.605903    0.662464   -1.638339    0.337702    3.369281   \n",
       "28   -0.552592   -1.605261    0.468818    1.106263   -2.345172   -1.065402   \n",
       "29   -1.859532    0.844466   -1.068846   -1.361623   -0.471691    0.166442   \n",
       "30   -0.191840    0.059832    1.069719    0.246031   -0.203168   -0.129385   \n",
       "31   -2.635601    1.290117   -2.519264   -3.089910   -0.709101   -0.371139   \n",
       "32   -0.950613    1.747661   -1.005997    4.097099    0.253958    0.751260   \n",
       "33   -2.376744    1.093570   -1.445323   -2.673176   -0.482940   -1.116234   \n",
       "34    1.149851    1.317329    0.084124   -0.492235    0.272894    0.226301   \n",
       "35   -0.780311   -0.253916    1.103095   -0.053177    0.582886    0.081854   \n",
       "36   -0.418414   -1.955465   -0.738919   -0.029820   -1.649664    1.813444   \n",
       "37   -2.766293    0.678564   -3.621157   -4.068689    1.308829    2.759447   \n",
       "38    0.913858    0.792552    0.973236   -0.064205    1.112880    1.283768   \n",
       "39   -1.006538    1.079595   -1.776464   -2.442889    0.348755    0.893941   \n",
       "\n",
       "    Word PCA 9  \n",
       "0    -0.322661  \n",
       "1     0.321110  \n",
       "2    -0.164483  \n",
       "3    -0.408206  \n",
       "4    -1.442258  \n",
       "5    -0.420548  \n",
       "6    -0.145249  \n",
       "7    -0.361696  \n",
       "8     0.015971  \n",
       "9    -0.133141  \n",
       "10   -0.012972  \n",
       "11   -0.122620  \n",
       "12    1.009537  \n",
       "13    0.137426  \n",
       "14    2.197091  \n",
       "15   -0.096747  \n",
       "16   -0.220151  \n",
       "17   -0.216945  \n",
       "18   -0.074483  \n",
       "19   -0.429088  \n",
       "20    0.155616  \n",
       "21   -0.213077  \n",
       "22    0.776127  \n",
       "23    1.053571  \n",
       "24   -0.102733  \n",
       "25    0.232609  \n",
       "26    0.078614  \n",
       "27    2.914420  \n",
       "28    1.079229  \n",
       "29    1.826226  \n",
       "30   -0.338684  \n",
       "31    0.775122  \n",
       "32    0.170571  \n",
       "33   -1.232997  \n",
       "34   -0.166533  \n",
       "35   -0.401975  \n",
       "36   -2.135830  \n",
       "37    0.721311  \n",
       "38   -1.506140  \n",
       "39    1.277160  \n",
       "\n",
       "[40 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin an investigation and visualize our data to identify any significant differences between how the two selected presidents speak by plotting the distributions of some of our features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no property 'hue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c2e8a6d57613>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word Frequency'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'President'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Named Years'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'President'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Years from Wars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'President'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Positivity Score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'President'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[1;34m(data, data2, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade_lowest, cbar, cbar_ax, cbar_kws, ax, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m                                 cbar, cbar_ax, cbar_kws, ax, **kwargs)\n\u001b[0;32m    699\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m         ax = _univariate_kdeplot(data, shade, vertical, kernel, bw,\n\u001b[0m\u001b[0;32m    701\u001b[0m                                  \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                                  cumulative=cumulative, **kwargs)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m_univariate_kdeplot\u001b[1;34m(data, shade, vertical, kernel, bw, gridsize, cut, clip, legend, ax, cumulative, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;31m# Use the active color cycle to find the plot color\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[0mfacecolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facecolor\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m     \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m     \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mncy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[0m\u001b[0;32m    419\u001b[0m                 for j in range(max(ncx, ncy))]\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mncy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[0m\u001b[0;32m    419\u001b[0m                 for j in range(max(ncx, ncy))]\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_makeline\u001b[1;34m(self, x, y, kw, kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mdefault_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mseg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;31m# update kwargs before updating data to give the caller a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;31m# chance to init axes (and hence unit support)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickradius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickradius\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m    994\u001b[0m                     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"set_{k}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[0m\u001b[0;32m    997\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[0;32m    998\u001b[0m                     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Line2D' object has no property 'hue'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6oAAAHWCAYAAAB+A3SNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiQklEQVR4nO3dUYild3k/8O/z321ArW3ErMVuEpqWaNwLU3SMUmqbVlqzuVkELxLF0CAsoUa8TOhFe+FNvSiIGLssEoI35qKGdltSQ6FYCzZtNhCja4hMI02mEZKoWFBo2Pj8L+aknoyzO+/uOTPz27OfDxyY931/e+bhxyxfvue8c6a6OwAAADCK/7ffAwAAAMA8RRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGMqORbWq7q+qF6rq2+e4XlX1uapar6onq+pdyx8TAHiVbAZg1U15R/WBJLec5/rRJNfPHseT/PXiYwEA5/FAZDMAK2zHotrdX0/yw/MsOZbkS73p0SRXVtVblzUgAPBashmAVbeM31E9nOS5ueON2TkAYH/IZgAuaQeX8By1zbnedmHV8WzegpQ3vOEN777hhhuW8O0BIHn88cdf6u5D+z3HIGQzAPtukWxeRlHdSHLN3PHVSZ7fbmF3n0xyMknW1tb69OnTS/j2AJBU1X/t9wwDkc0A7LtFsnkZt/6eSnLH7BMG35fkx939/SU8LwBwcWQzAJe0Hd9RraovJ7k5yVVVtZHkL5L8UpJ094kkDye5Ncl6kp8muXO3hgUAZDMAq2/Hotrdt+9wvZN8YmkTAQDnJZsBWHXLuPUXAAAAlkZRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwlElFtapuqaqnq2q9qu7d5vqvVtXfV9U3q+pMVd25/FEBgFfJZgBW2Y5FtaoOJLkvydEkR5LcXlVHtiz7RJLvdPeNSW5O8ldVdcWSZwUAIpsBWH1T3lG9Kcl6dz/T3S8neTDJsS1rOskbq6qS/HKSHyY5u9RJAYBXyWYAVtqUono4yXNzxxuzc/M+n+QdSZ5P8q0kn+run219oqo6XlWnq+r0iy++eJEjA8BlTzYDsNKmFNXa5lxvOf5gkieS/HqS307y+ar6lV/4R90nu3utu9cOHTp0gaMCADOyGYCVNqWobiS5Zu746my+OjvvziQP9ab1JN9LcsNyRgQAtpDNAKy0KUX1sSTXV9V1sw9huC3JqS1rnk3ygSSpql9L8vYkzyxzUADg/8hmAFbawZ0WdPfZqro7ySNJDiS5v7vPVNVds+snknw6yQNV9a1s3o50T3e/tItzA8BlSzYDsOp2LKpJ0t0PJ3l4y7kTc18/n+SPlzsaAHAushmAVTbl1l8AAADYM4oqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADCUSUW1qm6pqqerar2q7j3Hmpur6omqOlNV/7LcMQGAebIZgFV2cKcFVXUgyX1J/ijJRpLHqupUd39nbs2VSb6Q5Jbufraq3rJL8wLAZU82A7DqpryjelOS9e5+prtfTvJgkmNb1nwkyUPd/WySdPcLyx0TAJgjmwFYaVOK6uEkz80db8zOzXtbkjdV1deq6vGqumNZAwIAv0A2A7DSdrz1N0ltc663eZ53J/lAktcl+beqerS7v/uaJ6o6nuR4klx77bUXPi0AkMhmAFbclHdUN5JcM3d8dZLnt1nz1e7+SXe/lOTrSW7c+kTdfbK717p77dChQxc7MwBc7mQzACttSlF9LMn1VXVdVV2R5LYkp7as+bsk76+qg1X1+iTvTfLUckcFAGZkMwArbcdbf7v7bFXdneSRJAeS3N/dZ6rqrtn1E939VFV9NcmTSX6W5Ivd/e3dHBwALleyGYBVV91bf6Vlb6ytrfXp06f35XsDsHqq6vHuXtvvOS5lshmAZVokm6fc+gsAAAB7RlEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADCUSUW1qm6pqqerar2q7j3PuvdU1StV9eHljQgAbCWbAVhlOxbVqjqQ5L4kR5McSXJ7VR05x7rPJHlk2UMCAD8nmwFYdVPeUb0pyXp3P9PdLyd5MMmxbdZ9MslXkrywxPkAgF8kmwFYaVOK6uEkz80db8zO/Z+qOpzkQ0lOLG80AOAcZDMAK21KUa1tzvWW488muae7XznvE1Udr6rTVXX6xRdfnDgiALCFbAZgpR2csGYjyTVzx1cneX7LmrUkD1ZVklyV5NaqOtvdfzu/qLtPJjmZJGtra1sDFQCYRjYDsNKmFNXHklxfVdcl+e8ktyX5yPyC7r7u1a+r6oEk/7A1CAGApZHNAKy0HYtqd5+tqruz+YmBB5Lc391nququ2XW/+wIAe0g2A7Dqpryjmu5+OMnDW85tG4Ld/SeLjwUAnI9sBmCVTfkwJQAAANgziioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMJRJRbWqbqmqp6tqvaru3eb6R6vqydnjG1V14/JHBQBeJZsBWGU7FtWqOpDkviRHkxxJcntVHdmy7HtJfr+735nk00lOLntQAGCTbAZg1U15R/WmJOvd/Ux3v5zkwSTH5hd09ze6+0ezw0eTXL3cMQGAObIZgJU2pageTvLc3PHG7Ny5fDzJPy4yFABwXrIZgJV2cMKa2uZcb7uw6g+yGYa/e47rx5McT5Jrr7124ogAwBayGYCVNuUd1Y0k18wdX53k+a2LquqdSb6Y5Fh3/2C7J+ruk9291t1rhw4duph5AQDZDMCKm1JUH0tyfVVdV1VXJLktyan5BVV1bZKHknysu7+7/DEBgDmyGYCVtuOtv919tqruTvJIkgNJ7u/uM1V11+z6iSR/nuTNSb5QVUlytrvXdm9sALh8yWYAVl11b/srLbtubW2tT58+vS/fG4DVU1WPK2KLkc0ALNMi2Tzl1l8AAADYM4oqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChTCqqVXVLVT1dVetVde8216uqPje7/mRVvWv5owIAr5LNAKyyHYtqVR1Icl+So0mOJLm9qo5sWXY0yfWzx/Ekf73kOQGAGdkMwKqb8o7qTUnWu/uZ7n45yYNJjm1ZcyzJl3rTo0murKq3LnlWAGCTbAZgpU0pqoeTPDd3vDE7d6FrAIDlkM0ArLSDE9bUNuf6Itakqo5n8/ajJPnfqvr2hO/PuV2V5KX9HmIF2MfF2cPF2cPFvX2/B9hDsnlc/i8vh31cnD1cnD1c3EVn85SiupHkmrnjq5M8fxFr0t0nk5xMkqo63d1rFzQtr2EPl8M+Ls4eLs4eLq6qTu/3DHtINg/KHi6HfVycPVycPVzcItk85dbfx5JcX1XXVdUVSW5LcmrLmlNJ7ph9wuD7kvy4u79/sUMBAOclmwFYaTu+o9rdZ6vq7iSPJDmQ5P7uPlNVd82un0jycJJbk6wn+WmSO3dvZAC4vMlmAFbdlFt/090PZzPw5s+dmPu6k3ziAr/3yQtczy+yh8thHxdnDxdnDxd3We2hbB6WPVwO+7g4e7g4e7i4i97D2swxAAAAGMOU31EFAACAPbPrRbWqbqmqp6tqvaru3eZ6VdXnZtefrKp37fZMl5oJe/jR2d49WVXfqKob92POke20h3Pr3lNVr1TVh/dyvkvBlD2sqpur6omqOlNV/7LXM45uwv/lX62qv6+qb8720O8UblFV91fVC+f6EyoyZRrZvDjZvDjZvDjZvDjZvLhdy+bu3rVHNj/g4T+T/GaSK5J8M8mRLWtuTfKP2fx7b+9L8u+7OdOl9pi4h7+T5E2zr4/awwvfw7l1/5zN3/n68H7PPdJj4s/hlUm+k+Ta2fFb9nvukR4T9/DPknxm9vWhJD9McsV+zz7SI8nvJXlXkm+f47pM2XkPZfPe7KFsXnAP59bJ5ovcQ9m8lD2UzTvv465k826/o3pTkvXufqa7X07yYJJjW9YcS/Kl3vRokiur6q27PNelZMc97O5vdPePZoePZvNv5fFzU34Ok+STSb6S5IW9HO4SMWUPP5Lkoe5+Nkm62z6+1pQ97CRvrKpK8svZDMOzezvm2Lr769ncl3ORKTuTzYuTzYuTzYuTzYuTzUuwW9m820X1cJLn5o43ZucudM3l7EL35+PZfMWCn9txD6vqcJIPJTkRtjPl5/BtSd5UVV+rqser6o49m+7SMGUPP5/kHUmeT/KtJJ/q7p/tzXgrQ6bsTDYvTjYvTjYvTjYvTjbvjYvKlEl/nmYBtc25rR8zPGXN5Wzy/lTVH2QzDH93Vye69EzZw88muae7X9l8wYwtpuzhwSTvTvKBJK9L8m9V9Wh3f3e3h7tETNnDDyZ5IskfJvmtJP9UVf/a3f+zy7OtEpmyM9m8ONm8ONm8ONm8ONm8Ny4qU3a7qG4kuWbu+OpsvhpxoWsuZ5P2p6remeSLSY529w/2aLZLxZQ9XEvy4CwIr0pya1Wd7e6/3ZMJxzf1//JL3f2TJD+pqq8nuTGJMNw0ZQ/vTPKXvfkLHetV9b0kNyT5j70ZcSXIlJ3J5sXJ5sXJ5sXJ5sXJ5r1xUZmy27f+Ppbk+qq6rqquSHJbklNb1pxKcsfs06Del+TH3f39XZ7rUrLjHlbVtUkeSvIxr5Bta8c97O7ruvs3uvs3kvxNkj8VhK8x5f/y3yV5f1UdrKrXJ3lvkqf2eM6RTdnDZ7P5qneq6teSvD3JM3s65aVPpuxMNi9ONi9ONi9ONi9ONu+Ni8qUXX1HtbvPVtXdSR7J5qdq3d/dZ6rqrtn1E9n8FLdbk6wn+Wk2X7VgZuIe/nmSNyf5wuxVx7PdvbZfM49m4h5yHlP2sLufqqqvJnkyyc+SfLG7t/2Y8svRxJ/DTyd5oKq+lc3bZO7p7pf2begBVdWXk9yc5Kqq2kjyF0l+KZEpU8nmxcnmxcnmxcnmxcnm5ditbK7Nd7EBAABgDLt96y8AAABcEEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADGXHolpV91fVC1X17XNcr6r6XFWtV9WTVfWu5Y8JALxKNgOw6qa8o/pAklvOc/1okutnj+NJ/nrxsQCA83ggshmAFbZjUe3uryf54XmWHEvypd70aJIrq+qtyxoQAHgt2QzAqlvG76geTvLc3PHG7BwAsD9kMwCXtINLeI7a5lxvu7DqeDZvQcob3vCGd99www1L+PYAkDz++OMvdfeh/Z5jELIZgH23SDYvo6huJLlm7vjqJM9vt7C7TyY5mSRra2t9+vTpJXx7AEiq6r/2e4aByGYA9t0i2byMW39PJblj9gmD70vy4+7+/hKeFwC4OLIZgEvaju+oVtWXk9yc5Kqq2kjyF0l+KUm6+0SSh5PcmmQ9yU+T3LlbwwIAshmA1bdjUe3u23e43kk+sbSJAIDzks0ArLpl3PoLAAAAS6OoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYyqSiWlW3VNXTVbVeVfduc/1Xq+rvq+qbVXWmqu5c/qgAwKtkMwCrbMeiWlUHktyX5GiSI0lur6ojW5Z9Isl3uvvGJDcn+auqumLJswIAkc0ArL4p76jelGS9u5/p7peTPJjk2JY1neSNVVVJfjnJD5OcXeqkAMCrZDMAK21KUT2c5Lm5443ZuXmfT/KOJM8n+VaST3X3z5YyIQCwlWwGYKVNKaq1zbnecvzBJE8k+fUkv53k81X1K7/wRFXHq+p0VZ1+8cUXL3BUAGBGNgOw0qYU1Y0k18wdX53NV2fn3Znkod60nuR7SW7Y+kTdfbK717p77dChQxc7MwBc7mQzACttSlF9LMn1VXXd7EMYbktyasuaZ5N8IEmq6teSvD3JM8scFAD4P7IZgJV2cKcF3X22qu5O8kiSA0nu7+4zVXXX7PqJJJ9O8kBVfSubtyPd090v7eLcAHDZks0ArLodi2qSdPfDSR7ecu7E3NfPJ/nj5Y4GAJyLbAZglU259RcAAAD2jKIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxlUlGtqluq6umqWq+qe8+x5uaqeqKqzlTVvyx3TABgnmwGYJUd3GlBVR1Icl+SP0qykeSxqjrV3d+ZW3Nlki8kuaW7n62qt+zSvABw2ZPNAKy6Ke+o3pRkvbuf6e6XkzyY5NiWNR9J8lB3P5sk3f3CcscEAObIZgBW2pSiejjJc3PHG7Nz896W5E1V9bWqeryq7ljWgADAL5DNAKy0HW/9TVLbnOttnufdST6Q5HVJ/q2qHu3u777miaqOJzmeJNdee+2FTwsAJLIZgBU35R3VjSTXzB1fneT5bdZ8tbt/0t0vJfl6khu3PlF3n+zute5eO3To0MXODACXO9kMwEqbUlQfS3J9VV1XVVckuS3JqS1r/i7J+6vqYFW9Psl7kzy13FEBgBnZDMBK2/HW3+4+W1V3J3kkyYEk93f3maq6a3b9RHc/VVVfTfJkkp8l+WJ3f3s3BweAy5VsBmDVVffWX2nZG2tra3369Ol9+d4ArJ6qery71/Z7jkuZbAZgmRbJ5im3/gIAAMCeUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxFUQUAAGAoiioAAABDUVQBAAAYiqIKAADAUBRVAAAAhqKoAgAAMBRFFQAAgKEoqgAAAAxlUlGtqluq6umqWq+qe8+z7j1V9UpVfXh5IwIAW8lmAFbZjkW1qg4kuS/J0SRHktxeVUfOse4zSR5Z9pAAwM/JZgBW3ZR3VG9Kst7dz3T3y0keTHJsm3WfTPKVJC8scT4A4BfJZgBW2pSiejjJc3PHG7Nz/6eqDif5UJITyxsNADgH2QzASptSVGubc73l+LNJ7unuV877RFXHq+p0VZ1+8cUXJ44IAGwhmwFYaQcnrNlIcs3c8dVJnt+yZi3Jg1WVJFclubWqznb3384v6u6TSU4mydra2tZABQCmkc0ArLQpRfWxJNdX1XVJ/jvJbUk+Mr+gu6979euqeiDJP2wNQgBgaWQzACttx6La3Wer6u5sfmLggST3d/eZqrprdt3vvgDAHpLNAKy6Ke+oprsfTvLwlnPbhmB3/8niYwEA5yObAVhlUz5MCQAAAPaMogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQFFUAAACGoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiTimpV3VJVT1fVelXdu831j1bVk7PHN6rqxuWPCgC8SjYDsMp2LKpVdSDJfUmOJjmS5PaqOrJl2feS/H53vzPJp5OcXPagAMAm2QzAqpvyjupNSda7+5nufjnJg0mOzS/o7m90949mh48muXq5YwIAc2QzACttSlE9nOS5ueON2blz+XiSf9zuQlUdr6rTVXX6xRdfnD4lADBPNgOw0qYU1drmXG+7sOoPshmG92x3vbtPdvdad68dOnRo+pQAwDzZDMBKOzhhzUaSa+aOr07y/NZFVfXOJF9McrS7f7Cc8QCAbchmAFbalHdUH0tyfVVdV1VXJLktyan5BVV1bZKHknysu7+7/DEBgDmyGYCVtuM7qt19tqruTvJIkgNJ7u/uM1V11+z6iSR/nuTNSb5QVUlytrvXdm9sALh8yWYAVl11b/srLbtubW2tT58+vS/fG4DVU1WPK2KLkc0ALNMi2Tzl1l8AAADYM4oqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADAURRUAAIChKKoAAAAMRVEFAABgKIoqAAAAQ1FUAQAAGIqiCgAAwFAUVQAAAIaiqAIAADCUSUW1qm6pqqerar2q7t3melXV52bXn6yqdy1/VADgVbIZgFW2Y1GtqgNJ7ktyNMmRJLdX1ZEty44muX72OJ7kr5c8JwAwI5sBWHVT3lG9Kcl6dz/T3S8neTDJsS1rjiX5Um96NMmVVfXWJc8KAGySzQCstClF9XCS5+aON2bnLnQNALAcshmAlXZwwpra5lxfxJpU1fFs3n6UJP9bVd+e8P05t6uSvLTfQ6wA+7g4e7g4e7i4t+/3AHtINo/L/+XlsI+Ls4eLs4eLu+hsnlJUN5JcM3d8dZLnL2JNuvtkkpNJUlWnu3vtgqblNezhctjHxdnDxdnDxVXV6f2eYQ/J5kHZw+Wwj4uzh4uzh4tbJJun3Pr7WJLrq+q6qroiyW1JTm1ZcyrJHbNPGHxfkh939/cvdigA4LxkMwArbcd3VLv7bFXdneSRJAeS3N/dZ6rqrtn1E0keTnJrkvUkP01y5+6NDACXN9kMwKqbcutvuvvhbAbe/LkTc193kk9c4Pc+eYHr+UX2cDns4+Ls4eLs4eIuqz2UzcOyh8thHxdnDxdnDxd30XtYmzkGAAAAY5jyO6oAAACwZ3a9qFbVLVX1dFWtV9W921yvqvrc7PqTVfWu3Z7pUjNhDz8627snq+obVXXjfsw5sp32cG7de6rqlar68F7OdymYsodVdXNVPVFVZ6rqX/Z6xtFN+L/8q1X191X1zdke+p3CLarq/qp64Vx/QkWmTCObFyebFyebFyebFyebF7dr2dzdu/bI5gc8/GeS30xyRZJvJjmyZc2tSf4xm3/v7X1J/n03Z7rUHhP38HeSvGn29VF7eOF7OLfun7P5O18f3u+5R3pM/Dm8Msl3klw7O37Lfs890mPiHv5Zks/Mvj6U5IdJrtjv2Ud6JPm9JO9K8u1zXJcpO++hbN6bPZTNC+7h3DrZfJF7KJuXsoeyeed93JVs3u13VG9Kst7dz3T3y0keTHJsy5pjSb7Umx5NcmVVvXWX57qU7LiH3f2N7v7R7PDRbP6tPH5uys9hknwyyVeSvLCXw10ipuzhR5I81N3PJkl328fXmrKHneSNVVVJfjmbYXh2b8ccW3d/PZv7ci4yZWeyeXGyeXGyeXGyeXGyeQl2K5t3u6geTvLc3PHG7NyFrrmcXej+fDybr1jwczvuYVUdTvKhJCfCdqb8HL4tyZuq6mtV9XhV3bFn010apuzh55O8I8nzSb6V5FPd/bO9GW9lyJSdyebFyebFyebFyebFyea9cVGZMunP0yygtjm39WOGp6y5nE3en6r6g2yG4e/u6kSXnil7+Nkk93T3K5svmLHFlD08mOTdST6Q5HVJ/q2qHu3u7+72cJeIKXv4wSRPJPnDJL+V5J+q6l+7+392ebZVIlN2JpsXJ5sXJ5sXJ5sXJ5v3xkVlym4X1Y0k18wdX53NVyMudM3lbNL+VNU7k3wxydHu/sEezXapmLKHa0kenAXhVUluraqz3f23ezLh+Kb+X36pu3+S5CdV9fUkNyYRhpum7OGdSf6yN3+hY72qvpfkhiT/sTcjrgSZsjPZvDjZvDjZvDjZvDjZvDcuKlN2+9bfx5JcX1XXVdUVSW5LcmrLmlNJ7ph9GtT7kvy4u7+/y3NdSnbcw6q6NslDST7mFbJt7biH3X1dd/9Gd/9Gkr9J8qeC8DWm/F/+uyTvr6qDVfX6JO9N8tQezzmyKXv4bDZf9U5V/VqStyd5Zk+nvPTJlJ3J5sXJ5sXJ5sXJ5sXJ5r1xUZmyq++odvfZqro7ySPZ/FSt+7v7TFXdNbt+Ipuf4nZrkvUkP83mqxbMTNzDP0/y5iRfmL3qeLa71/Zr5tFM3EPOY8oedvdTVfXVJE8m+VmSL3b3th9Tfjma+HP46SQPVNW3snmbzD3d/dK+DT2gqvpykpuTXFVVG0n+IskvJTJlKtm8ONm8ONm8ONm8ONm8HLuVzbX5LjYAAACMYbdv/QUAAIALoqgCAAAwFEUVAACAoSiqAAAADEVRBQAAYCiKKgAAAENRVAEAABiKogoAAMBQ/j+LTvT0RlkPfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "sns.kdeplot(data['Word Frequency'], hue = data['President'], fill=True, ax = axes[0,0])\n",
    "sns.kdeplot(data['Named Years'], hue = data['President'], fill=True, ax = axes[0,1])\n",
    "sns.kdeplot(data['Years from Wars'], hue = data['President'], fill=True, ax = axes[1,0])\n",
    "sns.kdeplot(data['Positivity Score'], hue = data['President'], fill=True, ax = axes[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there is a significant difference between how George Washington and Donald Trump speak, which is appropriate given their different personalities, the state of the English language at the time, and the political climate they lived in. It appears that Donald Trump is much more consistent with his tone and language than George Washington, who seems to have a greater variety. Additionally, it is interesting to note that Donald Trump does mention named years and years from wars, but Washington does not at all. Due to these factors, it seems like it would be easy to distinguish the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will save the data frame as a csv. That way, after we have saved it the first time, we won't have to re-run all of the cells involved in creating the data frame every time we start a new kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>Speech Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>URL</th>\n",
       "      <th>Word Frequency</th>\n",
       "      <th>Named Years</th>\n",
       "      <th>Years from Wars</th>\n",
       "      <th>...</th>\n",
       "      <th>Word PCA 0</th>\n",
       "      <th>Word PCA 1</th>\n",
       "      <th>Word PCA 2</th>\n",
       "      <th>Word PCA 3</th>\n",
       "      <th>Word PCA 4</th>\n",
       "      <th>Word PCA 5</th>\n",
       "      <th>Word PCA 6</th>\n",
       "      <th>Word PCA 7</th>\n",
       "      <th>Word PCA 8</th>\n",
       "      <th>Word PCA 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1789-04-30</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Inaugural Address</td>\n",
       "      <td>Washington calls on Congress to avoid local an...</td>\n",
       "      <td>Fellow Citizens of the Senate and the House of...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.090491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602673</td>\n",
       "      <td>0.481389</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>-0.149919</td>\n",
       "      <td>-0.118753</td>\n",
       "      <td>0.292454</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>-0.195946</td>\n",
       "      <td>0.293637</td>\n",
       "      <td>-0.322661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789-10-03</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Thanksgiving Proclamation</td>\n",
       "      <td>At the request of Congress, Washington establi...</td>\n",
       "      <td>Whereas it is the duty of all Nations to ackno...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.213641</td>\n",
       "      <td>-0.167044</td>\n",
       "      <td>-0.182145</td>\n",
       "      <td>-0.074037</td>\n",
       "      <td>0.209590</td>\n",
       "      <td>0.888286</td>\n",
       "      <td>0.203182</td>\n",
       "      <td>-0.196372</td>\n",
       "      <td>-0.436881</td>\n",
       "      <td>0.321110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790-01-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Annual Message to Congress</td>\n",
       "      <td>In a wide ranging speech, President Washington...</td>\n",
       "      <td>Fellow Citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902582</td>\n",
       "      <td>0.265165</td>\n",
       "      <td>0.052168</td>\n",
       "      <td>-0.086841</td>\n",
       "      <td>-0.036712</td>\n",
       "      <td>0.414887</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>-0.105305</td>\n",
       "      <td>-0.260012</td>\n",
       "      <td>-0.164483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1790-12-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Second Annual Message to Congress</td>\n",
       "      <td>Washington focuses on commerce in his second a...</td>\n",
       "      <td>Fellow citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.087025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544502</td>\n",
       "      <td>0.540240</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.201296</td>\n",
       "      <td>-0.107202</td>\n",
       "      <td>-0.084313</td>\n",
       "      <td>0.159097</td>\n",
       "      <td>0.390601</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1790-12-29</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Talk to the Chiefs and Counselors of the Senec...</td>\n",
       "      <td>The President reassures the Seneca Nation that...</td>\n",
       "      <td>I the President of the United States, by my ow...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.187107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.603059</td>\n",
       "      <td>0.196260</td>\n",
       "      <td>0.540785</td>\n",
       "      <td>0.976761</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>-0.384000</td>\n",
       "      <td>-0.083146</td>\n",
       "      <td>-0.215440</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-1.442258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1791-10-25</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Third Annual Message to Congress</td>\n",
       "      <td>Washington praises the success of the new bank...</td>\n",
       "      <td>I meet you, upon the present occasion, with th...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.101808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221484</td>\n",
       "      <td>1.346507</td>\n",
       "      <td>0.405504</td>\n",
       "      <td>0.405072</td>\n",
       "      <td>-0.249228</td>\n",
       "      <td>-1.342746</td>\n",
       "      <td>0.347795</td>\n",
       "      <td>0.551307</td>\n",
       "      <td>0.964376</td>\n",
       "      <td>-0.420548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1792-04-05</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Veto Message on Congressional Redistricting</td>\n",
       "      <td>President Washington returns a congressional r...</td>\n",
       "      <td>Gentlemen of the House of Representatives: I h...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.420890</td>\n",
       "      <td>-0.066899</td>\n",
       "      <td>-0.116238</td>\n",
       "      <td>-0.173991</td>\n",
       "      <td>0.129888</td>\n",
       "      <td>0.398741</td>\n",
       "      <td>-0.048008</td>\n",
       "      <td>-0.387403</td>\n",
       "      <td>-0.213353</td>\n",
       "      <td>-0.145249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1792-11-06</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Fourth Annual Message to Congress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fellow Citizens of the Senate, and of the Hous...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.079670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>1.197036</td>\n",
       "      <td>0.340118</td>\n",
       "      <td>-0.033980</td>\n",
       "      <td>-0.163484</td>\n",
       "      <td>-0.997563</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.330827</td>\n",
       "      <td>0.809046</td>\n",
       "      <td>-0.361696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1792-12-12</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation Against Crimes Against the Cherok...</td>\n",
       "      <td>Offering a reward for the capture of American ...</td>\n",
       "      <td>Whereas I have received authentic information,...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.402423</td>\n",
       "      <td>-0.092744</td>\n",
       "      <td>-0.111781</td>\n",
       "      <td>-0.153797</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.491491</td>\n",
       "      <td>-0.054533</td>\n",
       "      <td>-0.314530</td>\n",
       "      <td>-0.181659</td>\n",
       "      <td>0.015971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1793-03-04</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Second Inaugural Address</td>\n",
       "      <td>In a simple, brief speech, Washington expresse...</td>\n",
       "      <td>Fellow Citizens: I am again called upon by the...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.447830</td>\n",
       "      <td>-0.072192</td>\n",
       "      <td>-0.072251</td>\n",
       "      <td>-0.262555</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>0.473331</td>\n",
       "      <td>-0.120551</td>\n",
       "      <td>-0.317832</td>\n",
       "      <td>-0.194689</td>\n",
       "      <td>-0.133141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1793-04-22</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation of Neutrality</td>\n",
       "      <td>Washington declares United States neutrality i...</td>\n",
       "      <td>Whereas it appears that a state of war exists ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.363897</td>\n",
       "      <td>-0.037849</td>\n",
       "      <td>-0.093930</td>\n",
       "      <td>-0.128423</td>\n",
       "      <td>0.187971</td>\n",
       "      <td>0.445611</td>\n",
       "      <td>-0.063824</td>\n",
       "      <td>-0.400134</td>\n",
       "      <td>-0.258049</td>\n",
       "      <td>-0.012972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1793-12-03</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Fifth Annual Message to Congress</td>\n",
       "      <td>Devoting much of his message to foreign affair...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.096413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284045</td>\n",
       "      <td>0.926447</td>\n",
       "      <td>0.212986</td>\n",
       "      <td>-0.257947</td>\n",
       "      <td>-0.191511</td>\n",
       "      <td>-0.858323</td>\n",
       "      <td>-0.207462</td>\n",
       "      <td>0.311487</td>\n",
       "      <td>-0.315844</td>\n",
       "      <td>-0.122620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1794-08-07</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation against Opposition to Execution o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whereas combinations to defeat the execution o...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.156894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.536063</td>\n",
       "      <td>0.753197</td>\n",
       "      <td>0.097249</td>\n",
       "      <td>0.283388</td>\n",
       "      <td>-0.012478</td>\n",
       "      <td>-0.352915</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>-1.414140</td>\n",
       "      <td>-0.198859</td>\n",
       "      <td>1.009537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1794-09-25</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation of Militia Service</td>\n",
       "      <td>Washington calls on the militias of other stat...</td>\n",
       "      <td>Whereas, from a hope that the combinations aga...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.133758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.103667</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>-0.093900</td>\n",
       "      <td>-0.022543</td>\n",
       "      <td>0.191394</td>\n",
       "      <td>0.317326</td>\n",
       "      <td>-0.119859</td>\n",
       "      <td>-0.636200</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.137426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1794-11-19</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Sixth Annual Message to Congress</td>\n",
       "      <td>The President outlines his response to the Whi...</td>\n",
       "      <td>Fellow Citizens of the Senate and of the House...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.091648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612290</td>\n",
       "      <td>1.531057</td>\n",
       "      <td>0.396976</td>\n",
       "      <td>-0.051058</td>\n",
       "      <td>-0.467224</td>\n",
       "      <td>-1.437298</td>\n",
       "      <td>-0.119224</td>\n",
       "      <td>-1.106374</td>\n",
       "      <td>-0.482157</td>\n",
       "      <td>2.197091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1795-07-10</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Proclamation of Pardons in Western Pennsylvania</td>\n",
       "      <td>Washington issues a pardon to those accused of...</td>\n",
       "      <td>Whereas the commissioners appointed by the Pre...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.263682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.291943</td>\n",
       "      <td>0.041735</td>\n",
       "      <td>-0.116523</td>\n",
       "      <td>-0.053547</td>\n",
       "      <td>0.124517</td>\n",
       "      <td>0.281384</td>\n",
       "      <td>-0.132887</td>\n",
       "      <td>-0.491463</td>\n",
       "      <td>-0.040964</td>\n",
       "      <td>-0.096747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1795-12-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Seventh Annual Message to Congress</td>\n",
       "      <td>Washington's 1795 speech is imbued with a sens...</td>\n",
       "      <td>I trust I do not deceive myself when I indulge...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.070740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117104</td>\n",
       "      <td>0.786382</td>\n",
       "      <td>-0.007090</td>\n",
       "      <td>-0.351968</td>\n",
       "      <td>-0.641085</td>\n",
       "      <td>-0.570803</td>\n",
       "      <td>0.303837</td>\n",
       "      <td>1.531395</td>\n",
       "      <td>-0.166181</td>\n",
       "      <td>-0.220151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1796-03-30</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Message to the House of Representatives, Decli...</td>\n",
       "      <td>In 1796, the House and the Senate were battlin...</td>\n",
       "      <td>Gentlemen of the House of Representatives: Wit...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.164530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715615</td>\n",
       "      <td>0.503754</td>\n",
       "      <td>0.083713</td>\n",
       "      <td>-0.088134</td>\n",
       "      <td>-0.017218</td>\n",
       "      <td>-0.457877</td>\n",
       "      <td>-0.308880</td>\n",
       "      <td>-0.321505</td>\n",
       "      <td>-0.035268</td>\n",
       "      <td>-0.216945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1796-08-29</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Talk to the Cherokee Nation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beloved Cherokees, Many years have passed sinc...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567416</td>\n",
       "      <td>-0.151446</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.334188</td>\n",
       "      <td>0.122242</td>\n",
       "      <td>0.903933</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>-0.514979</td>\n",
       "      <td>0.135584</td>\n",
       "      <td>-0.074483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1796-09-19</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Farewell Address</td>\n",
       "      <td>In one of the most famous addresses in America...</td>\n",
       "      <td>The period for a new election of a citizen to ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.080164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.523043</td>\n",
       "      <td>2.137527</td>\n",
       "      <td>1.499401</td>\n",
       "      <td>-1.042733</td>\n",
       "      <td>0.617589</td>\n",
       "      <td>3.425763</td>\n",
       "      <td>0.121435</td>\n",
       "      <td>-0.455202</td>\n",
       "      <td>-0.256009</td>\n",
       "      <td>-0.429088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1796-12-07</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Eighth Annual Message to Congress</td>\n",
       "      <td>Making his last public appearance as President...</td>\n",
       "      <td>Fellow Citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584515</td>\n",
       "      <td>1.420371</td>\n",
       "      <td>0.178036</td>\n",
       "      <td>0.035579</td>\n",
       "      <td>-0.351023</td>\n",
       "      <td>-0.965372</td>\n",
       "      <td>-0.204024</td>\n",
       "      <td>0.805118</td>\n",
       "      <td>0.572409</td>\n",
       "      <td>0.155616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Inaugural Address</td>\n",
       "      <td>Donald J. Trump was inaugurated on January 20,...</td>\n",
       "      <td>Chief Justice Roberts, President Carter, Presi...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.141643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706742</td>\n",
       "      <td>-0.454865</td>\n",
       "      <td>-0.660413</td>\n",
       "      <td>-0.043599</td>\n",
       "      <td>-0.314543</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>0.314407</td>\n",
       "      <td>1.246656</td>\n",
       "      <td>-1.250291</td>\n",
       "      <td>-0.213077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address to Joint Session of Congress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.089457</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036076</td>\n",
       "      <td>-0.649739</td>\n",
       "      <td>-1.499224</td>\n",
       "      <td>-0.641936</td>\n",
       "      <td>-1.784353</td>\n",
       "      <td>0.218131</td>\n",
       "      <td>0.177854</td>\n",
       "      <td>3.133021</td>\n",
       "      <td>-1.627366</td>\n",
       "      <td>0.776127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech at the Unleashing American Energy Event</td>\n",
       "      <td>President Donald Trump talks about his adminis...</td>\n",
       "      <td>Thank you, everybody. Thank you very much. How...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.141720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294973</td>\n",
       "      <td>-0.829687</td>\n",
       "      <td>0.482819</td>\n",
       "      <td>-0.623056</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>-0.155973</td>\n",
       "      <td>-0.356286</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>-0.903432</td>\n",
       "      <td>1.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech at the Boy Scout Jamboree</td>\n",
       "      <td>President Trump addresses the Boy Scout Jambor...</td>\n",
       "      <td>TRUMP: Thank you, everybody. Thank you very mu...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.160517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562729</td>\n",
       "      <td>-1.761190</td>\n",
       "      <td>2.919205</td>\n",
       "      <td>3.191327</td>\n",
       "      <td>-2.091153</td>\n",
       "      <td>0.472647</td>\n",
       "      <td>-0.190002</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>-0.354417</td>\n",
       "      <td>-0.102733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address to the United Nations General Assembly</td>\n",
       "      <td>President Trump addresses the 72nd session of ...</td>\n",
       "      <td>Mr. Secretary General, Mr. President, world le...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.128937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977588</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370246</td>\n",
       "      <td>0.048445</td>\n",
       "      <td>-1.636938</td>\n",
       "      <td>2.357328</td>\n",
       "      <td>2.551341</td>\n",
       "      <td>-0.600974</td>\n",
       "      <td>-0.322088</td>\n",
       "      <td>-0.399373</td>\n",
       "      <td>-1.821331</td>\n",
       "      <td>0.232609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks on National Security Strategy</td>\n",
       "      <td>President Donald Trump addresses the issue of ...</td>\n",
       "      <td>Thank you very much. Thank you. Please. I want...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.978702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212836</td>\n",
       "      <td>-0.938793</td>\n",
       "      <td>-1.104370</td>\n",
       "      <td>-0.144477</td>\n",
       "      <td>-0.190479</td>\n",
       "      <td>0.313582</td>\n",
       "      <td>0.343761</td>\n",
       "      <td>1.026754</td>\n",
       "      <td>-0.475595</td>\n",
       "      <td>0.078614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address at the World Economic Forum</td>\n",
       "      <td>In Davos, Switzerland, President Trump address...</td>\n",
       "      <td>Thank you, Klaus, very much. It's a privilege ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.099658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355073</td>\n",
       "      <td>-1.164612</td>\n",
       "      <td>-0.083866</td>\n",
       "      <td>-0.079907</td>\n",
       "      <td>0.605903</td>\n",
       "      <td>0.662464</td>\n",
       "      <td>-1.638339</td>\n",
       "      <td>0.337702</td>\n",
       "      <td>3.369281</td>\n",
       "      <td>2.914420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>In the 2018 State of the Union Address, Presid...</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.093414</td>\n",
       "      <td>0.994059</td>\n",
       "      <td>0.981179</td>\n",
       "      <td>...</td>\n",
       "      <td>1.149949</td>\n",
       "      <td>-1.035773</td>\n",
       "      <td>-1.500794</td>\n",
       "      <td>-0.552592</td>\n",
       "      <td>-1.605261</td>\n",
       "      <td>0.468818</td>\n",
       "      <td>1.106263</td>\n",
       "      <td>-2.345172</td>\n",
       "      <td>-1.065402</td>\n",
       "      <td>1.079229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks at the House and Senate Republican Mem...</td>\n",
       "      <td>President Trump addresses the Republican membe...</td>\n",
       "      <td>Thank you, Paul and Mitch, for the introductio...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.114221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.317972</td>\n",
       "      <td>-2.297750</td>\n",
       "      <td>0.849963</td>\n",
       "      <td>-1.859532</td>\n",
       "      <td>0.844466</td>\n",
       "      <td>-1.068846</td>\n",
       "      <td>-1.361623</td>\n",
       "      <td>-0.471691</td>\n",
       "      <td>0.166442</td>\n",
       "      <td>1.826226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Statement on the School Shooting in Parkland, ...</td>\n",
       "      <td>President Trump makes a statement about the sc...</td>\n",
       "      <td>My fellow Americans, today I speak to a nation...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.136612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.160254</td>\n",
       "      <td>-0.445237</td>\n",
       "      <td>-0.169965</td>\n",
       "      <td>-0.191840</td>\n",
       "      <td>0.059832</td>\n",
       "      <td>1.069719</td>\n",
       "      <td>0.246031</td>\n",
       "      <td>-0.203168</td>\n",
       "      <td>-0.129385</td>\n",
       "      <td>-0.338684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-02-23</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks at the Conservative Political Action C...</td>\n",
       "      <td>President Trump addresses the Conservative Pol...</td>\n",
       "      <td>Thank you very much. Thank you everybody. Than...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.119075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968301</td>\n",
       "      <td>...</td>\n",
       "      <td>2.701455</td>\n",
       "      <td>-3.643289</td>\n",
       "      <td>2.929717</td>\n",
       "      <td>-2.635601</td>\n",
       "      <td>1.290117</td>\n",
       "      <td>-2.519264</td>\n",
       "      <td>-3.089910</td>\n",
       "      <td>-0.709101</td>\n",
       "      <td>-0.371139</td>\n",
       "      <td>0.775122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks on Combating the Opioid Crisis</td>\n",
       "      <td>President Trump speaks in New Hampshire about ...</td>\n",
       "      <td>Thank you to our First Lady, Melania, who has ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.141314</td>\n",
       "      <td>0.999257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645473</td>\n",
       "      <td>-1.668165</td>\n",
       "      <td>1.229262</td>\n",
       "      <td>-0.950613</td>\n",
       "      <td>1.747661</td>\n",
       "      <td>-1.005997</td>\n",
       "      <td>4.097099</td>\n",
       "      <td>0.253958</td>\n",
       "      <td>0.751260</td>\n",
       "      <td>0.170571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-07-24</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech at the Veterans of Foreign Wars Nationa...</td>\n",
       "      <td>President Trump addresses American veterans fr...</td>\n",
       "      <td>Thank you, Lee. Thank you, Lee. Thank you. And...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.103634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972759</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088831</td>\n",
       "      <td>-1.883187</td>\n",
       "      <td>1.495723</td>\n",
       "      <td>-2.376744</td>\n",
       "      <td>1.093570</td>\n",
       "      <td>-1.445323</td>\n",
       "      <td>-2.673176</td>\n",
       "      <td>-0.482940</td>\n",
       "      <td>-1.116234</td>\n",
       "      <td>-1.232997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018-09-25</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Address at the 73rd Session of the United Nati...</td>\n",
       "      <td>President Donald Trump addresses the General A...</td>\n",
       "      <td>Madam President, Mr. Secretary-General, world ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.113730</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.978950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530063</td>\n",
       "      <td>-0.432077</td>\n",
       "      <td>-1.353240</td>\n",
       "      <td>1.149851</td>\n",
       "      <td>1.317329</td>\n",
       "      <td>0.084124</td>\n",
       "      <td>-0.492235</td>\n",
       "      <td>0.272894</td>\n",
       "      <td>0.226301</td>\n",
       "      <td>-0.166533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-01-19</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks about the US Southern Border</td>\n",
       "      <td>President Donald Trump speaks about what he se...</td>\n",
       "      <td>Just a short time ago, I had the honor of pres...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.121803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.791974</td>\n",
       "      <td>-0.497804</td>\n",
       "      <td>-0.486455</td>\n",
       "      <td>-0.780311</td>\n",
       "      <td>-0.253916</td>\n",
       "      <td>1.103095</td>\n",
       "      <td>-0.053177</td>\n",
       "      <td>0.582886</td>\n",
       "      <td>0.081854</td>\n",
       "      <td>-0.401975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>State of the Union Address</td>\n",
       "      <td>In his second State of the Union Address, Pres...</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.089081</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.982665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.225100</td>\n",
       "      <td>-0.559258</td>\n",
       "      <td>-1.738326</td>\n",
       "      <td>-0.418414</td>\n",
       "      <td>-1.955465</td>\n",
       "      <td>-0.738919</td>\n",
       "      <td>-0.029820</td>\n",
       "      <td>-1.649664</td>\n",
       "      <td>1.813444</td>\n",
       "      <td>-2.135830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Speech Declaring a National Emergency</td>\n",
       "      <td>President Donald Trump declares a national eme...</td>\n",
       "      <td>Thank you very much, everybody. Before we begi...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.106131</td>\n",
       "      <td>0.978713</td>\n",
       "      <td>0.967476</td>\n",
       "      <td>...</td>\n",
       "      <td>2.442493</td>\n",
       "      <td>-2.518877</td>\n",
       "      <td>3.527798</td>\n",
       "      <td>-2.766293</td>\n",
       "      <td>0.678564</td>\n",
       "      <td>-3.621157</td>\n",
       "      <td>-4.068689</td>\n",
       "      <td>1.308829</td>\n",
       "      <td>2.759447</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Remarks at the United Nations General Assembly</td>\n",
       "      <td>President Donald Trump speaks to the 74th sess...</td>\n",
       "      <td>Thank you very much. Mr. President, Mr. Secret...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.107126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567791</td>\n",
       "      <td>-0.402856</td>\n",
       "      <td>-1.003847</td>\n",
       "      <td>0.913858</td>\n",
       "      <td>0.792552</td>\n",
       "      <td>0.973236</td>\n",
       "      <td>-0.064205</td>\n",
       "      <td>1.112880</td>\n",
       "      <td>1.283768</td>\n",
       "      <td>-1.506140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Press Conference</td>\n",
       "      <td>President Donald Trump holds a press conferenc...</td>\n",
       "      <td>Thank you very much. Thank you. Well, thank yo...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.095827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.548871</td>\n",
       "      <td>-1.845280</td>\n",
       "      <td>2.493448</td>\n",
       "      <td>-1.006538</td>\n",
       "      <td>1.079595</td>\n",
       "      <td>-1.776464</td>\n",
       "      <td>-2.442889</td>\n",
       "      <td>0.348755</td>\n",
       "      <td>0.893941</td>\n",
       "      <td>1.277160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date          President         Party  \\\n",
       "0   1789-04-30  George Washington  Unaffiliated   \n",
       "1   1789-10-03  George Washington  Unaffiliated   \n",
       "2   1790-01-08  George Washington  Unaffiliated   \n",
       "3   1790-12-08  George Washington  Unaffiliated   \n",
       "4   1790-12-29  George Washington  Unaffiliated   \n",
       "5   1791-10-25  George Washington  Unaffiliated   \n",
       "6   1792-04-05  George Washington  Unaffiliated   \n",
       "7   1792-11-06  George Washington  Unaffiliated   \n",
       "8   1792-12-12  George Washington  Unaffiliated   \n",
       "9   1793-03-04  George Washington  Unaffiliated   \n",
       "10  1793-04-22  George Washington  Unaffiliated   \n",
       "11  1793-12-03  George Washington  Unaffiliated   \n",
       "12  1794-08-07  George Washington  Unaffiliated   \n",
       "13  1794-09-25  George Washington  Unaffiliated   \n",
       "14  1794-11-19  George Washington  Unaffiliated   \n",
       "15  1795-07-10  George Washington  Unaffiliated   \n",
       "16  1795-12-08  George Washington  Unaffiliated   \n",
       "17  1796-03-30  George Washington  Unaffiliated   \n",
       "18  1796-08-29  George Washington  Unaffiliated   \n",
       "19  1796-09-19  George Washington  Unaffiliated   \n",
       "20  1796-12-07  George Washington  Unaffiliated   \n",
       "21  2017-01-20       Donald Trump    Republican   \n",
       "22  2017-02-28       Donald Trump    Republican   \n",
       "23  2017-06-29       Donald Trump    Republican   \n",
       "24  2017-07-24       Donald Trump    Republican   \n",
       "25  2017-09-19       Donald Trump    Republican   \n",
       "26  2017-12-18       Donald Trump    Republican   \n",
       "27  2018-01-26       Donald Trump    Republican   \n",
       "28  2018-01-30       Donald Trump    Republican   \n",
       "29  2018-02-01       Donald Trump    Republican   \n",
       "30  2018-02-15       Donald Trump    Republican   \n",
       "31  2018-02-23       Donald Trump    Republican   \n",
       "32  2018-03-19       Donald Trump    Republican   \n",
       "33  2018-07-24       Donald Trump    Republican   \n",
       "34  2018-09-25       Donald Trump    Republican   \n",
       "35  2019-01-19       Donald Trump    Republican   \n",
       "36  2019-02-05       Donald Trump    Republican   \n",
       "37  2019-02-15       Donald Trump    Republican   \n",
       "38  2019-09-24       Donald Trump    Republican   \n",
       "39  2019-09-25       Donald Trump    Republican   \n",
       "\n",
       "                                         Speech Title  \\\n",
       "0                             First Inaugural Address   \n",
       "1                           Thanksgiving Proclamation   \n",
       "2                    First Annual Message to Congress   \n",
       "3                   Second Annual Message to Congress   \n",
       "4   Talk to the Chiefs and Counselors of the Senec...   \n",
       "5                    Third Annual Message to Congress   \n",
       "6         Veto Message on Congressional Redistricting   \n",
       "7                   Fourth Annual Message to Congress   \n",
       "8   Proclamation Against Crimes Against the Cherok...   \n",
       "9                            Second Inaugural Address   \n",
       "10                         Proclamation of Neutrality   \n",
       "11                   Fifth Annual Message to Congress   \n",
       "12  Proclamation against Opposition to Execution o...   \n",
       "13                    Proclamation of Militia Service   \n",
       "14                   Sixth Annual Message to Congress   \n",
       "15    Proclamation of Pardons in Western Pennsylvania   \n",
       "16                 Seventh Annual Message to Congress   \n",
       "17  Message to the House of Representatives, Decli...   \n",
       "18                        Talk to the Cherokee Nation   \n",
       "19                                   Farewell Address   \n",
       "20                  Eighth Annual Message to Congress   \n",
       "21                                  Inaugural Address   \n",
       "22               Address to Joint Session of Congress   \n",
       "23     Speech at the Unleashing American Energy Event   \n",
       "24                   Speech at the Boy Scout Jamboree   \n",
       "25     Address to the United Nations General Assembly   \n",
       "26              Remarks on National Security Strategy   \n",
       "27                Address at the World Economic Forum   \n",
       "28                         State of the Union Address   \n",
       "29  Remarks at the House and Senate Republican Mem...   \n",
       "30  Statement on the School Shooting in Parkland, ...   \n",
       "31  Remarks at the Conservative Political Action C...   \n",
       "32             Remarks on Combating the Opioid Crisis   \n",
       "33  Speech at the Veterans of Foreign Wars Nationa...   \n",
       "34  Address at the 73rd Session of the United Nati...   \n",
       "35               Remarks about the US Southern Border   \n",
       "36                         State of the Union Address   \n",
       "37              Speech Declaring a National Emergency   \n",
       "38     Remarks at the United Nations General Assembly   \n",
       "39                                   Press Conference   \n",
       "\n",
       "                                              Summary  \\\n",
       "0   Washington calls on Congress to avoid local an...   \n",
       "1   At the request of Congress, Washington establi...   \n",
       "2   In a wide ranging speech, President Washington...   \n",
       "3   Washington focuses on commerce in his second a...   \n",
       "4   The President reassures the Seneca Nation that...   \n",
       "5   Washington praises the success of the new bank...   \n",
       "6   President Washington returns a congressional r...   \n",
       "7                                                 NaN   \n",
       "8   Offering a reward for the capture of American ...   \n",
       "9   In a simple, brief speech, Washington expresse...   \n",
       "10  Washington declares United States neutrality i...   \n",
       "11  Devoting much of his message to foreign affair...   \n",
       "12                                                NaN   \n",
       "13  Washington calls on the militias of other stat...   \n",
       "14  The President outlines his response to the Whi...   \n",
       "15  Washington issues a pardon to those accused of...   \n",
       "16  Washington's 1795 speech is imbued with a sens...   \n",
       "17  In 1796, the House and the Senate were battlin...   \n",
       "18                                                NaN   \n",
       "19  In one of the most famous addresses in America...   \n",
       "20  Making his last public appearance as President...   \n",
       "21  Donald J. Trump was inaugurated on January 20,...   \n",
       "22                                                NaN   \n",
       "23  President Donald Trump talks about his adminis...   \n",
       "24  President Trump addresses the Boy Scout Jambor...   \n",
       "25  President Trump addresses the 72nd session of ...   \n",
       "26  President Donald Trump addresses the issue of ...   \n",
       "27  In Davos, Switzerland, President Trump address...   \n",
       "28  In the 2018 State of the Union Address, Presid...   \n",
       "29  President Trump addresses the Republican membe...   \n",
       "30  President Trump makes a statement about the sc...   \n",
       "31  President Trump addresses the Conservative Pol...   \n",
       "32  President Trump speaks in New Hampshire about ...   \n",
       "33  President Trump addresses American veterans fr...   \n",
       "34  President Donald Trump addresses the General A...   \n",
       "35  President Donald Trump speaks about what he se...   \n",
       "36  In his second State of the Union Address, Pres...   \n",
       "37  President Donald Trump declares a national eme...   \n",
       "38  President Donald Trump speaks to the 74th sess...   \n",
       "39  President Donald Trump holds a press conferenc...   \n",
       "\n",
       "                                           Transcript  \\\n",
       "0   Fellow Citizens of the Senate and the House of...   \n",
       "1   Whereas it is the duty of all Nations to ackno...   \n",
       "2   Fellow Citizens of the Senate and House of Rep...   \n",
       "3   Fellow citizens of the Senate and House of Rep...   \n",
       "4   I the President of the United States, by my ow...   \n",
       "5   I meet you, upon the present occasion, with th...   \n",
       "6   Gentlemen of the House of Representatives: I h...   \n",
       "7   Fellow Citizens of the Senate, and of the Hous...   \n",
       "8   Whereas I have received authentic information,...   \n",
       "9   Fellow Citizens: I am again called upon by the...   \n",
       "10  Whereas it appears that a state of war exists ...   \n",
       "11  Fellow Citizens of the Senate and of the House...   \n",
       "12  Whereas combinations to defeat the execution o...   \n",
       "13  Whereas, from a hope that the combinations aga...   \n",
       "14  Fellow Citizens of the Senate and of the House...   \n",
       "15  Whereas the commissioners appointed by the Pre...   \n",
       "16  I trust I do not deceive myself when I indulge...   \n",
       "17  Gentlemen of the House of Representatives: Wit...   \n",
       "18  Beloved Cherokees, Many years have passed sinc...   \n",
       "19  The period for a new election of a citizen to ...   \n",
       "20  Fellow Citizens of the Senate and House of Rep...   \n",
       "21  Chief Justice Roberts, President Carter, Presi...   \n",
       "22  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "23  Thank you, everybody. Thank you very much. How...   \n",
       "24  TRUMP: Thank you, everybody. Thank you very mu...   \n",
       "25  Mr. Secretary General, Mr. President, world le...   \n",
       "26  Thank you very much. Thank you. Please. I want...   \n",
       "27  Thank you, Klaus, very much. It's a privilege ...   \n",
       "28  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "29  Thank you, Paul and Mitch, for the introductio...   \n",
       "30  My fellow Americans, today I speak to a nation...   \n",
       "31  Thank you very much. Thank you everybody. Than...   \n",
       "32  Thank you to our First Lady, Melania, who has ...   \n",
       "33  Thank you, Lee. Thank you, Lee. Thank you. And...   \n",
       "34  Madam President, Mr. Secretary-General, world ...   \n",
       "35  Just a short time ago, I had the honor of pres...   \n",
       "36  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "37  Thank you very much, everybody. Before we begi...   \n",
       "38  Thank you very much. Mr. President, Mr. Secret...   \n",
       "39  Thank you very much. Thank you. Well, thank yo...   \n",
       "\n",
       "                                                  URL  Word Frequency  \\\n",
       "0   https://millercenter.org/the-presidency/presid...        0.090491   \n",
       "1   https://millercenter.org/the-presidency/presid...        0.166667   \n",
       "2   https://millercenter.org/the-presidency/presid...        0.088608   \n",
       "3   https://millercenter.org/the-presidency/presid...        0.087025   \n",
       "4   https://millercenter.org/the-presidency/presid...        0.187107   \n",
       "5   https://millercenter.org/the-presidency/presid...        0.101808   \n",
       "6   https://millercenter.org/the-presidency/presid...        0.400000   \n",
       "7   https://millercenter.org/the-presidency/presid...        0.079670   \n",
       "8   https://millercenter.org/the-presidency/presid...        0.212121   \n",
       "9   https://millercenter.org/the-presidency/presid...        0.213115   \n",
       "10  https://millercenter.org/the-presidency/presid...        0.289474   \n",
       "11  https://millercenter.org/the-presidency/presid...        0.096413   \n",
       "12  https://millercenter.org/the-presidency/presid...        0.156894   \n",
       "13  https://millercenter.org/the-presidency/presid...        0.133758   \n",
       "14  https://millercenter.org/the-presidency/presid...        0.091648   \n",
       "15  https://millercenter.org/the-presidency/presid...        0.263682   \n",
       "16  https://millercenter.org/the-presidency/presid...        0.070740   \n",
       "17  https://millercenter.org/the-presidency/presid...        0.164530   \n",
       "18  https://millercenter.org/the-presidency/presid...        0.145455   \n",
       "19  https://millercenter.org/the-presidency/presid...        0.080164   \n",
       "20  https://millercenter.org/the-presidency/presid...        0.089520   \n",
       "21  https://millercenter.org/the-presidency/presid...        0.141643   \n",
       "22  https://millercenter.org/the-presidency/presid...        0.089457   \n",
       "23  https://millercenter.org/the-presidency/presid...        0.141720   \n",
       "24  https://millercenter.org/the-presidency/presid...        0.160517   \n",
       "25  https://millercenter.org/the-presidency/presid...        0.128937   \n",
       "26  https://millercenter.org/the-presidency/presid...        0.119093   \n",
       "27  https://millercenter.org/the-presidency/presid...        0.099658   \n",
       "28  https://millercenter.org/the-presidency/presid...        0.093414   \n",
       "29  https://millercenter.org/the-presidency/presid...        0.114221   \n",
       "30  https://millercenter.org/the-presidency/presid...        0.136612   \n",
       "31  https://millercenter.org/the-presidency/presid...        0.119075   \n",
       "32  https://millercenter.org/the-presidency/presid...        0.141314   \n",
       "33  https://millercenter.org/the-presidency/presid...        0.103634   \n",
       "34  https://millercenter.org/the-presidency/presid...        0.113730   \n",
       "35  https://millercenter.org/the-presidency/presid...        0.121803   \n",
       "36  https://millercenter.org/the-presidency/presid...        0.089081   \n",
       "37  https://millercenter.org/the-presidency/presid...        0.106131   \n",
       "38  https://millercenter.org/the-presidency/presid...        0.107126   \n",
       "39  https://millercenter.org/the-presidency/presid...        0.095827   \n",
       "\n",
       "    Named Years  Years from Wars  ...  Word PCA 0  Word PCA 1  Word PCA 2  \\\n",
       "0           NaN              NaN  ...   -0.602673    0.481389    0.222224   \n",
       "1           NaN              NaN  ...   -1.213641   -0.167044   -0.182145   \n",
       "2           NaN              NaN  ...   -0.902582    0.265165    0.052168   \n",
       "3           NaN              NaN  ...   -0.544502    0.540240    0.166418   \n",
       "4           NaN              NaN  ...   -0.603059    0.196260    0.540785   \n",
       "5           NaN              NaN  ...    0.221484    1.346507    0.405504   \n",
       "6           NaN              NaN  ...   -1.420890   -0.066899   -0.116238   \n",
       "7           NaN              NaN  ...    0.170300    1.197036    0.340118   \n",
       "8           NaN              NaN  ...   -1.402423   -0.092744   -0.111781   \n",
       "9           NaN              NaN  ...   -1.447830   -0.072192   -0.072251   \n",
       "10          NaN              NaN  ...   -1.363897   -0.037849   -0.093930   \n",
       "11          NaN              NaN  ...   -0.284045    0.926447    0.212986   \n",
       "12          NaN              NaN  ...   -0.536063    0.753197    0.097249   \n",
       "13          NaN              NaN  ...   -1.103667    0.105616   -0.093900   \n",
       "14          NaN              NaN  ...    0.612290    1.531057    0.396976   \n",
       "15          NaN              NaN  ...   -1.291943    0.041735   -0.116523   \n",
       "16          NaN              NaN  ...   -0.117104    0.786382   -0.007090   \n",
       "17          NaN              NaN  ...   -0.715615    0.503754    0.083713   \n",
       "18          NaN              NaN  ...   -0.567416   -0.151446    0.745053   \n",
       "19          NaN              NaN  ...    2.523043    2.137527    1.499401   \n",
       "20          NaN              NaN  ...    0.584515    1.420371    0.178036   \n",
       "21          NaN              NaN  ...   -0.706742   -0.454865   -0.660413   \n",
       "22     0.997525              NaN  ...    1.036076   -0.649739   -1.499224   \n",
       "23          NaN              NaN  ...   -0.294973   -0.829687    0.482819   \n",
       "24          NaN              NaN  ...    0.562729   -1.761190    2.919205   \n",
       "25          NaN         0.977588  ...    1.370246    0.048445   -1.636938   \n",
       "26          NaN         0.978702  ...    0.212836   -0.938793   -1.104370   \n",
       "27          NaN         0.982995  ...    0.355073   -1.164612   -0.083866   \n",
       "28     0.994059         0.981179  ...    1.149949   -1.035773   -1.500794   \n",
       "29          NaN              NaN  ...    1.317972   -2.297750    0.849963   \n",
       "30          NaN              NaN  ...   -1.160254   -0.445237   -0.169965   \n",
       "31          NaN         0.968301  ...    2.701455   -3.643289    2.929717   \n",
       "32     0.999257              NaN  ...    0.645473   -1.668165    1.229262   \n",
       "33          NaN         0.972759  ...    1.088831   -1.883187    1.495723   \n",
       "34     0.997525         0.978950  ...    0.530063   -0.432077   -1.353240   \n",
       "35          NaN              NaN  ...   -0.791974   -0.497804   -0.486455   \n",
       "36     0.999010         0.982665  ...    1.225100   -0.559258   -1.738326   \n",
       "37     0.978713         0.967476  ...    2.442493   -2.518877    3.527798   \n",
       "38          NaN         0.982665  ...    0.567791   -0.402856   -1.003847   \n",
       "39          NaN         0.992075  ...    1.548871   -1.845280    2.493448   \n",
       "\n",
       "    Word PCA 3  Word PCA 4  Word PCA 5  Word PCA 6  Word PCA 7  Word PCA 8  \\\n",
       "0    -0.149919   -0.118753    0.292454    0.012771   -0.195946    0.293637   \n",
       "1    -0.074037    0.209590    0.888286    0.203182   -0.196372   -0.436881   \n",
       "2    -0.086841   -0.036712    0.414887    0.130578   -0.105305   -0.260012   \n",
       "3    -0.201296   -0.107202   -0.084313    0.159097    0.390601   -0.012455   \n",
       "4     0.976761    0.260800   -0.384000   -0.083146   -0.215440    0.003518   \n",
       "5     0.405072   -0.249228   -1.342746    0.347795    0.551307    0.964376   \n",
       "6    -0.173991    0.129888    0.398741   -0.048008   -0.387403   -0.213353   \n",
       "7    -0.033980   -0.163484   -0.997563    0.075277    0.330827    0.809046   \n",
       "8    -0.153797    0.167700    0.491491   -0.054533   -0.314530   -0.181659   \n",
       "9    -0.262555    0.091304    0.473331   -0.120551   -0.317832   -0.194689   \n",
       "10   -0.128423    0.187971    0.445611   -0.063824   -0.400134   -0.258049   \n",
       "11   -0.257947   -0.191511   -0.858323   -0.207462    0.311487   -0.315844   \n",
       "12    0.283388   -0.012478   -0.352915    0.072869   -1.414140   -0.198859   \n",
       "13   -0.022543    0.191394    0.317326   -0.119859   -0.636200    0.055197   \n",
       "14   -0.051058   -0.467224   -1.437298   -0.119224   -1.106374   -0.482157   \n",
       "15   -0.053547    0.124517    0.281384   -0.132887   -0.491463   -0.040964   \n",
       "16   -0.351968   -0.641085   -0.570803    0.303837    1.531395   -0.166181   \n",
       "17   -0.088134   -0.017218   -0.457877   -0.308880   -0.321505   -0.035268   \n",
       "18    0.334188    0.122242    0.903933   -0.004251   -0.514979    0.135584   \n",
       "19   -1.042733    0.617589    3.425763    0.121435   -0.455202   -0.256009   \n",
       "20    0.035579   -0.351023   -0.965372   -0.204024    0.805118    0.572409   \n",
       "21   -0.043599   -0.314543    0.494561    0.314407    1.246656   -1.250291   \n",
       "22   -0.641936   -1.784353    0.218131    0.177854    3.133021   -1.627366   \n",
       "23   -0.623056    0.061071   -0.155973   -0.356286    0.871874   -0.903432   \n",
       "24    3.191327   -2.091153    0.472647   -0.190002    0.002237   -0.354417   \n",
       "25    2.357328    2.551341   -0.600974   -0.322088   -0.399373   -1.821331   \n",
       "26   -0.144477   -0.190479    0.313582    0.343761    1.026754   -0.475595   \n",
       "27   -0.079907    0.605903    0.662464   -1.638339    0.337702    3.369281   \n",
       "28   -0.552592   -1.605261    0.468818    1.106263   -2.345172   -1.065402   \n",
       "29   -1.859532    0.844466   -1.068846   -1.361623   -0.471691    0.166442   \n",
       "30   -0.191840    0.059832    1.069719    0.246031   -0.203168   -0.129385   \n",
       "31   -2.635601    1.290117   -2.519264   -3.089910   -0.709101   -0.371139   \n",
       "32   -0.950613    1.747661   -1.005997    4.097099    0.253958    0.751260   \n",
       "33   -2.376744    1.093570   -1.445323   -2.673176   -0.482940   -1.116234   \n",
       "34    1.149851    1.317329    0.084124   -0.492235    0.272894    0.226301   \n",
       "35   -0.780311   -0.253916    1.103095   -0.053177    0.582886    0.081854   \n",
       "36   -0.418414   -1.955465   -0.738919   -0.029820   -1.649664    1.813444   \n",
       "37   -2.766293    0.678564   -3.621157   -4.068689    1.308829    2.759447   \n",
       "38    0.913858    0.792552    0.973236   -0.064205    1.112880    1.283768   \n",
       "39   -1.006538    1.079595   -1.776464   -2.442889    0.348755    0.893941   \n",
       "\n",
       "    Word PCA 9  \n",
       "0    -0.322661  \n",
       "1     0.321110  \n",
       "2    -0.164483  \n",
       "3    -0.408206  \n",
       "4    -1.442258  \n",
       "5    -0.420548  \n",
       "6    -0.145249  \n",
       "7    -0.361696  \n",
       "8     0.015971  \n",
       "9    -0.133141  \n",
       "10   -0.012972  \n",
       "11   -0.122620  \n",
       "12    1.009537  \n",
       "13    0.137426  \n",
       "14    2.197091  \n",
       "15   -0.096747  \n",
       "16   -0.220151  \n",
       "17   -0.216945  \n",
       "18   -0.074483  \n",
       "19   -0.429088  \n",
       "20    0.155616  \n",
       "21   -0.213077  \n",
       "22    0.776127  \n",
       "23    1.053571  \n",
       "24   -0.102733  \n",
       "25    0.232609  \n",
       "26    0.078614  \n",
       "27    2.914420  \n",
       "28    1.079229  \n",
       "29    1.826226  \n",
       "30   -0.338684  \n",
       "31    0.775122  \n",
       "32    0.170571  \n",
       "33   -1.232997  \n",
       "34   -0.166533  \n",
       "35   -0.401975  \n",
       "36   -2.135830  \n",
       "37    0.721311  \n",
       "38   -1.506140  \n",
       "39    1.277160  \n",
       "\n",
       "[40 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('features_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning using Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>Speech Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>URL</th>\n",
       "      <th>Word Frequency</th>\n",
       "      <th>Named Years</th>\n",
       "      <th>Years from Wars</th>\n",
       "      <th>...</th>\n",
       "      <th>Word PCA 0</th>\n",
       "      <th>Word PCA 1</th>\n",
       "      <th>Word PCA 2</th>\n",
       "      <th>Word PCA 3</th>\n",
       "      <th>Word PCA 4</th>\n",
       "      <th>Word PCA 5</th>\n",
       "      <th>Word PCA 6</th>\n",
       "      <th>Word PCA 7</th>\n",
       "      <th>Word PCA 8</th>\n",
       "      <th>Word PCA 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1789-04-30</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Inaugural Address</td>\n",
       "      <td>Washington calls on Congress to avoid local an...</td>\n",
       "      <td>Fellow Citizens of the Senate and the House of...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.090491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602673</td>\n",
       "      <td>0.481389</td>\n",
       "      <td>0.222224</td>\n",
       "      <td>-0.149919</td>\n",
       "      <td>-0.118753</td>\n",
       "      <td>0.292454</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>-0.195946</td>\n",
       "      <td>0.293637</td>\n",
       "      <td>-0.322661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789-10-03</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Thanksgiving Proclamation</td>\n",
       "      <td>At the request of Congress, Washington establi...</td>\n",
       "      <td>Whereas it is the duty of all Nations to ackno...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.213641</td>\n",
       "      <td>-0.167044</td>\n",
       "      <td>-0.182145</td>\n",
       "      <td>-0.074037</td>\n",
       "      <td>0.209590</td>\n",
       "      <td>0.888286</td>\n",
       "      <td>0.203182</td>\n",
       "      <td>-0.196372</td>\n",
       "      <td>-0.436881</td>\n",
       "      <td>0.321110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790-01-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>First Annual Message to Congress</td>\n",
       "      <td>In a wide ranging speech, President Washington...</td>\n",
       "      <td>Fellow Citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.902582</td>\n",
       "      <td>0.265165</td>\n",
       "      <td>0.052168</td>\n",
       "      <td>-0.086841</td>\n",
       "      <td>-0.036712</td>\n",
       "      <td>0.414887</td>\n",
       "      <td>0.130578</td>\n",
       "      <td>-0.105305</td>\n",
       "      <td>-0.260012</td>\n",
       "      <td>-0.164483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1790-12-08</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Second Annual Message to Congress</td>\n",
       "      <td>Washington focuses on commerce in his second a...</td>\n",
       "      <td>Fellow citizens of the Senate and House of Rep...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.087025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544502</td>\n",
       "      <td>0.540240</td>\n",
       "      <td>0.166418</td>\n",
       "      <td>-0.201296</td>\n",
       "      <td>-0.107202</td>\n",
       "      <td>-0.084313</td>\n",
       "      <td>0.159097</td>\n",
       "      <td>0.390601</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.408206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1790-12-29</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>Unaffiliated</td>\n",
       "      <td>Talk to the Chiefs and Counselors of the Senec...</td>\n",
       "      <td>The President reassures the Seneca Nation that...</td>\n",
       "      <td>I the President of the United States, by my ow...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.187107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.603059</td>\n",
       "      <td>0.196260</td>\n",
       "      <td>0.540785</td>\n",
       "      <td>0.976761</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>-0.384000</td>\n",
       "      <td>-0.083146</td>\n",
       "      <td>-0.215440</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-1.442258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date          President         Party  \\\n",
       "0  1789-04-30  George Washington  Unaffiliated   \n",
       "1  1789-10-03  George Washington  Unaffiliated   \n",
       "2  1790-01-08  George Washington  Unaffiliated   \n",
       "3  1790-12-08  George Washington  Unaffiliated   \n",
       "4  1790-12-29  George Washington  Unaffiliated   \n",
       "\n",
       "                                        Speech Title  \\\n",
       "0                            First Inaugural Address   \n",
       "1                          Thanksgiving Proclamation   \n",
       "2                   First Annual Message to Congress   \n",
       "3                  Second Annual Message to Congress   \n",
       "4  Talk to the Chiefs and Counselors of the Senec...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Washington calls on Congress to avoid local an...   \n",
       "1  At the request of Congress, Washington establi...   \n",
       "2  In a wide ranging speech, President Washington...   \n",
       "3  Washington focuses on commerce in his second a...   \n",
       "4  The President reassures the Seneca Nation that...   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  Fellow Citizens of the Senate and the House of...   \n",
       "1  Whereas it is the duty of all Nations to ackno...   \n",
       "2  Fellow Citizens of the Senate and House of Rep...   \n",
       "3  Fellow citizens of the Senate and House of Rep...   \n",
       "4  I the President of the United States, by my ow...   \n",
       "\n",
       "                                                 URL  Word Frequency  \\\n",
       "0  https://millercenter.org/the-presidency/presid...        0.090491   \n",
       "1  https://millercenter.org/the-presidency/presid...        0.166667   \n",
       "2  https://millercenter.org/the-presidency/presid...        0.088608   \n",
       "3  https://millercenter.org/the-presidency/presid...        0.087025   \n",
       "4  https://millercenter.org/the-presidency/presid...        0.187107   \n",
       "\n",
       "   Named Years  Years from Wars  ...  Word PCA 0  Word PCA 1  Word PCA 2  \\\n",
       "0          NaN              NaN  ...   -0.602673    0.481389    0.222224   \n",
       "1          NaN              NaN  ...   -1.213641   -0.167044   -0.182145   \n",
       "2          NaN              NaN  ...   -0.902582    0.265165    0.052168   \n",
       "3          NaN              NaN  ...   -0.544502    0.540240    0.166418   \n",
       "4          NaN              NaN  ...   -0.603059    0.196260    0.540785   \n",
       "\n",
       "   Word PCA 3  Word PCA 4  Word PCA 5  Word PCA 6  Word PCA 7  Word PCA 8  \\\n",
       "0   -0.149919   -0.118753    0.292454    0.012771   -0.195946    0.293637   \n",
       "1   -0.074037    0.209590    0.888286    0.203182   -0.196372   -0.436881   \n",
       "2   -0.086841   -0.036712    0.414887    0.130578   -0.105305   -0.260012   \n",
       "3   -0.201296   -0.107202   -0.084313    0.159097    0.390601   -0.012455   \n",
       "4    0.976761    0.260800   -0.384000   -0.083146   -0.215440    0.003518   \n",
       "\n",
       "   Word PCA 9  \n",
       "0   -0.322661  \n",
       "1    0.321110  \n",
       "2   -0.164483  \n",
       "3   -0.408206  \n",
       "4   -1.442258  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('features_df.csv',index_col=0) # Reloads the data frame from the csv\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things simpler, we delete all non-numerical columns and change the Presidential labels to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions will be used to reclassify some columns of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerically classify presidents\n",
    "def reclassify_labels(data):\n",
    "    presidents_to_classify = pd.unique(data['President'])\n",
    "    \n",
    "    # The exact value of the president will vary based on how many presidents we are trying to classify.\n",
    "    for p in range(0, len(presidents_to_classify)):\n",
    "        for i in range(0, len(data['President'])):\n",
    "            if data['President'][i] == presidents_to_classify[p]:\n",
    "                data['President'][i] = p\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing standardizes the data so all features are between -1 and 1.\n",
    "def normalize(data):\n",
    "    \n",
    "    for column in data:\n",
    "        if column != 'President': #We don't want to reclassify the presidential labels.\n",
    "            data[column] = data[column]/(data[column].max())\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns not needed\n",
    "pres_data = data.drop(columns = ['Date', 'Party', 'Speech Title', 'Summary', 'Transcript', 'URL'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace any missing data with the column means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_data['Named Years'].fillna(value=pres_data['Named Years'].mean(), inplace=True)\n",
    "pres_data['Years from Wars'].fillna(value=pres_data['Years from Wars'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions from above, we normalize the data and numerically classify the Presidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8fad96c79c87>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['President'][i] = p\n"
     ]
    }
   ],
   "source": [
    "pres_data = normalize(pres_data)\n",
    "pres_data = reclassify_labels(pres_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the Features from the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word Frequency</th>\n",
       "      <th>Named Years</th>\n",
       "      <th>Years from Wars</th>\n",
       "      <th>Positivity Score</th>\n",
       "      <th>Sentence Length</th>\n",
       "      <th>Word Length</th>\n",
       "      <th>Syllables per word</th>\n",
       "      <th>Stop Word Proportion</th>\n",
       "      <th>No. of Words</th>\n",
       "      <th>No. of Sentences</th>\n",
       "      <th>...</th>\n",
       "      <th>Word PCA 0</th>\n",
       "      <th>Word PCA 1</th>\n",
       "      <th>Word PCA 2</th>\n",
       "      <th>Word PCA 3</th>\n",
       "      <th>Word PCA 4</th>\n",
       "      <th>Word PCA 5</th>\n",
       "      <th>Word PCA 6</th>\n",
       "      <th>Word PCA 7</th>\n",
       "      <th>Word PCA 8</th>\n",
       "      <th>Word PCA 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226227</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.156414</td>\n",
       "      <td>0.949739</td>\n",
       "      <td>0.963421</td>\n",
       "      <td>0.974121</td>\n",
       "      <td>0.157686</td>\n",
       "      <td>0.030496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223092</td>\n",
       "      <td>0.225208</td>\n",
       "      <td>0.062992</td>\n",
       "      <td>-0.046977</td>\n",
       "      <td>-0.046545</td>\n",
       "      <td>0.085369</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>-0.062542</td>\n",
       "      <td>0.087151</td>\n",
       "      <td>-0.110712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.284686</td>\n",
       "      <td>0.912893</td>\n",
       "      <td>0.924069</td>\n",
       "      <td>0.945692</td>\n",
       "      <td>0.047834</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449255</td>\n",
       "      <td>-0.078148</td>\n",
       "      <td>-0.051631</td>\n",
       "      <td>-0.023199</td>\n",
       "      <td>0.082149</td>\n",
       "      <td>0.259296</td>\n",
       "      <td>0.049592</td>\n",
       "      <td>-0.062678</td>\n",
       "      <td>-0.129666</td>\n",
       "      <td>0.110180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221519</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.105709</td>\n",
       "      <td>0.985286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.955462</td>\n",
       "      <td>0.093248</td>\n",
       "      <td>0.026684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334110</td>\n",
       "      <td>0.124052</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>-0.027212</td>\n",
       "      <td>-0.014389</td>\n",
       "      <td>0.121108</td>\n",
       "      <td>0.031871</td>\n",
       "      <td>-0.033611</td>\n",
       "      <td>-0.077171</td>\n",
       "      <td>-0.056437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.940159</td>\n",
       "      <td>0.928386</td>\n",
       "      <td>0.981746</td>\n",
       "      <td>0.154058</td>\n",
       "      <td>0.050826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201559</td>\n",
       "      <td>0.252741</td>\n",
       "      <td>0.047173</td>\n",
       "      <td>-0.063076</td>\n",
       "      <td>-0.042018</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.038832</td>\n",
       "      <td>0.124672</td>\n",
       "      <td>-0.003697</td>\n",
       "      <td>-0.140064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467767</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.076462</td>\n",
       "      <td>0.867136</td>\n",
       "      <td>0.839041</td>\n",
       "      <td>0.975943</td>\n",
       "      <td>0.154168</td>\n",
       "      <td>0.060991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223235</td>\n",
       "      <td>0.091816</td>\n",
       "      <td>0.153292</td>\n",
       "      <td>0.306067</td>\n",
       "      <td>0.102221</td>\n",
       "      <td>-0.112092</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.068764</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>-0.494870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word Frequency  Named Years  Years from Wars  Positivity Score  \\\n",
       "0        0.226227     0.995087         0.986486          0.875000   \n",
       "1        0.416667     0.995087         0.986486          1.000000   \n",
       "2        0.221519     0.995087         0.986486          0.761905   \n",
       "3        0.217563     0.995087         0.986486          0.800000   \n",
       "4        0.467767     0.995087         0.986486          0.740000   \n",
       "\n",
       "   Sentence Length  Word Length  Syllables per word  Stop Word Proportion  \\\n",
       "0         0.156414     0.949739            0.963421              0.974121   \n",
       "1         0.284686     0.912893            0.924069              0.945692   \n",
       "2         0.105709     0.985286            1.000000              0.955462   \n",
       "3         0.091688     0.940159            0.928386              0.981746   \n",
       "4         0.076462     0.867136            0.839041              0.975943   \n",
       "\n",
       "   No. of Words  No. of Sentences  ...  Word PCA 0  Word PCA 1  Word PCA 2  \\\n",
       "0      0.157686          0.030496  ...   -0.223092    0.225208    0.062992   \n",
       "1      0.047834          0.005083  ...   -0.449255   -0.078148   -0.051631   \n",
       "2      0.093248          0.026684  ...   -0.334110    0.124052    0.014788   \n",
       "3      0.154058          0.050826  ...   -0.201559    0.252741    0.047173   \n",
       "4      0.154168          0.060991  ...   -0.223235    0.091816    0.153292   \n",
       "\n",
       "   Word PCA 3  Word PCA 4  Word PCA 5  Word PCA 6  Word PCA 7  Word PCA 8  \\\n",
       "0   -0.046977   -0.046545    0.085369    0.003117   -0.062542    0.087151   \n",
       "1   -0.023199    0.082149    0.259296    0.049592   -0.062678   -0.129666   \n",
       "2   -0.027212   -0.014389    0.121108    0.031871   -0.033611   -0.077171   \n",
       "3   -0.063076   -0.042018   -0.024612    0.038832    0.124672   -0.003697   \n",
       "4    0.306067    0.102221   -0.112092   -0.020294   -0.068764    0.001044   \n",
       "\n",
       "   Word PCA 9  \n",
       "0   -0.110712  \n",
       "1    0.110180  \n",
       "2   -0.056437  \n",
       "3   -0.140064  \n",
       "4   -0.494870  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop president column and set equal to features\n",
    "features = pres_data.drop(columns = 'President')\n",
    "\n",
    "# Set equal to president column\n",
    "labels = pres_data['President'].astype(int)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Test and Training Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the training set is set to be 75% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, train_size = 0.75, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Parameters for Model Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "SVC(C=1, gamma=0.001, kernel='linear', probability=True)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'kernel':('linear', 'rbf'),\n",
    "              'C': [0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [1e-3, 1e-2, 1e-1, 1, 10]}\n",
    "clf = GridSearchCV(SVC(probability = True), param_grid)\n",
    "\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judging the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Washington       1.00      0.83      0.91         6\n",
      "       Trump       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.90      0.92      0.90        10\n",
      "weighted avg       0.92      0.90      0.90        10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Predicted Speaker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Washington</th>\n",
       "      <th>Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual Speaker</th>\n",
       "      <th>Washington</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Predicted Speaker       \n",
       "                                 Washington  Trump \n",
       "Actual Speaker Washington                  5      1\n",
       "               Trump                       0      4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = clf.predict(test_features) #Running the model on the testing data\n",
    "# Getting the confusion matrix and classification report\n",
    "conf_mat = confusion_matrix(test_labels, pred_labels)\n",
    "class_rep = classification_report(test_labels, pred_labels)\n",
    "#formatting the confusion matrix and classification report:\n",
    "# First, we want to replace the numerical labels in the class rep with the names of presidents. The extra space at\n",
    "#the end prevents actual numerical data from being replaced by a president's name.\n",
    "preslist = ['Washington ','Trump '] \n",
    "# We need to replace a number of 0's equal to 1 less than the length of the president's name before the number so \n",
    "#that everything is still aligned properly\n",
    "replacelist = [' '*(len(preslist[i])-2)+f'{i} ' for i in range(len(preslist))]\n",
    "class_rep = mreplace(class_rep,replacelist,preslist,max=1) #replace all the substrings in replacelist with preslist\n",
    "#The confusion matrix will be turned into a DF with a multi-index so that it is easy to tell what each row and col\n",
    "#represent.\n",
    "cols = pd.MultiIndex.from_product([['Predicted Speaker'],preslist])\n",
    "rows = pd.MultiIndex.from_product([['Actual Speaker'],preslist])\n",
    "print(class_rep)\n",
    "pd.DataFrame(conf_mat,index=rows,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Predicted Label', ylabel='True Label'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_image(clf,test_features,test_labels,preslist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Another President to Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data and Adding Features to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>Speech Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1944-06-12</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Opening Fifth War Loan Drive</td>\n",
       "      <td>Less than a week after D-Day, Roosevelt calls ...</td>\n",
       "      <td>Ladies and Gentlemen: All our fighting men ove...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1944-07-20</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Democratic National Convention</td>\n",
       "      <td>President Roosevelt accepts the Democratic Par...</td>\n",
       "      <td>I have already indicated to you why I accept t...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1945-01-20</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Fourth Inaugural Address</td>\n",
       "      <td>Franklin Delano Roosevelt makes a brief addres...</td>\n",
       "      <td>Mr. Chief Justice, Mr. Vice President, my frie...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1945-02-11</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Joint Statement with Churchill and Stalin on t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THE DEFEAT OF GERMANY We have considered and d...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1945-03-01</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>Address to Congress on Yalta</td>\n",
       "      <td>President Roosevelt reports on his meeting wit...</td>\n",
       "      <td>I hope that you will pardon me for this unusua...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date              President       Party  \\\n",
       "44  1944-06-12  Franklin D. Roosevelt  Democratic   \n",
       "45  1944-07-20  Franklin D. Roosevelt  Democratic   \n",
       "46  1945-01-20  Franklin D. Roosevelt  Democratic   \n",
       "47  1945-02-11  Franklin D. Roosevelt  Democratic   \n",
       "48  1945-03-01  Franklin D. Roosevelt  Democratic   \n",
       "\n",
       "                                         Speech Title  \\\n",
       "44                       Opening Fifth War Loan Drive   \n",
       "45                     Democratic National Convention   \n",
       "46                           Fourth Inaugural Address   \n",
       "47  Joint Statement with Churchill and Stalin on t...   \n",
       "48                       Address to Congress on Yalta   \n",
       "\n",
       "                                              Summary  \\\n",
       "44  Less than a week after D-Day, Roosevelt calls ...   \n",
       "45  President Roosevelt accepts the Democratic Par...   \n",
       "46  Franklin Delano Roosevelt makes a brief addres...   \n",
       "47                                                NaN   \n",
       "48  President Roosevelt reports on his meeting wit...   \n",
       "\n",
       "                                           Transcript  \\\n",
       "44  Ladies and Gentlemen: All our fighting men ove...   \n",
       "45  I have already indicated to you why I accept t...   \n",
       "46  Mr. Chief Justice, Mr. Vice President, my frie...   \n",
       "47  THE DEFEAT OF GERMANY We have considered and d...   \n",
       "48  I hope that you will pardon me for this unusua...   \n",
       "\n",
       "                                                  URL  \n",
       "44  https://millercenter.org/the-presidency/presid...  \n",
       "45  https://millercenter.org/the-presidency/presid...  \n",
       "46  https://millercenter.org/the-presidency/presid...  \n",
       "47  https://millercenter.org/the-presidency/presid...  \n",
       "48  https://millercenter.org/the-presidency/presid...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask data to show certain president\n",
    "FDR_data = orig_data[orig_data['President'] == 'Franklin D. Roosevelt']\n",
    "\n",
    "# Reset index starting from zero\n",
    "FDR_data = FDR_data.reset_index(drop = True)\n",
    "\n",
    "FDR_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the same functions that we used before so that this FDR dataset contains all the same features as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_data['Word Frequency'] = word_frequency(FDR_data, n = 10, remove_stopwords = True)\n",
    "FDR_data['Named Years'] = named_years(FDR_data)\n",
    "FDR_data['Years from Wars'] = year_from_wars(FDR_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = build_sentiment_model()\n",
    "FDR_data['Positivity Score'] = [positivity_score(x, classifier) for x in FDR_data['Transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_data['Sentence Length'] = sentlen(FDR_data['Transcript'])\n",
    "FDR_data['Word Length'] = wordlen(FDR_data['Transcript'])\n",
    "FDR_data['Syllables per word'] = avesylls(FDR_data['Transcript'])\n",
    "FDR_data['Stop Word Proportion'] = SWprop(FDR_data['Transcript'])\n",
    "FDR_data['No. of Words'] = wordcount(FDR_data['Transcript'])\n",
    "FDR_data['No. of Sentences'] = sentcount(FDR_data['Transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_data['Reading Level'] = readlvl(FDR_data['Transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.661844</td>\n",
       "      <td>-0.215269</td>\n",
       "      <td>0.097741</td>\n",
       "      <td>-0.312516</td>\n",
       "      <td>-0.878290</td>\n",
       "      <td>-0.261941</td>\n",
       "      <td>0.511866</td>\n",
       "      <td>0.116277</td>\n",
       "      <td>0.610725</td>\n",
       "      <td>0.548302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.699924</td>\n",
       "      <td>-0.635482</td>\n",
       "      <td>0.478248</td>\n",
       "      <td>0.330119</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>-0.009813</td>\n",
       "      <td>0.471284</td>\n",
       "      <td>-0.152817</td>\n",
       "      <td>-0.036933</td>\n",
       "      <td>-0.660866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.215418</td>\n",
       "      <td>-0.529051</td>\n",
       "      <td>-1.074084</td>\n",
       "      <td>0.091253</td>\n",
       "      <td>-0.156992</td>\n",
       "      <td>-0.044128</td>\n",
       "      <td>-0.429014</td>\n",
       "      <td>1.108246</td>\n",
       "      <td>0.555762</td>\n",
       "      <td>-0.268050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064301</td>\n",
       "      <td>-0.251599</td>\n",
       "      <td>-0.479440</td>\n",
       "      <td>0.609072</td>\n",
       "      <td>0.492875</td>\n",
       "      <td>-0.309599</td>\n",
       "      <td>0.258169</td>\n",
       "      <td>0.308699</td>\n",
       "      <td>0.218142</td>\n",
       "      <td>-0.236497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.080384</td>\n",
       "      <td>-0.706211</td>\n",
       "      <td>-0.194921</td>\n",
       "      <td>0.441868</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>-1.311201</td>\n",
       "      <td>0.558121</td>\n",
       "      <td>0.371401</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>-1.362531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.661844 -0.215269  0.097741 -0.312516 -0.878290 -0.261941  0.511866   \n",
       "1 -0.699924 -0.635482  0.478248  0.330119  0.452148 -0.009813  0.471284   \n",
       "2  0.215418 -0.529051 -1.074084  0.091253 -0.156992 -0.044128 -0.429014   \n",
       "3  0.064301 -0.251599 -0.479440  0.609072  0.492875 -0.309599  0.258169   \n",
       "4 -0.080384 -0.706211 -0.194921  0.441868  0.559900 -1.311201  0.558121   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.116277  0.610725  0.548302  \n",
       "1 -0.152817 -0.036933 -0.660866  \n",
       "2  1.108246  0.555762 -0.268050  \n",
       "3  0.308699  0.218142 -0.236497  \n",
       "4  0.371401  0.496053 -1.362531  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once again, this cell takes a while to run.\n",
    "FDR_data_PCA = FDR_data[['President', 'Transcript']]\n",
    "PCAfeatures = PCAphrases(FDR_data_PCA, n = 1, numfeatures = 10)\n",
    "PCAfeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    FDR_data[f'Word PCA {i}'] = PCAfeatures[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>President</th>\n",
       "      <th>Party</th>\n",
       "      <th>Speech Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>URL</th>\n",
       "      <th>Word Frequency</th>\n",
       "      <th>Named Years</th>\n",
       "      <th>Years from Wars</th>\n",
       "      <th>...</th>\n",
       "      <th>Word PCA 0</th>\n",
       "      <th>Word PCA 1</th>\n",
       "      <th>Word PCA 2</th>\n",
       "      <th>Word PCA 3</th>\n",
       "      <th>Word PCA 4</th>\n",
       "      <th>Word PCA 5</th>\n",
       "      <th>Word PCA 6</th>\n",
       "      <th>Word PCA 7</th>\n",
       "      <th>Word PCA 8</th>\n",
       "      <th>Word PCA 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1933-03-04</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>First Inaugural Address</td>\n",
       "      <td>President Franklin Delano Roosevelt delivers t...</td>\n",
       "      <td>President Hoover, Mr. Chief Justice, my friend...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661844</td>\n",
       "      <td>-0.215269</td>\n",
       "      <td>0.097741</td>\n",
       "      <td>-0.312516</td>\n",
       "      <td>-0.878290</td>\n",
       "      <td>-0.261941</td>\n",
       "      <td>0.511866</td>\n",
       "      <td>0.116277</td>\n",
       "      <td>0.610725</td>\n",
       "      <td>0.548302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1933-03-12</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>On the Banking Crisis</td>\n",
       "      <td>By the time of Roosevelt's inauguration, nearl...</td>\n",
       "      <td>I want to talk for a few minutes with the peop...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.156404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699924</td>\n",
       "      <td>-0.635482</td>\n",
       "      <td>0.478248</td>\n",
       "      <td>0.330119</td>\n",
       "      <td>0.452148</td>\n",
       "      <td>-0.009813</td>\n",
       "      <td>0.471284</td>\n",
       "      <td>-0.152817</td>\n",
       "      <td>-0.036933</td>\n",
       "      <td>-0.660866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1933-05-07</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>On Progress During the First Two Months</td>\n",
       "      <td>Sixty days into the \"First Hundred Days\" Roose...</td>\n",
       "      <td>On a Sunday night a week after my Inauguration...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.082985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215418</td>\n",
       "      <td>-0.529051</td>\n",
       "      <td>-1.074084</td>\n",
       "      <td>0.091253</td>\n",
       "      <td>-0.156992</td>\n",
       "      <td>-0.044128</td>\n",
       "      <td>-0.429014</td>\n",
       "      <td>1.108246</td>\n",
       "      <td>0.555762</td>\n",
       "      <td>-0.268050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1933-07-24</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>On the National Recovery Administration</td>\n",
       "      <td>Roosevelt defends the New Deal at the end of t...</td>\n",
       "      <td>After the adjournment of the historical specia...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.091231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064301</td>\n",
       "      <td>-0.251599</td>\n",
       "      <td>-0.479440</td>\n",
       "      <td>0.609072</td>\n",
       "      <td>0.492875</td>\n",
       "      <td>-0.309599</td>\n",
       "      <td>0.258169</td>\n",
       "      <td>0.308699</td>\n",
       "      <td>0.218142</td>\n",
       "      <td>-0.236497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1933-10-22</td>\n",
       "      <td>Franklin D. Roosevelt</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>On Economic Progress</td>\n",
       "      <td>In the midst of discouraging economic news rep...</td>\n",
       "      <td>It is three months since I have talked with th...</td>\n",
       "      <td>https://millercenter.org/the-presidency/presid...</td>\n",
       "      <td>0.100230</td>\n",
       "      <td>0.956931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080384</td>\n",
       "      <td>-0.706211</td>\n",
       "      <td>-0.194921</td>\n",
       "      <td>0.441868</td>\n",
       "      <td>0.559900</td>\n",
       "      <td>-1.311201</td>\n",
       "      <td>0.558121</td>\n",
       "      <td>0.371401</td>\n",
       "      <td>0.496053</td>\n",
       "      <td>-1.362531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date              President       Party  \\\n",
       "0  1933-03-04  Franklin D. Roosevelt  Democratic   \n",
       "1  1933-03-12  Franklin D. Roosevelt  Democratic   \n",
       "2  1933-05-07  Franklin D. Roosevelt  Democratic   \n",
       "3  1933-07-24  Franklin D. Roosevelt  Democratic   \n",
       "4  1933-10-22  Franklin D. Roosevelt  Democratic   \n",
       "\n",
       "                              Speech Title  \\\n",
       "0                  First Inaugural Address   \n",
       "1                    On the Banking Crisis   \n",
       "2  On Progress During the First Two Months   \n",
       "3  On the National Recovery Administration   \n",
       "4                     On Economic Progress   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  President Franklin Delano Roosevelt delivers t...   \n",
       "1  By the time of Roosevelt's inauguration, nearl...   \n",
       "2  Sixty days into the \"First Hundred Days\" Roose...   \n",
       "3  Roosevelt defends the New Deal at the end of t...   \n",
       "4  In the midst of discouraging economic news rep...   \n",
       "\n",
       "                                          Transcript  \\\n",
       "0  President Hoover, Mr. Chief Justice, my friend...   \n",
       "1  I want to talk for a few minutes with the peop...   \n",
       "2  On a Sunday night a week after my Inauguration...   \n",
       "3  After the adjournment of the historical specia...   \n",
       "4  It is three months since I have talked with th...   \n",
       "\n",
       "                                                 URL  Word Frequency  \\\n",
       "0  https://millercenter.org/the-presidency/presid...        0.080000   \n",
       "1  https://millercenter.org/the-presidency/presid...        0.156404   \n",
       "2  https://millercenter.org/the-presidency/presid...        0.082985   \n",
       "3  https://millercenter.org/the-presidency/presid...        0.091231   \n",
       "4  https://millercenter.org/the-presidency/presid...        0.100230   \n",
       "\n",
       "   Named Years  Years from Wars  ...  Word PCA 0  Word PCA 1  Word PCA 2  \\\n",
       "0          NaN              NaN  ...   -0.661844   -0.215269    0.097741   \n",
       "1          NaN              NaN  ...   -0.699924   -0.635482    0.478248   \n",
       "2          NaN              NaN  ...    0.215418   -0.529051   -1.074084   \n",
       "3          NaN              NaN  ...    0.064301   -0.251599   -0.479440   \n",
       "4     0.956931              NaN  ...   -0.080384   -0.706211   -0.194921   \n",
       "\n",
       "   Word PCA 3  Word PCA 4  Word PCA 5  Word PCA 6  Word PCA 7  Word PCA 8  \\\n",
       "0   -0.312516   -0.878290   -0.261941    0.511866    0.116277    0.610725   \n",
       "1    0.330119    0.452148   -0.009813    0.471284   -0.152817   -0.036933   \n",
       "2    0.091253   -0.156992   -0.044128   -0.429014    1.108246    0.555762   \n",
       "3    0.609072    0.492875   -0.309599    0.258169    0.308699    0.218142   \n",
       "4    0.441868    0.559900   -1.311201    0.558121    0.371401    0.496053   \n",
       "\n",
       "   Word PCA 9  \n",
       "0    0.548302  \n",
       "1   -0.660866  \n",
       "2   -0.268050  \n",
       "3   -0.236497  \n",
       "4   -1.362531  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FDR_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export our data to a csv\n",
    "FDR_data.to_csv('FDR_features_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing FDR Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After combining data from FDR with that of the other presidents, we'll normalize the data, numerically categorize the presidents, and fill in any missing values using the same methods as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_data = pd.read_csv('FDR_features_df.csv',index_col=0) # Reloads the data frame from the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes together\n",
    "full_data = pd.concat([pres_data, FDR_data], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns not needed\n",
    "full_data = full_data.drop(columns = ['Date', 'Party', 'Speech Title', 'Summary', 'Transcript', 'URL'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Axes.legend of <AxesSubplot:>>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axes[0,0].legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's visualize the data before we impute it. Once again, all three presidents are fairly distinct from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Line2D' object has no property 'hue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-def87d4225c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabel_legend_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'President'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFDR_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'President'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Word Frequency'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_legend_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Named Years'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_legend_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Years from Wars'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_legend_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[1;34m(data, data2, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade_lowest, cbar, cbar_ax, cbar_kws, ax, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m                                 cbar, cbar_ax, cbar_kws, ax, **kwargs)\n\u001b[0;32m    699\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m         ax = _univariate_kdeplot(data, shade, vertical, kernel, bw,\n\u001b[0m\u001b[0;32m    701\u001b[0m                                  \u001b[0mgridsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                                  cumulative=cumulative, **kwargs)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\seaborn\\distributions.py\u001b[0m in \u001b[0;36m_univariate_kdeplot\u001b[1;34m(data, shade, vertical, kernel, bw, gridsize, cut, clip, legend, ax, cumulative, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;31m# Use the active color cycle to find the plot color\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[0mfacecolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facecolor\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m     \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m     \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mncy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[0m\u001b[0;32m    419\u001b[0m                 for j in range(max(ncx, ncy))]\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncy\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mncx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mncy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"x has {ncx} columns but y has {ncy} columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         return [func(x[:, j % ncx], y[:, j % ncy], kw, kwargs)\n\u001b[0m\u001b[0;32m    419\u001b[0m                 for j in range(max(ncx, ncy))]\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_makeline\u001b[1;34m(self, x, y, kw, kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0mdefault_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setdefaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mseg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;31m# update kwargs before updating data to give the caller a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;31m# chance to init axes (and hence unit support)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpickradius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickradius\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mind_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m    994\u001b[0m                     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"set_{k}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[0m\u001b[0;32m    997\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[0;32m    998\u001b[0m                     \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Line2D' object has no property 'hue'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7IAAAHeCAYAAACmKTf8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8ZklEQVR4nO3df2yV9f3+8auloaeF9oNrT9tYZEaTriG6VjjsEAk1QhbMyLZkdgkmOqb8cMw1BJvSkuoYpcxK2hpcTLQZEjRKMHFCJ9lkCUQNlGQUNA7RWRziNLSnYLE/Tk9Lz/39gy9HD2WcHt+H0/Pmfj4S/ji378Krr3C4cp3e55jmOI4jAAAAAAAskT7ZAwAAAAAAEA+KLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsEleRHRkZ0dKlS3Xw4MH/eaa/v1/V1dWaO3euFi5cqB07dhgPCQAAro5sBgC4UcZEDw4PD2vdunXq6uq65rn6+nr19PTolVde0enTp7VhwwYVFBRo6dKlxsMCAIBvkM0AALeaUJE9ceKEamtrNWXKlGue++KLL7R//361t7erpKREpaWl6urq0o4dOwhLAAASiGwGALjZhG4tPnLkiBYvXqzdu3df89x7772n3NxclZSURK75fD6dOHFCoVDIbFIAABBBNgMA3GxCP5FdsWLFhH6z7u5uFRQURF3zer0Kh8Pq6enRLbfcEv+EAABgHLIZAOBmCf3U4mAwqKlTp0Zdu/x4ZGQkkX8UAACYALIZAHAjmvCHPU2Ex+MZF4qXH2dlZcX1e3311aDCYSdhs7lNXt50nTs3MNljWI0dmmOH5tihmfT0NN1007TJHmNSkc2pg+ezOXZojh2aY4dmEpXNCS2yRUVFCgQCUdd6enqUkZGhvLy8uH6vcNghLA2xP3Ps0Bw7NMcOYYJsTi3szxw7NMcOzbHDyZfQW4vLy8vV19enU6dORa51dnZq9uzZyszMTOQfBQAAJoBsBgDciIyLbF9fn/r7+yVJxcXFuvfee7VhwwZ9+OGHeuutt7R9+3Y9/PDDxoMCAICJIZsBADc64yJbVVWlLVu2RB43NTWpqKhIDzzwgLZs2aK1a9fqJz/5iekfAwAAJohsBgDc6NIcx0nJG7zPnRvg3nMDXm+OAoH+yR7DauzQHDs0xw7NpKenKS9v+mSPccMgm83wfDbHDs2xQ3Ps0Eyisjmh75EFAAAAAOB6o8gCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwyoSK7OjoqBoaGuT3++X3+9Xc3KxwOHzVs93d3Xrsscfk8/lUUVGhlpYWXbx4MaFDAwDgdmQzAMDNMiZyqLW1VYcOHVJbW5sGBgZUW1ur3NxcrV69etzZtWvXasaMGdq9e7e6u7tVU1Oj7OxsrVmzJuHDAwDgVmQzAMDNYv5ENhQKadeuXaqrq1NZWZkWLFig6upq7dy5c9wrvxcuXNDx48f1m9/8Rrfffrvuvvtu/fSnP9Xhw4ev2zcAAIDbkM0AALeLWWRPnjypYDAon88Xuebz+dTb26szZ85EnfV4PMrOztYbb7yhkZERdXd3691339Wdd96Z+MkBAHApshkA4HYxi2x3d7eys7OVk5MTueb1eiVJZ8+ejTqbmZmpTZs26c0331R5ebkqKirk9Xq1bt26BI8NAIB7kc0AALeL+R7ZYDCoqVOnRl27/HhkZGTc+VOnTmnevHlas2aNent71dDQoK1bt6q+vj6uwfLypsd1HuN5vTmxD+Ga2KE5dmiOHeJKZLO9eD6bY4fm2KE5djj5YhZZj8czLhQvP87Kyoq6fuTIEb300kt65513Iq8SZ2RkaM2aNXr00UeVn58/4cHOnRtQOOxM+Dyieb05CgT6J3sMq7FDc+zQHDs0k56edkOWL7LZTjyfzbFDc+zQHDs0k6hsjnlrcVFRkYaGhjQ4OBi5FggEJEmFhYVRZz/44AMVFRVF3ep0xx13aGxsTF9++aXxsAAAgGwGACBmkS0tLVVWVpY6Ozsj144ePar8/HzNmjUr6mxhYaE+//xzDQ0NRa598sknkqSZM2cmamYAAFyNbAYAuF3MIuvxeFRZWanGxkYdO3ZMHR0damlp0fLlyyVJfX196u+/9KP1RYsWKS8vT7W1terq6tLRo0e1adMm/eIXv9D3vve96/udAADgEmQzAMDtYr5HVpJqamoUCoW0cuVKZWZmqrKyUqtWrZIkVVVVqbi4WE1NTZo+fbp27typp556Sg888ICys7N133336fHHH7+u3wQAAG5DNgMA3CzNcZyU/NQGPlDCDG9CN8cOzbFDc+zQzI36YU+ThWw2w/PZHDs0xw7NsUMzSfuwJwAAAAAAUglFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqEyqyo6OjamhokN/vl9/vV3Nzs8Lh8FXPDg4O6oknntC8efM0f/58bd68WSMjIwkdGgAAtyObAQBuljGRQ62trTp06JDa2to0MDCg2tpa5ebmavXq1ePO1tXV6fTp03rxxRc1PDys6upqzZgxQ1VVVQkfHgAAtyKbAQBuFrPIhkIh7dq1S88884zKysokSdXV1WpubtbKlSuVnv7ND3VPnTql/fv3669//atKSkokSb/97W/1j3/84zqNDwCA+5DNAAC3i3lr8cmTJxUMBuXz+SLXfD6fent7debMmaizHR0duvXWWyNBKUnLli3T9u3bEzgyAADuRjYDANwuZpHt7u5Wdna2cnJyIte8Xq8k6ezZs1FnP/vsM82cOVOvvvqqlixZokWLFqm5uVmjo6MJHhsAAPcimwEAbhfz1uJgMKipU6dGXbv8+MoPihgaGtL777+vixcv6umnn9b58+e1ceNGXbx4UXV1dXENlpc3Pa7zGM/rzYl9CNfEDs2xQ3PsEFcim+3F89kcOzTHDs2xw8kXs8h6PJ5xoXj5cVZWVtT1KVOmKBgMatu2bZoxY4Yk6euvv9bGjRu1fv36qPfsxHLu3IDCYWfC5xHN681RINA/2WNYjR2aY4fm2KGZ9PS0G7J8kc124vlsjh2aY4fm2KGZRGVzzPQqKirS0NCQBgcHI9cCgYAkqbCwMOpsQUGB8vPzI0EpSbfddpuGh4d1/vx542EBAADZDABAzCJbWlqqrKwsdXZ2Rq4dPXpU+fn5mjVrVtTZOXPmKBAIqKenJ3Lt008/1fTp03XTTTclcGwAANyLbAYAuF3MIuvxeFRZWanGxkYdO3ZMHR0damlp0fLlyyVJfX196u+/9KP1+fPna/bs2aqpqdHHH3+sjo4OPfPMM1q2bJmmTJlyfb8TAABcgmwGALhdzPfISlJNTY1CoZBWrlypzMxMVVZWatWqVZKkqqoqFRcXq6mpSenp6XrhhRe0efNmLVu2TJmZmbr//vu1bt266/pNAADgNmQzAMDN0hzHSclPbeADJczwJnRz7NAcOzTHDs3cqB/2NFnIZjM8n82xQ3Ps0Bw7NJO0D3sCAAAAACCVUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYZUJFdnR0VA0NDfL7/fL7/WpublY4HI75devXr9dDDz1kPCQAAIhGNgMA3GxCRba1tVWHDh1SW1ubWltbtWfPHv35z3++5tccPHhQe/fuTciQAAAgGtkMAHCzmEU2FApp165dqqurU1lZmRYsWKDq6mrt3Lnzf77ye+HCBf3hD3/QnDlzEj4wAABuRzYDANwuZpE9efKkgsGgfD5f5JrP51Nvb6/OnDlz1a/ZsmWLlixZovLy8oQNCgAALiGbAQBuF7PIdnd3Kzs7Wzk5OZFrXq9XknT27Nlx5w8cOKDjx49r3bp1CRwTAABcRjYDANwuI9aBYDCoqVOnRl27/HhkZCTq+oULF7Rx40Y1NzcrKyvLaLC8vOlGXw/J682JfQjXxA7NsUNz7BBXIpvtxfPZHDs0xw7NscPJF7PIejyecaF4+fGVgdjY2KhFixbJ7/cbD3bu3IDCYcf493ErrzdHgUD/ZI9hNXZojh2aY4dm0tPTbsjyRTbbieezOXZojh2aY4dmEpXNMYtsUVGRhoaGNDg4qGnTpkmSAoGAJKmwsDDqbHt7uzwej9rb2yVd+l8DjI2N6a677tK+fft08803Gw8MAIDbkc0AALeLWWRLS0uVlZWlzs5OVVRUSJKOHj2q/Px8zZo1K+rs/v37ox63tbXp3//+t5qbm1VQUJDAsQEAcC+yGQDgdhO6tbiyslKNjY1qampSKBRSS0uLli9fLknq6+vTlClTlJOTo+9///tRX5ubmyuPxzPuOgAA+O7IZgCA28UsspJUU1OjUCiklStXKjMzU5WVlVq1apUkqaqqSsXFxWpqarqugwIAgG+QzQAAN0tzHCclP7WBD5Qww5vQzbFDc+zQHDs0c6N+2NNkIZvN8Hw2xw7NsUNz7NBMorI55v9HFgAAAACAVEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALDKhIrs6OioGhoa5Pf75ff71dzcrHA4fNWzXV1dWrFihXw+n+655x41NTVpeHg4oUMDAOB2ZDMAwM0yJnKotbVVhw4dUltbmwYGBlRbW6vc3FytXr066tzAwIBWrVqlefPmaffu3QoEAqqvr9fo6KiefPLJ6/INAADgRmQzAMDNYv5ENhQKadeuXaqrq1NZWZkWLFig6upq7dy5c9wrv4cPH1Z/f78aGxt1++23a/78+Vq7dq3a29uv2zcAAIDbkM0AALeLWWRPnjypYDAon88Xuebz+dTb26szZ85EnS0rK9Nzzz2nqVOnRq6lpaVpdHT0f97uBAAA4kM2AwDcLmaR7e7uVnZ2tnJyciLXvF6vJOns2bNRZwsLC+X3+yOPx8bG9PLLL2vOnDlKT+dzpQAASASyGQDgdjHfIxsMBqNexZUUeTwyMnLNr928ebM++ugjvfbaawYjAgCAbyObAQBuF7PIejyecaF4+XFWVtZVv2ZsbEybNm3S66+/rm3btqm0tDTuwfLypsf9NYjm9ebEPoRrYofm2KE5dogrkc324vlsjh2aY4fm2OHki1lki4qKNDQ0pMHBQU2bNk2SFAgEJF26XelKo6Ojqq6u1sGDB/Xss89q8eLF32mwc+cGFA473+lrcenJFQj0T/YYVmOH5tihOXZoJj097YYsX2SznXg+m2OH5tihOXZoJlHZHPPNMaWlpcrKylJnZ2fk2tGjR5Wfn69Zs2aNO19fX6+3335bzz///HcOSgAA8L+RzQAAt4tZZD0ejyorK9XY2Khjx46po6NDLS0tWr58uSSpr69P/f2XXpE4ePCg9u7dq5qaGpWUlCgQCER+OQ6v4AIAkAhkMwDA7WLeWixJNTU1CoVCWrlypTIzM1VZWalVq1ZJkqqqqlRcXKympib97W9/k3TpgyQ2b94c9XscO3YscvsTAAAwQzYDANwszUnRl2N5H44Z7t03xw7NsUNz7NDMjfoe2clCNpvh+WyOHZpjh+bYoZmkvUcWAAAAAIBUQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABglQkV2dHRUTU0NMjv98vv96u5uVnhcPiqZ/v7+1VdXa25c+dq4cKF2rFjR0IHBgAAZDMAwN0yJnKotbVVhw4dUltbmwYGBlRbW6vc3FytXr163Nn6+nr19PTolVde0enTp7VhwwYVFBRo6dKlCR8eAAC3IpsBAG4Ws8iGQiHt2rVLzzzzjMrKyiRJ1dXVam5u1sqVK5We/s0Pdb/44gvt379f7e3tKikpUWlpqbq6urRjxw7CEgCABCGbAQBuF/PW4pMnTyoYDMrn80Wu+Xw+9fb26syZM1Fn33vvPeXm5qqkpCTq7IkTJxQKhRI4NgAA7kU2AwDcLuZPZLu7u5Wdna2cnJzINa/XK0k6e/asbr311qizBQUFUV/v9XoVDofV09OjW265ZcKDpaenTfgsro4dmmOH5tihOXb43d2ouyOb7cUOzbFDc+zQHDv87hK1u5hFNhgMaurUqVHXLj8eGRn5zmdjuemmaXGdx3h5edMnewTrsUNz7NAcO8SVyGZ78Xw2xw7NsUNz7HDyxby12OPxjAu6y4+zsrK+81kAAPDdkM0AALeLWWSLioo0NDSkwcHByLVAICBJKiwsHHf28n+7rKenRxkZGcrLy0vEvAAAuB7ZDABwu5hFtrS0VFlZWers7IxcO3r0qPLz8zVr1qyos+Xl5err69OpU6ci1zo7OzV79mxlZmYmcGwAANyLbAYAuN2Ebi2urKxUY2Ojjh07po6ODrW0tGj58uWSpL6+PvX390uSiouLde+992rDhg368MMP9dZbb2n79u16+OGHr+93AQCAi5DNAAC3S3Mcx4l1KBQKqbGxUfv27VNmZqYqKyv1+OOPKy0tTQ899JCKi4vV1NQk6VJ4/v73v9fbb7+t//u//9MjjzyiX//619f7+wAAwFXIZgCAm02oyAIAAAAAkCpi3loMAAAAAEAqocgCAAAAAKxCkQUAAAAAWCXpRXZ0dFQNDQ3y+/3y+/1qbm5WOBy+6tn+/n5VV1dr7ty5WrhwoXbs2JHkaVNTPDvs6urSihUr5PP5dM8996ipqUnDw8NJnjg1xbPHb1u/fr0eeuihJEyY+uLZ4eDgoJ544gnNmzdP8+fP1+bNmzUyMpLkiVNPPDvs7u7WY489Jp/Pp4qKCrW0tOjixYtJnjh1jYyMaOnSpTp48OD/PEOuXB3ZbI5sTgyy2RzZbI5sTpzrmc0ZiRpyolpbW3Xo0CG1tbVpYGBAtbW1ys3N1erVq8edra+vV09Pj1555RWdPn1aGzZsUEFBgZYuXZrssVPKRHc4MDCgVatWad68edq9e7cCgYDq6+s1OjqqJ598cpKmTx3x/F287ODBg9q7d69+9KMfJXHS1BXPDuvq6nT69Gm9+OKLGh4eVnV1tWbMmKGqqqpJmDx1xLPDtWvXasaMGdq9e7e6u7tVU1Oj7OxsrVmzZhImTy3Dw8Nat26durq6rnmOXLk6stkc2ZwYZLM5stkc2ZwY1z2bnSQaHh52ysrKnAMHDkSu/eUvf3HuvvtuZ2xsLOrsf//7X+cHP/iB8/HHH0eu/elPf3Luv//+pM2biuLZ4VtvveXMnTvXCYVCkWt79+51fD5f0uZNVfHs8bK+vj6noqLCWbZsmfPggw8ma9SUFc8Ou7q6nJKSkqjn865du5xHHnkkafOmonh22NfX55SUlDjHjx+PXHvqqaf4u+g4zr/+9S9n6dKlzs9+9jOnpKQkap/fRq5cHdlsjmxODLLZHNlsjmxOjGRkc1JvLT558qSCwaB8Pl/kms/nU29vr86cORN19r333lNubq5KSkqizp44cUKhUChpM6eaeHZYVlam5557TlOnTo1cS0tL0+jo6IRu07mRxbPHy7Zs2aIlS5aovLw8SVOmtnh22NHRoVtvvTXq+bxs2TJt3749afOmonh26PF4lJ2drTfeeEMjIyPq7u7Wu+++qzvvvDPZY6ecI0eOaPHixdq9e/c1z5ErV0c2myObE4NsNkc2myObEyMZ2ZzUItvd3a3s7Gzl5ORErnm9XknS2bNnx50tKCiIuub1ehUOh9XT03P9h01R8eywsLBQfr8/8nhsbEwvv/yy5syZo/R0d3/OVzx7lKQDBw7o+PHjWrduXdJmTHXx7PCzzz7TzJkz9eqrr2rJkiVatGiRmpubNTo6mtSZU008O8zMzNSmTZv05ptvqry8XBUVFfJ6vfydlLRixQqtW7dOHo/nmufIlasjm82RzYlBNpsjm82RzYmRjGxO6ntkg8Fg1CuQkiKPr3xjeTxn3cRkL5s3b9ZHH32k11577brNZ4t49njhwgVt3LhRzc3NysrKStqMqS6eHQ4NDen999/XxYsX9fTTT+v8+fPauHGjLl68qLq6uqTNnGrifT6fOnVK8+bN05o1a9Tb26uGhgZt3bpV9fX1SZnXduTK1ZHN5sjmxCCbzZHN5sjm5DL59zOpRdbj8Ywb6PLjK/8Riuesm3yXvYyNjWnTpk16/fXXtW3bNpWWll73OVNdPHtsbGzUokWLol5BR3w7nDJlioLBoLZt26YZM2ZIkr7++mtt3LhR69evd+1PIeLZ4ZEjR/TSSy/pnXfeibxKnJGRoTVr1ujRRx9Vfn5+coa2GLlydWSzObI5Mchmc2SzObI5uUxyJalFtqioSENDQxocHNS0adMkSYFAQNKlW22uPHv5v13W09OjjIwM5eXlJWfgFBTPDqVLHx9eXV2tgwcP6tlnn9XixYuTOm+qimeP7e3t8ng8am9vl3Rpp2NjY7rrrru0b98+3XzzzckdPkXEs8OCggLl5+dHglKSbrvtNg0PD+v8+fOu/Yc+nh1+8MEHKioqirrV6Y477tDY2Ji+/PJL1+4wHuTK1ZHN5sjmxCCbzZHN5sjm5DLJlaS+1FJaWqqsrCx1dnZGrh09elT5+fmaNWtW1Nny8nL19fXp1KlTkWudnZ2aPXu2MjMzkzZzqolnh9Klj7N+++239fzzzxOU3xLPHvfv36/29nbt2bNHe/bs0c9//nPdcccd2rNnz7h7+t0knh3OmTNHgUAg6r0On376qaZPn66bbropaTOnmnh2WFhYqM8//1xDQ0ORa5988okkaebMmckZ2HLkytWRzebI5sQgm82RzebI5uQyypWEfcbyBG3evNn58Y9/7HR2djqHDx92FixY4LzwwguO4zjOV1995Xz99deRs48++qjzy1/+0jlx4oTz97//3SkvL3f27duX7JFTzkR3eODAAaekpMR5+eWXnZ6enqhf4XB4Mr+FlBDP38Vva2pq4mPV/7+J7nBsbMy5//77nV/96lfORx995Bw+fNipqKhwtm7dOpnjp4SJ7rC/v9+pqKhwfve73zmffPKJ889//tO57777nLq6uskcP+Vc+RH/5MrEkM3myObEIJvNkc3myObEul7ZnPQiOzw87DzxxBPOXXfd5cyfP99pbm6O/MP94IMPOrW1tZGzX331lVNVVeX88Ic/dBYuXOjs2LEj2eOmpInusKamxikpKbnqr4GBgcn8FlJCPH8Xv42w/EY8O+zt7XXWrl3rlJeXO36/39m6daszOjo6WaOnjHh2+J///MdZvXq14/P5nIqKCuePf/yjMzw8PFmjp6Qrw5JcmRiy2RzZnBhkszmy2RzZnFjXK5vTHMdxrvNPjAEAAAAASBh3fhwZAAAAAMBaFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFaJq8iOjIxo6dKlOnjw4P8809/fr+rqas2dO1cLFy7Ujh07jIcEAABXRzYDANwoY6IHh4eHtW7dOnV1dV3zXH19vXp6evTKK6/o9OnT2rBhgwoKCrR06VLjYQEAwDfIZgCAW02oyJ44cUK1tbWaMmXKNc998cUX2r9/v9rb21VSUqLS0lJ1dXVpx44dhCUAAAlENgMA3GxCtxYfOXJEixcv1u7du6957r333lNubq5KSkoi13w+n06cOKFQKGQ2KQAAiCCbAQBuNqGfyK5YsWJCv1l3d7cKCgqirnm9XoXDYfX09OiWW26Jf0IAADAO2QwAcLOEfmpxMBjU1KlTo65dfjwyMpLIPwoAAEwA2QwAuBEltMh6PJ5xoXj5cVZWViL/KAAAMAFkMwDgRjThTy2eiKKiIgUCgahrPT09ysjIUF5eXly/11dfDSocdhI5nqvk5U3XuXMDkz2G1dihOXZojh2aSU9P0003TZvsMSYV2Zw6eD6bY4fm2KE5dmgmUdmc0CJbXl6uvr4+nTp1SrfffrskqbOzU7Nnz1ZmZmZcv1c47BCWhtifOXZojh2aY4cwQTanFvZnjh2aY4fm2OHkM761uK+vT/39/ZKk4uJi3XvvvdqwYYM+/PBDvfXWW9q+fbsefvhh40EBAMDEkM0AgBudcZGtqqrSli1bIo+bmppUVFSkBx54QFu2bNHatWv1k5/8xPSPAQAAE0Q2AwBudGmO46Tkz8XPnRvgR/YGvN4cBQL9kz2G1dihOXZojh2aSU9PU17e9Mke44ZBNpvh+WyOHZpjh+bYoZlEZXNCP7UYAAAAAIDrjSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhMqsqOjo2poaJDf75ff71dzc7PC4fBVz3Z3d+uxxx6Tz+dTRUWFWlpadPHixYQODQCA25HNAAA3y5jIodbWVh06dEhtbW0aGBhQbW2tcnNztXr16nFn165dqxkzZmj37t3q7u5WTU2NsrOztWbNmoQPDwCAW5HNAAA3i/kT2VAopF27dqmurk5lZWVasGCBqqurtXPnznGv/F64cEHHjx/Xb37zG91+++26++679dOf/lSHDx++bt8AAABuQzYDANwuZpE9efKkgsGgfD5f5JrP51Nvb6/OnDkTddbj8Sg7O1tvvPGGRkZG1N3drXfffVd33nln4icHAMClyGYAgNvFLLLd3d3Kzs5WTk5O5JrX65UknT17NupsZmamNm3apDfffFPl5eWqqKiQ1+vVunXrEjw2AADuRTYDANwu5ntkg8Ggpk6dGnXt8uORkZFx50+dOqV58+ZpzZo16u3tVUNDg7Zu3ar6+vq4BsvLmx7XeYzn9ebEPoRrYofm2KE5dogrkc324vlsjh2aY4fm2OHki1lkPR7PuFC8/DgrKyvq+pEjR/TSSy/pnXfeibxKnJGRoTVr1ujRRx9Vfn7+hAc7d25A4bAz4fOI5vXmKBDon+wxrMYOzbFDc+zQTHp62g1ZvshmO/F8NscOzbFDc+zQTKKyOeatxUVFRRoaGtLg4GDkWiAQkCQVFhZGnf3ggw9UVFQUdavTHXfcobGxMX355ZfGwwIAALIZAICYRba0tFRZWVnq7OyMXDt69Kjy8/M1a9asqLOFhYX6/PPPNTQ0FLn2ySefSJJmzpyZqJkBAHA1shkA4HYxi6zH41FlZaUaGxt17NgxdXR0qKWlRcuXL5ck9fX1qb//0o/WFy1apLy8PNXW1qqrq0tHjx7Vpk2b9Itf/ELf+973ru93AgCAS5DNAAC3i/keWUmqqalRKBTSypUrlZmZqcrKSq1atUqSVFVVpeLiYjU1NWn69OnauXOnnnrqKT3wwAPKzs7Wfffdp8cff/y6fhMAALgN2QwAcLM0x3FS8lMb+EAJM7wJ3Rw7NMcOzbFDMzfqhz1NFrLZDM9nc+zQHDs0xw7NJO3DngAAAAAASCUUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrTKjIjo6OqqGhQX6/X36/X83NzQqHw1c9Ozg4qCeeeELz5s3T/PnztXnzZo2MjCR0aAAA3I5sBgC4WcZEDrW2turQoUNqa2vTwMCAamtrlZubq9WrV487W1dXp9OnT+vFF1/U8PCwqqurNWPGDFVVVSV8eAAA3IpsBgC4WcwiGwqFtGvXLj3zzDMqKyuTJFVXV6u5uVkrV65Uevo3P9Q9deqU9u/fr7/+9a8qKSmRJP32t7/VP/7xj+s0PgAA7kM2AwDcLuatxSdPnlQwGJTP54tc8/l86u3t1ZkzZ6LOdnR06NZbb40EpSQtW7ZM27dvT+DIAAC4G9kMAHC7mEW2u7tb2dnZysnJiVzzer2SpLNnz0ad/eyzzzRz5ky9+uqrWrJkiRYtWqTm5maNjo4meGwAANyLbAYAuF3MW4uDwaCmTp0ade3y4ys/KGJoaEjvv/++Ll68qKefflrnz5/Xxo0bdfHiRdXV1SVwbAAA3ItsBgC4Xcwi6/F4xoXi5cdZWVlR16dMmaJgMKht27ZpxowZkqSvv/5aGzdu1Pr166PesxNLXt70CZ/F1Xm9ObEP4ZrYoTl2aI4d4kpks714Pptjh+bYoTl2OPliFtmioiINDQ1pcHBQ06ZNkyQFAgFJUmFhYdTZgoIC5efnR4JSkm677TYNDw/r/Pnzys/Pn/Bg584NKBx2Jnwe0bzeHAUC/ZM9htXYoTl2aI4dmklPT7shyxfZbCeez+bYoTl2aI4dmklUNsd8Gba0tFRZWVnq7OyMXDt69Kjy8/M1a9asqLNz5sxRIBBQT09P5Nqnn36q6dOn66abbjIeFgAAkM0AAMQssh6PR5WVlWpsbNSxY8fU0dGhlpYWLV++XJLU19en/v5Lr0jMnz9fs2fPVk1NjT7++GN1dHTomWee0bJlyzRlypTr+50AAOASZDMAwO1i3losSTU1NQqFQlq5cqUyMzNVWVmpVatWSZKqqqpUXFyspqYmpaen64UXXtDmzZu1bNkyZWZm6v7779e6deuu6zcBAIDbkM0AADdLcxwnJd/swvtwzHDvvjl2aI4dmmOHZm7U98hOFrLZDM9nc+zQHDs0xw7NJO09sgAAAAAApBKKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtMqMiOjo6qoaFBfr9ffr9fzc3NCofDMb9u/fr1euihh4yHBAAA0chmAICbTajItra26tChQ2pra1Nra6v27NmjP//5z9f8moMHD2rv3r0JGRIAAEQjmwEAbhazyIZCIe3atUt1dXUqKyvTggULVF1drZ07d/7PV34vXLigP/zhD5ozZ07CBwYAwO3IZgCA28UssidPnlQwGJTP54tc8/l86u3t1ZkzZ676NVu2bNGSJUtUXl6esEEBAMAlZDMAwO1iFtnu7m5lZ2crJycncs3r9UqSzp49O+78gQMHdPz4ca1bty6BYwIAgMvIZgCA22XEOhAMBjV16tSoa5cfj4yMRF2/cOGCNm7cqObmZmVlZRkNlpc33ejrIXm9ObEP4ZrYoTl2aI4d4kpks714Pptjh+bYoTl2OPliFlmPxzMuFC8/vjIQGxsbtWjRIvn9fuPBzp0bUDjsGP8+buX15igQ6J/sMazGDs2xQ3Ps0Ex6etoNWb7IZjvxfDbHDs2xQ3Ps0EyisjlmkS0qKtLQ0JAGBwc1bdo0SVIgEJAkFRYWRp1tb2+Xx+NRe3u7pEv/a4CxsTHddddd2rdvn26++WbjgQEAcDuyGQDgdjGLbGlpqbKystTZ2amKigpJ0tGjR5Wfn69Zs2ZFnd2/f3/U47a2Nv373/9Wc3OzCgoKEjg2AADuRTYDANxuQrcWV1ZWqrGxUU1NTQqFQmppadHy5cslSX19fZoyZYpycnL0/e9/P+prc3Nz5fF4xl0HAADfHdkMAHC7mEVWkmpqahQKhbRy5UplZmaqsrJSq1atkiRVVVWpuLhYTU1N13VQAADwDbIZAOBmaY7jpOSnNvCBEmZ4E7o5dmiOHZpjh2Zu1A97mixksxmez+bYoTl2aI4dmklUNsf8/8gCAAAAAJBKKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsMqEiOzo6qoaGBvn9fvn9fjU3NyscDl/1bFdXl1asWCGfz6d77rlHTU1NGh4eTujQAAC4HdkMAHCzjIkcam1t1aFDh9TW1qaBgQHV1tYqNzdXq1evjjo3MDCgVatWad68edq9e7cCgYDq6+s1OjqqJ5988rp8AwAAuBHZDABws5g/kQ2FQtq1a5fq6upUVlamBQsWqLq6Wjt37hz3yu/hw4fV39+vxsZG3X777Zo/f77Wrl2r9vb26/YNAADgNmQzAMDtYhbZkydPKhgMyufzRa75fD719vbqzJkzUWfLysr03HPPaerUqZFraWlpGh0d/Z+3OwEAgPiQzQAAt4tZZLu7u5Wdna2cnJzINa/XK0k6e/Zs1NnCwkL5/f7I47GxMb388suaM2eO0tP5XCkAABKBbAYAuF3M98gGg8GoV3ElRR6PjIxc82s3b96sjz76SK+99lrcg+XlTY/7axDN682JfQjXxA7NsUNz7BBXIpvtxfPZHDs0xw7NscPJF7PIejyecaF4+XFWVtZVv2ZsbEybNm3S66+/rm3btqm0tDTuwc6dG1A47MT9dbjE681RINA/2WNYjR2aY4fm2KGZ9PS0G7J8kc124vlsjh2aY4fm2KGZRGVzzCJbVFSkoaEhDQ4Oatq0aZKkQCAg6dLtSlcaHR1VdXW1Dh48qGeffVaLFy82HhIAAHyDbAYAuF3MN8eUlpYqKytLnZ2dkWtHjx5Vfn6+Zs2aNe58fX293n77bT3//PMEJQAA1wHZDABwu5hF1uPxqLKyUo2NjTp27Jg6OjrU0tKi5cuXS5L6+vrU33/pR+sHDx7U3r17VVNTo5KSEgUCgcgvx+FWJAAAEoFsBgC4XcxbiyWppqZGoVBIK1euVGZmpiorK7Vq1SpJUlVVlYqLi9XU1KS//e1vki59kMTmzZujfo9jx45Fbn8CAABmyGYAgJulOSn6ciwfKGGGN6GbY4fm2KE5dmjmRv2wp8lCNpvh+WyOHZpjh+bYoZlEZTP/AzkAAAAAgFUosgAAAAAAq1BkAQAAAABWocgCAAAAAKxCkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArEKRBQAAAABYhSILAAAAALAKRRYAAAAAYBWKLAAAAADAKhRZAAAAAIBVKLIAAAAAAKtQZAEAAAAAVqHIAgAAAACsQpEFAAAAAFiFIgsAAAAAsApFFgAAAABgFYosAAAAAMAqFFkAAAAAgFUosgAAAAAAq1BkAQAAAABWmVCRHR0dVUNDg/x+v/x+v5qbmxUOh696tr+/X9XV1Zo7d64WLlyoHTt2JHRgAABANgMA3C1jIodaW1t16NAhtbW1aWBgQLW1tcrNzdXq1avHna2vr1dPT49eeeUVnT59Whs2bFBBQYGWLl2a8OEBAHArshkA4GYxi2woFNKuXbv0zDPPqKysTJJUXV2t5uZmrVy5Uunp3/xQ94svvtD+/fvV3t6ukpISlZaWqqurSzt27CAsAQBIELIZAOB2MW8tPnnypILBoHw+X+Saz+dTb2+vzpw5E3X2vffeU25urkpKSqLOnjhxQqFQKIFjAwDgXmQzAMDtYv5Etru7W9nZ2crJyYlc83q9kqSzZ8/q1ltvjTpbUFAQ9fVer1fhcFg9PT265ZZbJjxYenrahM/i6tihOXZojh2aY4ff3Y26O7LZXuzQHDs0xw7NscPvLlG7i1lkg8Ggpk6dGnXt8uORkZHvfDaWm26aFtd5jJeXN32yR7AeOzTHDs2xQ1yJbLYXz2dz7NAcOzTHDidfzFuLPR7PuKC7/DgrK+s7nwUAAN8N2QwAcLuYRbaoqEhDQ0MaHByMXAsEApKkwsLCcWcv/7fLenp6lJGRoby8vETMCwCA65HNAAC3i1lkS0tLlZWVpc7Ozsi1o0ePKj8/X7NmzYo6W15err6+Pp06dSpyrbOzU7Nnz1ZmZmYCxwYAwL3IZgCA203o1uLKyko1Njbq2LFj6ujoUEtLi5YvXy5J6uvrU39/vySpuLhY9957rzZs2KAPP/xQb731lrZv366HH374+n4XAAC4CNkMAHC7NMdxnFiHQqGQGhsbtW/fPmVmZqqyslKPP/640tLS9NBDD6m4uFhNTU2SLoXn73//e7399tv6v//7Pz3yyCP69a9/fb2/DwAAXIVsBgC42YSKLAAAAAAAqSLmrcUAAAAAAKQSiiwAAAAAwCoUWQAAAACAVZJeZEdHR9XQ0CC/3y+/36/m5maFw+Grnu3v71d1dbXmzp2rhQsXaseOHUmeNjXFs8Ouri6tWLFCPp9P99xzj5qamjQ8PJzkiVNTPHv8tvXr1+uhhx5KwoSpL54dDg4O6oknntC8efM0f/58bd68WSMjI0meOPXEs8Pu7m499thj8vl8qqioUEtLiy5evJjkiVPXyMiIli5dqoMHD/7PM+TK1ZHN5sjmxCCbzZHN5sjmxLme2ZyRqCEnqrW1VYcOHVJbW5sGBgZUW1ur3NxcrV69etzZ+vp69fT06JVXXtHp06e1YcMGFRQUaOnSpckeO6VMdIcDAwNatWqV5s2bp927dysQCKi+vl6jo6N68sknJ2n61BHP38XLDh48qL179+pHP/pREidNXfHssK6uTqdPn9aLL76o4eFhVVdXa8aMGaqqqpqEyVNHPDtcu3atZsyYod27d6u7u1s1NTXKzs7WmjVrJmHy1DI8PKx169apq6vrmufIlasjm82RzYlBNpsjm82RzYlx3bPZSaLh4WGnrKzMOXDgQOTaX/7yF+fuu+92xsbGos7+97//dX7wgx84H3/8ceTan/70J+f+++9P2rypKJ4dvvXWW87cuXOdUCgUubZ3717H5/Mlbd5UFc8eL+vr63MqKiqcZcuWOQ8++GCyRk1Z8eywq6vLKSkpiXo+79q1y3nkkUeSNm8qimeHfX19TklJiXP8+PHItaeeeoq/i47j/Otf/3KWLl3q/OxnP3NKSkqi9vlt5MrVkc3myObEIJvNkc3myObESEY2J/XW4pMnTyoYDMrn80Wu+Xw+9fb26syZM1Fn33vvPeXm5qqkpCTq7IkTJxQKhZI2c6qJZ4dlZWV67rnnNHXq1Mi1tLQ0jY6OTug2nRtZPHu8bMuWLVqyZInKy8uTNGVqi2eHHR0duvXWW6Oez8uWLdP27duTNm8qimeHHo9H2dnZeuONNzQyMqLu7m69++67uvPOO5M9dso5cuSIFi9erN27d1/zHLlydWSzObI5Mchmc2SzObI5MZKRzUktst3d3crOzlZOTk7kmtfrlSSdPXt23NmCgoKoa16vV+FwWD09Pdd/2BQVzw4LCwvl9/sjj8fGxvTyyy9rzpw5Sk939+d8xbNHSTpw4ICOHz+udevWJW3GVBfPDj/77DPNnDlTr776qpYsWaJFixapublZo6OjSZ051cSzw8zMTG3atElvvvmmysvLVVFRIa/Xy99JSStWrNC6devk8XiueY5cuTqy2RzZnBhkszmy2RzZnBjJyOakvkc2GAxGvQIpKfL4yjeWx3PWTUz2snnzZn300Ud67bXXrtt8tohnjxcuXNDGjRvV3NysrKyspM2Y6uLZ4dDQkN5//31dvHhRTz/9tM6fP6+NGzfq4sWLqqurS9rMqSbe5/OpU6c0b948rVmzRr29vWpoaNDWrVtVX1+flHltR65cHdlsjmxODLLZHNlsjmxOLpN/P5NaZD0ez7iBLj++8h+heM66yXfZy9jYmDZt2qTXX39d27ZtU2lp6XWfM9XFs8fGxkYtWrQo6hV0xLfDKVOmKBgMatu2bZoxY4Yk6euvv9bGjRu1fv161/4UIp4dHjlyRC+99JLeeeedyKvEGRkZWrNmjR599FHl5+cnZ2iLkStXRzabI5sTg2w2RzabI5uTyyRXklpki4qKNDQ0pMHBQU2bNk2SFAgEJF261ebKs5f/22U9PT3KyMhQXl5ecgZOQfHsULr08eHV1dU6ePCgnn32WS1evDip86aqePbY3t4uj8ej9vZ2SZd2OjY2prvuukv79u3TzTffnNzhU0Q8OywoKFB+fn4kKCXptttu0/DwsM6fP+/af+jj2eEHH3ygoqKiqFud7rjjDo2NjenLL7907Q7jQa5cHdlsjmxODLLZHNlsjmxOLpNcSepLLaWlpcrKylJnZ2fk2tGjR5Wfn69Zs2ZFnS0vL1dfX59OnToVudbZ2anZs2crMzMzaTOnmnh2KF36OOu3335bzz//PEH5LfHscf/+/Wpvb9eePXu0Z88e/fznP9cdd9yhPXv2jLun303i2eGcOXMUCASi3uvw6aefavr06brpppuSNnOqiWeHhYWF+vzzzzU0NBS59sknn0iSZs6cmZyBLUeuXB3ZbI5sTgyy2RzZbI5sTi6jXEnYZyxP0ObNm50f//jHTmdnp3P48GFnwYIFzgsvvOA4juN89dVXztdffx05++ijjzq//OUvnRMnTjh///vfnfLycmffvn3JHjnlTHSHBw4ccEpKSpyXX37Z6enpifoVDocn81tICfH8Xfy2pqYmPlb9/5voDsfGxpz777/f+dWvfuV89NFHzuHDh52Kigpn69atkzl+SpjoDvv7+52Kigrnd7/7nfPJJ584//znP5377rvPqaurm8zxU86VH/FPrkwM2WyObE4Mstkc2WyObE6s65XNSS+yw8PDzhNPPOHcddddzvz5853m5ubIP9wPPvigU1tbGzn71VdfOVVVVc4Pf/hDZ+HChc6OHTuSPW5KmugOa2pqnJKSkqv+GhgYmMxvISXE83fx2wjLb8Szw97eXmft2rVOeXm54/f7na1btzqjo6OTNXrKiGeH//nPf5zVq1c7Pp/PqaiocP74xz86w8PDkzV6SroyLMmViSGbzZHNiUE2myObzZHNiXW9sjnNcRznOv/EGAAAAACAhHHnx5EBAAAAAKxFkQUAAAAAWIUiCwAAAACwCkUWAAAAAGAViiwAAAAAwCoUWQAAAACAVSiyAAAAAACrUGQBAAAAAFahyAIAAAAArPL/AGTh3FbCiMR0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_legend_data = pd.concat([data['President'],FDR_data['President']], ignore_index = True)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "sns.kdeplot(full_data['Word Frequency'], hue = label_legend_data, fill=True, ax = axes[0,0])\n",
    "sns.kdeplot(full_data['Named Years'], hue = label_legend_data, fill=True, ax = axes[0,1])\n",
    "sns.kdeplot(full_data['Years from Wars'], hue = label_legend_data, fill=True, ax = axes[1,0])\n",
    "sns.kdeplot(full_data['Positivity Score'], hue = label_legend_data, fill=True, ax = axes[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA values in specified columns with mean of that column\n",
    "full_data['Named Years'].fillna(value=full_data['Named Years'].mean(), inplace=True)\n",
    "full_data['Years from Wars'].fillna(value=full_data['Years from Wars'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8fad96c79c87>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['President'][i] = p\n"
     ]
    }
   ],
   "source": [
    "full_data = normalize(full_data)\n",
    "full_data = reclassify_labels(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President</th>\n",
       "      <th>Word Frequency</th>\n",
       "      <th>Named Years</th>\n",
       "      <th>Years from Wars</th>\n",
       "      <th>Positivity Score</th>\n",
       "      <th>Sentence Length</th>\n",
       "      <th>Word Length</th>\n",
       "      <th>Syllables per word</th>\n",
       "      <th>Stop Word Proportion</th>\n",
       "      <th>No. of Words</th>\n",
       "      <th>...</th>\n",
       "      <th>Word PCA 0</th>\n",
       "      <th>Word PCA 1</th>\n",
       "      <th>Word PCA 2</th>\n",
       "      <th>Word PCA 3</th>\n",
       "      <th>Word PCA 4</th>\n",
       "      <th>Word PCA 5</th>\n",
       "      <th>Word PCA 6</th>\n",
       "      <th>Word PCA 7</th>\n",
       "      <th>Word PCA 8</th>\n",
       "      <th>Word PCA 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.226227</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.185863</td>\n",
       "      <td>0.593942</td>\n",
       "      <td>0.974121</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085753</td>\n",
       "      <td>0.087051</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>-0.014267</td>\n",
       "      <td>-0.013867</td>\n",
       "      <td>0.030950</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>-0.021599</td>\n",
       "      <td>0.031652</td>\n",
       "      <td>-0.041481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.178652</td>\n",
       "      <td>0.569682</td>\n",
       "      <td>0.945692</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172686</td>\n",
       "      <td>-0.030207</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>-0.007046</td>\n",
       "      <td>0.024474</td>\n",
       "      <td>0.094007</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>-0.021646</td>\n",
       "      <td>-0.047092</td>\n",
       "      <td>0.041281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.221519</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.192819</td>\n",
       "      <td>0.616493</td>\n",
       "      <td>0.955462</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128426</td>\n",
       "      <td>0.047951</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>-0.004287</td>\n",
       "      <td>0.043908</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>-0.028027</td>\n",
       "      <td>-0.021145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.183988</td>\n",
       "      <td>0.572344</td>\n",
       "      <td>0.981746</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077476</td>\n",
       "      <td>0.097694</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>-0.019156</td>\n",
       "      <td>-0.012518</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>-0.052478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.467767</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.517263</td>\n",
       "      <td>0.975943</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085808</td>\n",
       "      <td>0.035490</td>\n",
       "      <td>0.047982</td>\n",
       "      <td>0.092951</td>\n",
       "      <td>0.030454</td>\n",
       "      <td>-0.040639</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-0.185413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>0.112346</td>\n",
       "      <td>0.960726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.640665</td>\n",
       "      <td>0.886540</td>\n",
       "      <td>0.863390</td>\n",
       "      <td>0.506999</td>\n",
       "      <td>0.272335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336125</td>\n",
       "      <td>0.256133</td>\n",
       "      <td>0.144775</td>\n",
       "      <td>-0.047131</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>-0.263117</td>\n",
       "      <td>-0.018653</td>\n",
       "      <td>0.159192</td>\n",
       "      <td>-0.006051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>0.112455</td>\n",
       "      <td>0.959406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.793474</td>\n",
       "      <td>0.890021</td>\n",
       "      <td>0.877477</td>\n",
       "      <td>0.532694</td>\n",
       "      <td>0.294049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259077</td>\n",
       "      <td>0.196568</td>\n",
       "      <td>-0.009207</td>\n",
       "      <td>0.292715</td>\n",
       "      <td>0.261529</td>\n",
       "      <td>0.093024</td>\n",
       "      <td>-0.450455</td>\n",
       "      <td>-0.117023</td>\n",
       "      <td>-0.088524</td>\n",
       "      <td>0.042293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.884653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.656262</td>\n",
       "      <td>0.825702</td>\n",
       "      <td>0.801111</td>\n",
       "      <td>0.543672</td>\n",
       "      <td>0.092989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654524</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.027578</td>\n",
       "      <td>0.120390</td>\n",
       "      <td>-0.108808</td>\n",
       "      <td>0.143071</td>\n",
       "      <td>0.271369</td>\n",
       "      <td>0.200677</td>\n",
       "      <td>0.104165</td>\n",
       "      <td>0.073041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>0.146056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.912904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.489309</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137277</td>\n",
       "      <td>-0.055895</td>\n",
       "      <td>0.378949</td>\n",
       "      <td>0.042087</td>\n",
       "      <td>-0.037119</td>\n",
       "      <td>-0.027818</td>\n",
       "      <td>-0.626611</td>\n",
       "      <td>0.059051</td>\n",
       "      <td>0.148858</td>\n",
       "      <td>-0.098012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>0.091070</td>\n",
       "      <td>0.955198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520755</td>\n",
       "      <td>0.695052</td>\n",
       "      <td>0.888543</td>\n",
       "      <td>0.886164</td>\n",
       "      <td>0.529753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.089983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.555745</td>\n",
       "      <td>0.182301</td>\n",
       "      <td>-0.087417</td>\n",
       "      <td>0.038680</td>\n",
       "      <td>0.036420</td>\n",
       "      <td>-0.014417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   President  Word Frequency  Named Years  Years from Wars  Positivity Score  \\\n",
       "0          0        0.226227     0.995087         0.986486          0.875000   \n",
       "1          0        0.416667     0.995087         0.986486          1.000000   \n",
       "2          0        0.221519     0.995087         0.986486          0.761905   \n",
       "3          0        0.217563     0.995087         0.986486          0.800000   \n",
       "4          0        0.467767     0.995087         0.986486          0.740000   \n",
       "..       ...             ...          ...              ...               ...   \n",
       "84         2        0.112346     0.960726              NaN          0.576923   \n",
       "85         2        0.112455     0.959406              NaN          0.588235   \n",
       "86         2        0.152941     0.884653              NaN          0.500000   \n",
       "87         2        0.146056          NaN              NaN          0.571429   \n",
       "88         2        0.091070     0.955198              NaN          0.520755   \n",
       "\n",
       "    Sentence Length  Word Length  Syllables per word  Stop Word Proportion  \\\n",
       "0          0.004757     0.185863            0.593942              0.974121   \n",
       "1          0.008659     0.178652            0.569682              0.945692   \n",
       "2          0.003215     0.192819            0.616493              0.955462   \n",
       "3          0.002789     0.183988            0.572344              0.981746   \n",
       "4          0.002326     0.169697            0.517263              0.975943   \n",
       "..              ...          ...                 ...                   ...   \n",
       "84         0.640665     0.886540            0.863390              0.506999   \n",
       "85         0.793474     0.890021            0.877477              0.532694   \n",
       "86         0.656262     0.825702            0.801111              0.543672   \n",
       "87         0.912904     1.000000            1.000000              0.489309   \n",
       "88         0.695052     0.888543            0.886164              0.529753   \n",
       "\n",
       "    No. of Words  ...  Word PCA 0  Word PCA 1  Word PCA 2  Word PCA 3  \\\n",
       "0       0.000026  ...   -0.085753    0.087051    0.019717   -0.014267   \n",
       "1       0.000008  ...   -0.172686   -0.030207   -0.016161   -0.007046   \n",
       "2       0.000015  ...   -0.128426    0.047951    0.004629   -0.008264   \n",
       "3       0.000026  ...   -0.077476    0.097694    0.014766   -0.019156   \n",
       "4       0.000026  ...   -0.085808    0.035490    0.047982    0.092951   \n",
       "..           ...  ...         ...         ...         ...         ...   \n",
       "84      0.272335  ...   -0.336125    0.256133    0.144775   -0.047131   \n",
       "85      0.294049  ...   -0.259077    0.196568   -0.009207    0.292715   \n",
       "86      0.092989  ...   -0.654524    0.119205    0.027578    0.120390   \n",
       "87      0.333333  ...   -0.137277   -0.055895    0.378949    0.042087   \n",
       "88      1.000000  ...    1.000000   -0.089983    1.000000    1.000000   \n",
       "\n",
       "    Word PCA 4  Word PCA 5  Word PCA 6  Word PCA 7  Word PCA 8  Word PCA 9  \n",
       "0    -0.013867    0.030950    0.001417   -0.021599    0.031652   -0.041481  \n",
       "1     0.024474    0.094007    0.022549   -0.021646   -0.047092    0.041281  \n",
       "2    -0.004287    0.043908    0.014492   -0.011607   -0.028027   -0.021145  \n",
       "3    -0.012518   -0.008923    0.017657    0.043055   -0.001343   -0.052478  \n",
       "4     0.030454   -0.040639   -0.009228   -0.023747    0.000379   -0.185413  \n",
       "..         ...         ...         ...         ...         ...         ...  \n",
       "84    0.023419    0.001030   -0.263117   -0.018653    0.159192   -0.006051  \n",
       "85    0.261529    0.093024   -0.450455   -0.117023   -0.088524    0.042293  \n",
       "86   -0.108808    0.143071    0.271369    0.200677    0.104165    0.073041  \n",
       "87   -0.037119   -0.027818   -0.626611    0.059051    0.148858   -0.098012  \n",
       "88   -0.555745    0.182301   -0.087417    0.038680    0.036420   -0.014417  \n",
       "\n",
       "[89 rows x 22 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the Features from the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word Frequency</th>\n",
       "      <th>Named Years</th>\n",
       "      <th>Years from Wars</th>\n",
       "      <th>Positivity Score</th>\n",
       "      <th>Sentence Length</th>\n",
       "      <th>Word Length</th>\n",
       "      <th>Syllables per word</th>\n",
       "      <th>Stop Word Proportion</th>\n",
       "      <th>No. of Words</th>\n",
       "      <th>No. of Sentences</th>\n",
       "      <th>...</th>\n",
       "      <th>Word PCA 0</th>\n",
       "      <th>Word PCA 1</th>\n",
       "      <th>Word PCA 2</th>\n",
       "      <th>Word PCA 3</th>\n",
       "      <th>Word PCA 4</th>\n",
       "      <th>Word PCA 5</th>\n",
       "      <th>Word PCA 6</th>\n",
       "      <th>Word PCA 7</th>\n",
       "      <th>Word PCA 8</th>\n",
       "      <th>Word PCA 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.226227</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.185863</td>\n",
       "      <td>0.593942</td>\n",
       "      <td>0.974121</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085753</td>\n",
       "      <td>0.087051</td>\n",
       "      <td>0.019717</td>\n",
       "      <td>-0.014267</td>\n",
       "      <td>-0.013867</td>\n",
       "      <td>0.030950</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>-0.021599</td>\n",
       "      <td>0.031652</td>\n",
       "      <td>-0.041481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.178652</td>\n",
       "      <td>0.569682</td>\n",
       "      <td>0.945692</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172686</td>\n",
       "      <td>-0.030207</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>-0.007046</td>\n",
       "      <td>0.024474</td>\n",
       "      <td>0.094007</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>-0.021646</td>\n",
       "      <td>-0.047092</td>\n",
       "      <td>0.041281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.221519</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.192819</td>\n",
       "      <td>0.616493</td>\n",
       "      <td>0.955462</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128426</td>\n",
       "      <td>0.047951</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>-0.004287</td>\n",
       "      <td>0.043908</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>-0.028027</td>\n",
       "      <td>-0.021145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.183988</td>\n",
       "      <td>0.572344</td>\n",
       "      <td>0.981746</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077476</td>\n",
       "      <td>0.097694</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>-0.019156</td>\n",
       "      <td>-0.012518</td>\n",
       "      <td>-0.008923</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>-0.052478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467767</td>\n",
       "      <td>0.995087</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.517263</td>\n",
       "      <td>0.975943</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085808</td>\n",
       "      <td>0.035490</td>\n",
       "      <td>0.047982</td>\n",
       "      <td>0.092951</td>\n",
       "      <td>0.030454</td>\n",
       "      <td>-0.040639</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>-0.023747</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-0.185413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word Frequency  Named Years  Years from Wars  Positivity Score  \\\n",
       "0        0.226227     0.995087         0.986486          0.875000   \n",
       "1        0.416667     0.995087         0.986486          1.000000   \n",
       "2        0.221519     0.995087         0.986486          0.761905   \n",
       "3        0.217563     0.995087         0.986486          0.800000   \n",
       "4        0.467767     0.995087         0.986486          0.740000   \n",
       "\n",
       "   Sentence Length  Word Length  Syllables per word  Stop Word Proportion  \\\n",
       "0         0.004757     0.185863            0.593942              0.974121   \n",
       "1         0.008659     0.178652            0.569682              0.945692   \n",
       "2         0.003215     0.192819            0.616493              0.955462   \n",
       "3         0.002789     0.183988            0.572344              0.981746   \n",
       "4         0.002326     0.169697            0.517263              0.975943   \n",
       "\n",
       "   No. of Words  No. of Sentences  ...  Word PCA 0  Word PCA 1  Word PCA 2  \\\n",
       "0      0.000026          0.000116  ...   -0.085753    0.087051    0.019717   \n",
       "1      0.000008          0.000019  ...   -0.172686   -0.030207   -0.016161   \n",
       "2      0.000015          0.000101  ...   -0.128426    0.047951    0.004629   \n",
       "3      0.000026          0.000193  ...   -0.077476    0.097694    0.014766   \n",
       "4      0.000026          0.000231  ...   -0.085808    0.035490    0.047982   \n",
       "\n",
       "   Word PCA 3  Word PCA 4  Word PCA 5  Word PCA 6  Word PCA 7  Word PCA 8  \\\n",
       "0   -0.014267   -0.013867    0.030950    0.001417   -0.021599    0.031652   \n",
       "1   -0.007046    0.024474    0.094007    0.022549   -0.021646   -0.047092   \n",
       "2   -0.008264   -0.004287    0.043908    0.014492   -0.011607   -0.028027   \n",
       "3   -0.019156   -0.012518   -0.008923    0.017657    0.043055   -0.001343   \n",
       "4    0.092951    0.030454   -0.040639   -0.009228   -0.023747    0.000379   \n",
       "\n",
       "   Word PCA 9  \n",
       "0   -0.041481  \n",
       "1    0.041281  \n",
       "2   -0.021145  \n",
       "3   -0.052478  \n",
       "4   -0.185413  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = full_data.drop(columns = 'President')\n",
    "labels = full_data['President'].astype(int)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data into Testing and Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, train_size = 0.75, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass Full Data to Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same classifiers that we found above, we can re-fit the model to the new data and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 160, in fit\n",
      "    X, y = self._validate_data(X, y, dtype=np.float64,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 432, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 795, in check_X_y\n",
      "    X = check_array(X, accept_sparse=accept_sparse,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n",
      "    _assert_all_finite(array,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n",
      "    raise ValueError(\n",
      "ValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-25eebe0d5d70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             X, y = self._validate_data(X, y, dtype=np.float64,\n\u001b[0m\u001b[0;32m    161\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                                        accept_large_sparse=False)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "clf = clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = clf.predict(test_features)\n",
    "# Once again, creating a confusion matrix and classification report\n",
    "conf_mat = confusion_matrix(test_labels, pred_labels)\n",
    "class_rep = classification_report(test_labels, pred_labels)\n",
    "# Formatting the confusion matrixCand classification report in the same way as before\n",
    "preslist = ['Washington ','Trump ','Roosevelt ']\n",
    "replacelist = [' '*(len(preslist[i])-2)+f'{i} ' for i in range(len(preslist))]\n",
    "class_rep = mreplace(class_rep,replacelist,preslist,max=1)\n",
    "cols = pd.MultiIndex.from_product([['Predicted Speaker'],preslist])\n",
    "rows = pd.MultiIndex.from_product([['Actual Speaker'],preslist])\n",
    "print(class_rep)\n",
    "pd.DataFrame(conf_mat,index=rows,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-d0a9a098b939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreslist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\School\\CMSE 202\\Group Project\\Confusion_Image.ipynb\u001b[0m in \u001b[0;36mconfusion_image\u001b[1;34m(trained_estimator, test_data, test_labels, preslist)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \"\"\"\n\u001b[0;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             raise NotFittedError(\"predict_proba is not available when fitted \"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "confusion_image(clf,test_features,test_labels,preslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find repository of random presidential speeches and send through model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautify notebook (confusion matrix)\n",
    "# Add graphs\n",
    "# Correlation matrix\n",
    "# Annotate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "     ..\n",
       "84    0\n",
       "85    0\n",
       "86    0\n",
       "87    0\n",
       "88    0\n",
       "Name: President, Length: 89, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col20{\n",
       "            background-color:  #d63c64;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col1{\n",
       "            background-color:  #eba1b4;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col3{\n",
       "            background-color:  #f2c4d0;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col3{\n",
       "            background-color:  #f2c0cd;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col2{\n",
       "            background-color:  #d53d69;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col17{\n",
       "            background-color:  #d6416d;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col7{\n",
       "            background-color:  #e5839c;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col20{\n",
       "            background-color:  #d6426e;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col11{\n",
       "            background-color:  #d6436f;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col6{\n",
       "            background-color:  #d53f6c;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col11{\n",
       "            background-color:  #ea9db4;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col12{\n",
       "            background-color:  #f1bccc;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col14{\n",
       "            background-color:  #f7dce4;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col15{\n",
       "            background-color:  #f8e1e8;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col20{\n",
       "            background-color:  #f9e2e9;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col18{\n",
       "            background-color:  #f5d0da;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col18{\n",
       "            background-color:  #f4cbd7;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col18{\n",
       "            background-color:  #f4ced9;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col13{\n",
       "            background-color:  #f3c9d6;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col2{\n",
       "            background-color:  #ea9eb2;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col0{\n",
       "            background-color:  #e27894;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col7{\n",
       "            background-color:  #d9527a;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col15{\n",
       "            background-color:  #d95079;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col12{\n",
       "            background-color:  #d53e6a;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col13{\n",
       "            background-color:  #f7d9e2;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col18{\n",
       "            background-color:  #f7dae3;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col19{\n",
       "            background-color:  #f2f2f2;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col18{\n",
       "            background-color:  #fae9ed;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col15{\n",
       "            background-color:  #f6d6e0;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col19{\n",
       "            background-color:  #f6d5df;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col18{\n",
       "            background-color:  #f2c4d2;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col20{\n",
       "            background-color:  #eeb2c3;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col0{\n",
       "            background-color:  #f5ced8;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col11{\n",
       "            background-color:  #eca7b9;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col16{\n",
       "            background-color:  #db587f;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col18{\n",
       "            background-color:  #da537b;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col19{\n",
       "            background-color:  #da577e;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col7{\n",
       "            background-color:  #f0b7c6;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col5{\n",
       "            background-color:  #e585a1;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col12{\n",
       "            background-color:  #eca7bc;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col12{\n",
       "            background-color:  #f5d2db;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col15{\n",
       "            background-color:  #f5d1dc;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col14{\n",
       "            background-color:  #f5d2dd;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col2{\n",
       "            background-color:  #f6d8e1;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col20{\n",
       "            background-color:  #e587a2;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col1{\n",
       "            background-color:  #f7d9e1;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col15{\n",
       "            background-color:  #fae9ee;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col19{\n",
       "            background-color:  #d84c75;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col20,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col16{\n",
       "            background-color:  #d64570;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col7{\n",
       "            background-color:  #f0b8c7;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col1{\n",
       "            background-color:  #da567d;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col13{\n",
       "            background-color:  #e999b1;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col12{\n",
       "            background-color:  #f2c1cf;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col8{\n",
       "            background-color:  #e68ba6;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col14{\n",
       "            background-color:  #eeb3c4;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col2{\n",
       "            background-color:  #edaabe;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col10{\n",
       "            background-color:  #eba1b7;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col17{\n",
       "            background-color:  #efb4c6;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col19{\n",
       "            background-color:  #efb6c7;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col20{\n",
       "            background-color:  #eeb0c2;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col12{\n",
       "            background-color:  #df6d8f;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col2{\n",
       "            background-color:  #df6c8e;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col3{\n",
       "            background-color:  #eaa0b6;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col4{\n",
       "            background-color:  #d63f66;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col5{\n",
       "            background-color:  #d74067;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col8{\n",
       "            background-color:  #dc587a;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col5{\n",
       "            background-color:  #dd6080;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col4{\n",
       "            background-color:  #d8486e;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col20{\n",
       "            background-color:  #fae6ec;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col20{\n",
       "            background-color:  #e07192;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col20{\n",
       "            background-color:  #ea9fb5;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col8{\n",
       "            background-color:  #d63e65;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col4{\n",
       "            background-color:  #dc5c7d;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col9{\n",
       "            background-color:  #dd5d7e;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col13{\n",
       "            background-color:  #f9e5eb;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col12{\n",
       "            background-color:  #f9e0e7;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col15{\n",
       "            background-color:  #fae7ed;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col2{\n",
       "            background-color:  #e998b0;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col3{\n",
       "            background-color:  #eca9bd;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col9{\n",
       "            background-color:  #dd5e7f;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col6{\n",
       "            background-color:  #d8476d;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col1{\n",
       "            background-color:  #e16f8d;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col2{\n",
       "            background-color:  #ea9db1;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col3{\n",
       "            background-color:  #e999ae;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col15{\n",
       "            background-color:  #db5c81;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col7{\n",
       "            background-color:  #db5b80;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col14{\n",
       "            background-color:  #dd6186;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col3{\n",
       "            background-color:  #e894ac;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col10{\n",
       "            background-color:  #dd6181;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col10{\n",
       "            background-color:  #de6585;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col1{\n",
       "            background-color:  #dc6085;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col2{\n",
       "            background-color:  #de698b;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col15{\n",
       "            background-color:  #e78fa9;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col8{\n",
       "            background-color:  #de6282;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col6{\n",
       "            background-color:  #de6483;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col11{\n",
       "            background-color:  #edabbc;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col12{\n",
       "            background-color:  #f9e2e8;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col19{\n",
       "            background-color:  #e07091;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col7{\n",
       "            background-color:  #df6a8c;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col11{\n",
       "            background-color:  #f8dfe7;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col17{\n",
       "            background-color:  #fae7ec;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col18{\n",
       "            background-color:  #f9e3ea;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col20{\n",
       "            background-color:  #faeaef;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col13{\n",
       "            background-color:  #e589a5;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col14{\n",
       "            background-color:  #e17796;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col15{\n",
       "            background-color:  #e17494;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col7{\n",
       "            background-color:  #e895ad;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col8{\n",
       "            background-color:  #f6d5dd;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col9{\n",
       "            background-color:  #f7dae2;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col18{\n",
       "            background-color:  #e37e9c;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col15{\n",
       "            background-color:  #e27897;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col2{\n",
       "            background-color:  #e07293;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col18,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col6{\n",
       "            background-color:  #e483a0;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col19{\n",
       "            background-color:  #e4829f;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col13,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col8{\n",
       "            background-color:  #d94f78;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col3{\n",
       "            background-color:  #e17595;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col6{\n",
       "            background-color:  #e588a4;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col0,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col6,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col10{\n",
       "            background-color:  #d74772;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col7{\n",
       "            background-color:  #e68ca7;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col9{\n",
       "            background-color:  #e99cb3;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col15,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col3{\n",
       "            background-color:  #dd6387;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col2,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col16{\n",
       "            background-color:  #e27a99;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col19,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col1,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col18{\n",
       "            background-color:  #da547c;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col8,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col14{\n",
       "            background-color:  #de6589;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col11,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col10{\n",
       "            background-color:  #e3819e;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col7,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col19{\n",
       "            background-color:  #dc5f84;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col16,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col5,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col14,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col16{\n",
       "            background-color:  #de678a;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col17{\n",
       "            background-color:  #d84a74;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col17,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col0{\n",
       "            background-color:  #e37d9b;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col1{\n",
       "            background-color:  #e790aa;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col3,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col4,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col5{\n",
       "            background-color:  #d74671;\n",
       "            color:  #f1f1f1;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col0{\n",
       "            background-color:  #df6e90;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col10,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col0{\n",
       "            background-color:  #dc5d83;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col9,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col17{\n",
       "            background-color:  #e27b9a;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col11{\n",
       "            background-color:  #d74973;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col12,#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col20{\n",
       "            background-color:  #d84e76;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col9{\n",
       "            background-color:  #e792ab;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }#T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col19{\n",
       "            background-color:  #e37f9d;\n",
       "            color:  #000000;\n",
       "            max-width:  100px;\n",
       "            font-size:  12pt;\n",
       "        }</style><table id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Word Frequency</th>        <th class=\"col_heading level0 col1\" >Named Years</th>        <th class=\"col_heading level0 col2\" >Years from Wars</th>        <th class=\"col_heading level0 col3\" >Positivity Score</th>        <th class=\"col_heading level0 col4\" >Sentence Length</th>        <th class=\"col_heading level0 col5\" >Word Length</th>        <th class=\"col_heading level0 col6\" >Syllables per word</th>        <th class=\"col_heading level0 col7\" >Stop Word Proportion</th>        <th class=\"col_heading level0 col8\" >No. of Words</th>        <th class=\"col_heading level0 col9\" >No. of Sentences</th>        <th class=\"col_heading level0 col10\" >Reading Level</th>        <th class=\"col_heading level0 col11\" >Word PCA 0</th>        <th class=\"col_heading level0 col12\" >Word PCA 1</th>        <th class=\"col_heading level0 col13\" >Word PCA 2</th>        <th class=\"col_heading level0 col14\" >Word PCA 3</th>        <th class=\"col_heading level0 col15\" >Word PCA 4</th>        <th class=\"col_heading level0 col16\" >Word PCA 5</th>        <th class=\"col_heading level0 col17\" >Word PCA 6</th>        <th class=\"col_heading level0 col18\" >Word PCA 7</th>        <th class=\"col_heading level0 col19\" >Word PCA 8</th>        <th class=\"col_heading level0 col20\" >Word PCA 9</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row0\" class=\"row_heading level0 row0\" >Word Frequency</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col1\" class=\"data row0 col1\" >0.528756</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col2\" class=\"data row0 col2\" >0.367182</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col3\" class=\"data row0 col3\" >0.391243</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col4\" class=\"data row0 col4\" >-0.691092</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col5\" class=\"data row0 col5\" >-0.687266</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col6\" class=\"data row0 col6\" >-0.670345</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col7\" class=\"data row0 col7\" >0.668324</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col8\" class=\"data row0 col8\" >-0.658510</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col9\" class=\"data row0 col9\" >-0.654720</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col10\" class=\"data row0 col10\" >-0.676768</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col11\" class=\"data row0 col11\" >-0.238422</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col12\" class=\"data row0 col12\" >-0.095587</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col13\" class=\"data row0 col13\" >0.049517</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col14\" class=\"data row0 col14\" >0.050142</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col15\" class=\"data row0 col15\" >0.071031</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col16\" class=\"data row0 col16\" >0.078651</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col17\" class=\"data row0 col17\" >-0.009260</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col18\" class=\"data row0 col18\" >-0.025746</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col19\" class=\"data row0 col19\" >-0.010917</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row0_col20\" class=\"data row0 col20\" >-0.035565</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row1\" class=\"row_heading level0 row1\" >Named Years</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col0\" class=\"data row1 col0\" >0.528756</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col2\" class=\"data row1 col2\" >0.531610</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col3\" class=\"data row1 col3\" >0.358720</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col4\" class=\"data row1 col4\" >-0.704870</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col5\" class=\"data row1 col5\" >-0.723512</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col6\" class=\"data row1 col6\" >-0.703268</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col7\" class=\"data row1 col7\" >0.715214</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col8\" class=\"data row1 col8\" >-0.619217</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col9\" class=\"data row1 col9\" >-0.623238</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col10\" class=\"data row1 col10\" >-0.710829</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col11\" class=\"data row1 col11\" >0.022213</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col12\" class=\"data row1 col12\" >-0.055404</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col13\" class=\"data row1 col13\" >0.030073</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col14\" class=\"data row1 col14\" >0.108705</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col15\" class=\"data row1 col15\" >0.180105</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col16\" class=\"data row1 col16\" >0.005322</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col17\" class=\"data row1 col17\" >-0.002986</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col18\" class=\"data row1 col18\" >-0.079250</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col19\" class=\"data row1 col19\" >0.132054</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row1_col20\" class=\"data row1 col20\" >-0.165593</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row2\" class=\"row_heading level0 row2\" >Years from Wars</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col0\" class=\"data row2 col0\" >0.367182</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col1\" class=\"data row2 col1\" >0.531610</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col3\" class=\"data row2 col3\" >0.218210</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col4\" class=\"data row2 col4\" >-0.455241</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col5\" class=\"data row2 col5\" >-0.476548</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col6\" class=\"data row2 col6\" >-0.462356</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col7\" class=\"data row2 col7\" >0.467046</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col8\" class=\"data row2 col8\" >-0.564301</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col9\" class=\"data row2 col9\" >-0.581039</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col10\" class=\"data row2 col10\" >-0.462979</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col11\" class=\"data row2 col11\" >-0.264926</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col12\" class=\"data row2 col12\" >-0.115825</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col13\" class=\"data row2 col13\" >0.034084</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col14\" class=\"data row2 col14\" >0.350981</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col15\" class=\"data row2 col15\" >0.062960</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col16\" class=\"data row2 col16\" >0.071707</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col17\" class=\"data row2 col17\" >0.053381</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col18\" class=\"data row2 col18\" >0.246697</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col19\" class=\"data row2 col19\" >0.092601</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row2_col20\" class=\"data row2 col20\" >-0.257534</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row3\" class=\"row_heading level0 row3\" >Positivity Score</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col0\" class=\"data row3 col0\" >0.391243</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col1\" class=\"data row3 col1\" >0.358720</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col2\" class=\"data row3 col2\" >0.218210</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col4\" class=\"data row3 col4\" >-0.420111</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col5\" class=\"data row3 col5\" >-0.446709</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col6\" class=\"data row3 col6\" >-0.373014</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col7\" class=\"data row3 col7\" >0.492408</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col8\" class=\"data row3 col8\" >-0.375194</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col9\" class=\"data row3 col9\" >-0.394146</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col10\" class=\"data row3 col10\" >-0.484027</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col11\" class=\"data row3 col11\" >-0.104614</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col12\" class=\"data row3 col12\" >0.058740</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col13\" class=\"data row3 col13\" >-0.161022</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col14\" class=\"data row3 col14\" >0.001142</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col15\" class=\"data row3 col15\" >-0.036749</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col16\" class=\"data row3 col16\" >-0.068429</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col17\" class=\"data row3 col17\" >0.005006</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col18\" class=\"data row3 col18\" >0.113368</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col19\" class=\"data row3 col19\" >0.014378</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row3_col20\" class=\"data row3 col20\" >-0.011706</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row4\" class=\"row_heading level0 row4\" >Sentence Length</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col0\" class=\"data row4 col0\" >-0.691092</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col1\" class=\"data row4 col1\" >-0.704870</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col2\" class=\"data row4 col2\" >-0.455241</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col3\" class=\"data row4 col3\" >-0.420111</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col5\" class=\"data row4 col5\" >0.979316</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col6\" class=\"data row4 col6\" >0.971127</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col7\" class=\"data row4 col7\" >-0.957496</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col8\" class=\"data row4 col8\" >0.840644</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col9\" class=\"data row4 col9\" >0.806906</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col10\" class=\"data row4 col10\" >0.927658</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col11\" class=\"data row4 col11\" >0.002405</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col12\" class=\"data row4 col12\" >0.053656</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col13\" class=\"data row4 col13\" >-0.064439</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col14\" class=\"data row4 col14\" >0.016405</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col15\" class=\"data row4 col15\" >-0.040427</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col16\" class=\"data row4 col16\" >0.023291</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col17\" class=\"data row4 col17\" >-0.045115</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col18\" class=\"data row4 col18\" >0.029307</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col19\" class=\"data row4 col19\" >-0.012457</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row4_col20\" class=\"data row4 col20\" >-0.030105</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row5\" class=\"row_heading level0 row5\" >Word Length</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col0\" class=\"data row5 col0\" >-0.687266</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col1\" class=\"data row5 col1\" >-0.723512</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col2\" class=\"data row5 col2\" >-0.476548</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col3\" class=\"data row5 col3\" >-0.446709</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col4\" class=\"data row5 col4\" >0.979316</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col6\" class=\"data row5 col6\" >0.986740</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col7\" class=\"data row5 col7\" >-0.980764</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col8\" class=\"data row5 col8\" >0.823693</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col9\" class=\"data row5 col9\" >0.817209</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col10\" class=\"data row5 col10\" >0.971305</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col11\" class=\"data row5 col11\" >-0.061424</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col12\" class=\"data row5 col12\" >0.108525</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col13\" class=\"data row5 col13\" >-0.015806</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col14\" class=\"data row5 col14\" >0.000334</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col15\" class=\"data row5 col15\" >-0.048774</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col16\" class=\"data row5 col16\" >0.002367</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col17\" class=\"data row5 col17\" >0.004162</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col18\" class=\"data row5 col18\" >-0.015282</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col19\" class=\"data row5 col19\" >-0.014035</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row5_col20\" class=\"data row5 col20\" >-0.003120</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row6\" class=\"row_heading level0 row6\" >Syllables per word</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col0\" class=\"data row6 col0\" >-0.670345</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col1\" class=\"data row6 col1\" >-0.703268</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col2\" class=\"data row6 col2\" >-0.462356</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col3\" class=\"data row6 col3\" >-0.373014</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col4\" class=\"data row6 col4\" >0.971127</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col5\" class=\"data row6 col5\" >0.986740</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col7\" class=\"data row6 col7\" >-0.959417</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col8\" class=\"data row6 col8\" >0.814862</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col9\" class=\"data row6 col9\" >0.801354</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col10\" class=\"data row6 col10\" >0.935222</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col11\" class=\"data row6 col11\" >-0.069566</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col12\" class=\"data row6 col12\" >0.116068</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col13\" class=\"data row6 col13\" >-0.047119</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col14\" class=\"data row6 col14\" >0.007980</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col15\" class=\"data row6 col15\" >-0.066471</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col16\" class=\"data row6 col16\" >-0.002113</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col17\" class=\"data row6 col17\" >0.002745</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col18\" class=\"data row6 col18\" >-0.006117</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col19\" class=\"data row6 col19\" >-0.010431</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row6_col20\" class=\"data row6 col20\" >-0.010980</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row7\" class=\"row_heading level0 row7\" >Stop Word Proportion</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col0\" class=\"data row7 col0\" >0.668324</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col1\" class=\"data row7 col1\" >0.715214</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col2\" class=\"data row7 col2\" >0.467046</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col3\" class=\"data row7 col3\" >0.492408</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col4\" class=\"data row7 col4\" >-0.957496</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col5\" class=\"data row7 col5\" >-0.980764</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col6\" class=\"data row7 col6\" >-0.959417</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col8\" class=\"data row7 col8\" >-0.809312</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col9\" class=\"data row7 col9\" >-0.804591</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col10\" class=\"data row7 col10\" >-0.957525</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col11\" class=\"data row7 col11\" >0.043318</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col12\" class=\"data row7 col12\" >-0.078368</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col13\" class=\"data row7 col13\" >0.037702</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col14\" class=\"data row7 col14\" >0.008498</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col15\" class=\"data row7 col15\" >0.046575</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col16\" class=\"data row7 col16\" >-0.010471</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col17\" class=\"data row7 col17\" >-0.006862</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col18\" class=\"data row7 col18\" >0.006719</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col19\" class=\"data row7 col19\" >0.016518</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row7_col20\" class=\"data row7 col20\" >0.020400</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row8\" class=\"row_heading level0 row8\" >No. of Words</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col0\" class=\"data row8 col0\" >-0.658510</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col1\" class=\"data row8 col1\" >-0.619217</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col2\" class=\"data row8 col2\" >-0.564301</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col3\" class=\"data row8 col3\" >-0.375194</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col4\" class=\"data row8 col4\" >0.840644</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col5\" class=\"data row8 col5\" >0.823693</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col6\" class=\"data row8 col6\" >0.814862</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col7\" class=\"data row8 col7\" >-0.809312</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col9\" class=\"data row8 col9\" >0.986876</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col10\" class=\"data row8 col10\" >0.792948</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col11\" class=\"data row8 col11\" >0.469218</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col12\" class=\"data row8 col12\" >0.128744</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col13\" class=\"data row8 col13\" >-0.027094</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col14\" class=\"data row8 col14\" >-0.045047</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col15\" class=\"data row8 col15\" >-0.032011</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col16\" class=\"data row8 col16\" >-0.018422</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col17\" class=\"data row8 col17\" >0.032255</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col18\" class=\"data row8 col18\" >-0.024625</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col19\" class=\"data row8 col19\" >-0.043820</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row8_col20\" class=\"data row8 col20\" >0.015584</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row9\" class=\"row_heading level0 row9\" >No. of Sentences</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col0\" class=\"data row9 col0\" >-0.654720</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col1\" class=\"data row9 col1\" >-0.623238</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col2\" class=\"data row9 col2\" >-0.581039</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col3\" class=\"data row9 col3\" >-0.394146</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col4\" class=\"data row9 col4\" >0.806906</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col5\" class=\"data row9 col5\" >0.817209</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col6\" class=\"data row9 col6\" >0.801354</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col7\" class=\"data row9 col7\" >-0.804591</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col8\" class=\"data row9 col8\" >0.986876</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col9\" class=\"data row9 col9\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col10\" class=\"data row9 col10\" >0.812229</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col11\" class=\"data row9 col11\" >0.448731</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col12\" class=\"data row9 col12\" >0.180274</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col13\" class=\"data row9 col13\" >0.029350</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col14\" class=\"data row9 col14\" >-0.061031</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col15\" class=\"data row9 col15\" >-0.040712</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col16\" class=\"data row9 col16\" >-0.049566</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col17\" class=\"data row9 col17\" >0.081167</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col18\" class=\"data row9 col18\" >-0.082403</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col19\" class=\"data row9 col19\" >-0.045089</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row9_col20\" class=\"data row9 col20\" >0.039649</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row10\" class=\"row_heading level0 row10\" >Reading Level</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col0\" class=\"data row10 col0\" >-0.676768</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col1\" class=\"data row10 col1\" >-0.710829</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col2\" class=\"data row10 col2\" >-0.462979</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col3\" class=\"data row10 col3\" >-0.484027</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col4\" class=\"data row10 col4\" >0.927658</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col5\" class=\"data row10 col5\" >0.971305</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col6\" class=\"data row10 col6\" >0.935222</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col7\" class=\"data row10 col7\" >-0.957525</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col8\" class=\"data row10 col8\" >0.792948</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col9\" class=\"data row10 col9\" >0.812229</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col10\" class=\"data row10 col10\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col11\" class=\"data row10 col11\" >-0.084992</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col12\" class=\"data row10 col12\" >0.196021</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col13\" class=\"data row10 col13\" >0.034754</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col14\" class=\"data row10 col14\" >0.005020</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col15\" class=\"data row10 col15\" >-0.029814</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col16\" class=\"data row10 col16\" >0.031299</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col17\" class=\"data row10 col17\" >0.076973</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col18\" class=\"data row10 col18\" >-0.055824</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col19\" class=\"data row10 col19\" >-0.008408</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row10_col20\" class=\"data row10 col20\" >-0.017853</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row11\" class=\"row_heading level0 row11\" >Word PCA 0</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col0\" class=\"data row11 col0\" >-0.238422</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col1\" class=\"data row11 col1\" >0.022213</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col2\" class=\"data row11 col2\" >-0.264926</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col3\" class=\"data row11 col3\" >-0.104614</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col4\" class=\"data row11 col4\" >0.002405</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col5\" class=\"data row11 col5\" >-0.061424</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col6\" class=\"data row11 col6\" >-0.069566</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col7\" class=\"data row11 col7\" >0.043318</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col8\" class=\"data row11 col8\" >0.469218</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col9\" class=\"data row11 col9\" >0.448731</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col10\" class=\"data row11 col10\" >-0.084992</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col11\" class=\"data row11 col11\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col12\" class=\"data row11 col12\" >-0.037076</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col13\" class=\"data row11 col13\" >0.057822</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col14\" class=\"data row11 col14\" >-0.134442</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col15\" class=\"data row11 col15\" >0.024040</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col16\" class=\"data row11 col16\" >-0.055495</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col17\" class=\"data row11 col17\" >-0.072854</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col18\" class=\"data row11 col18\" >-0.015050</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col19\" class=\"data row11 col19\" >-0.021964</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row11_col20\" class=\"data row11 col20\" >0.076682</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row12\" class=\"row_heading level0 row12\" >Word PCA 1</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col0\" class=\"data row12 col0\" >-0.095587</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col1\" class=\"data row12 col1\" >-0.055404</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col2\" class=\"data row12 col2\" >-0.115825</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col3\" class=\"data row12 col3\" >0.058740</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col4\" class=\"data row12 col4\" >0.053656</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col5\" class=\"data row12 col5\" >0.108525</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col6\" class=\"data row12 col6\" >0.116068</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col7\" class=\"data row12 col7\" >-0.078368</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col8\" class=\"data row12 col8\" >0.128744</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col9\" class=\"data row12 col9\" >0.180274</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col10\" class=\"data row12 col10\" >0.196021</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col11\" class=\"data row12 col11\" >-0.037076</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col12\" class=\"data row12 col12\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col13\" class=\"data row12 col13\" >-0.049125</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col14\" class=\"data row12 col14\" >0.027559</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col15\" class=\"data row12 col15\" >0.005063</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col16\" class=\"data row12 col16\" >0.074745</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col17\" class=\"data row12 col17\" >0.057271</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col18\" class=\"data row12 col18\" >-0.030078</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col19\" class=\"data row12 col19\" >-0.038790</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row12_col20\" class=\"data row12 col20\" >-0.029573</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row13\" class=\"row_heading level0 row13\" >Word PCA 2</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col0\" class=\"data row13 col0\" >0.049517</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col1\" class=\"data row13 col1\" >0.030073</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col2\" class=\"data row13 col2\" >0.034084</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col3\" class=\"data row13 col3\" >-0.161022</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col4\" class=\"data row13 col4\" >-0.064439</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col5\" class=\"data row13 col5\" >-0.015806</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col6\" class=\"data row13 col6\" >-0.047119</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col7\" class=\"data row13 col7\" >0.037702</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col8\" class=\"data row13 col8\" >-0.027094</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col9\" class=\"data row13 col9\" >0.029350</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col10\" class=\"data row13 col10\" >0.034754</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col11\" class=\"data row13 col11\" >0.057822</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col12\" class=\"data row13 col12\" >-0.049125</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col13\" class=\"data row13 col13\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col14\" class=\"data row13 col14\" >-0.074068</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col15\" class=\"data row13 col15\" >0.014599</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col16\" class=\"data row13 col16\" >-0.020762</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col17\" class=\"data row13 col17\" >-0.112646</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col18\" class=\"data row13 col18\" >-0.004260</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col19\" class=\"data row13 col19\" >0.031410</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row13_col20\" class=\"data row13 col20\" >0.008068</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row14\" class=\"row_heading level0 row14\" >Word PCA 3</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col0\" class=\"data row14 col0\" >0.050142</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col1\" class=\"data row14 col1\" >0.108705</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col2\" class=\"data row14 col2\" >0.350981</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col3\" class=\"data row14 col3\" >0.001142</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col4\" class=\"data row14 col4\" >0.016405</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col5\" class=\"data row14 col5\" >0.000334</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col6\" class=\"data row14 col6\" >0.007980</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col7\" class=\"data row14 col7\" >0.008498</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col8\" class=\"data row14 col8\" >-0.045047</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col9\" class=\"data row14 col9\" >-0.061031</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col10\" class=\"data row14 col10\" >0.005020</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col11\" class=\"data row14 col11\" >-0.134442</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col12\" class=\"data row14 col12\" >0.027559</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col13\" class=\"data row14 col13\" >-0.074068</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col14\" class=\"data row14 col14\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col15\" class=\"data row14 col15\" >0.054795</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col16\" class=\"data row14 col16\" >0.059902</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col17\" class=\"data row14 col17\" >0.066462</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col18\" class=\"data row14 col18\" >0.041663</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col19\" class=\"data row14 col19\" >0.028766</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row14_col20\" class=\"data row14 col20\" >-0.126698</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row15\" class=\"row_heading level0 row15\" >Word PCA 4</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col0\" class=\"data row15 col0\" >0.071031</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col1\" class=\"data row15 col1\" >0.180105</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col2\" class=\"data row15 col2\" >0.062960</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col3\" class=\"data row15 col3\" >-0.036749</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col4\" class=\"data row15 col4\" >-0.040427</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col5\" class=\"data row15 col5\" >-0.048774</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col6\" class=\"data row15 col6\" >-0.066471</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col7\" class=\"data row15 col7\" >0.046575</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col8\" class=\"data row15 col8\" >-0.032011</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col9\" class=\"data row15 col9\" >-0.040712</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col10\" class=\"data row15 col10\" >-0.029814</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col11\" class=\"data row15 col11\" >0.024040</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col12\" class=\"data row15 col12\" >0.005063</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col13\" class=\"data row15 col13\" >0.014599</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col14\" class=\"data row15 col14\" >0.054795</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col15\" class=\"data row15 col15\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col16\" class=\"data row15 col16\" >0.002459</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col17\" class=\"data row15 col17\" >-0.030570</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col18\" class=\"data row15 col18\" >0.012986</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col19\" class=\"data row15 col19\" >0.015529</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row15_col20\" class=\"data row15 col20\" >-0.064166</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row16\" class=\"row_heading level0 row16\" >Word PCA 5</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col0\" class=\"data row16 col0\" >0.078651</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col1\" class=\"data row16 col1\" >0.005322</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col2\" class=\"data row16 col2\" >0.071707</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col3\" class=\"data row16 col3\" >-0.068429</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col4\" class=\"data row16 col4\" >0.023291</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col5\" class=\"data row16 col5\" >0.002367</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col6\" class=\"data row16 col6\" >-0.002113</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col7\" class=\"data row16 col7\" >-0.010471</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col8\" class=\"data row16 col8\" >-0.018422</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col9\" class=\"data row16 col9\" >-0.049566</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col10\" class=\"data row16 col10\" >0.031299</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col11\" class=\"data row16 col11\" >-0.055495</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col12\" class=\"data row16 col12\" >0.074745</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col13\" class=\"data row16 col13\" >-0.020762</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col14\" class=\"data row16 col14\" >0.059902</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col15\" class=\"data row16 col15\" >0.002459</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col16\" class=\"data row16 col16\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col17\" class=\"data row16 col17\" >0.017968</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col18\" class=\"data row16 col18\" >0.002818</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col19\" class=\"data row16 col19\" >-0.019602</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row16_col20\" class=\"data row16 col20\" >-0.043366</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row17\" class=\"row_heading level0 row17\" >Word PCA 6</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col0\" class=\"data row17 col0\" >-0.009260</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col1\" class=\"data row17 col1\" >-0.002986</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col2\" class=\"data row17 col2\" >0.053381</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col3\" class=\"data row17 col3\" >0.005006</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col4\" class=\"data row17 col4\" >-0.045115</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col5\" class=\"data row17 col5\" >0.004162</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col6\" class=\"data row17 col6\" >0.002745</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col7\" class=\"data row17 col7\" >-0.006862</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col8\" class=\"data row17 col8\" >0.032255</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col9\" class=\"data row17 col9\" >0.081167</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col10\" class=\"data row17 col10\" >0.076973</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col11\" class=\"data row17 col11\" >-0.072854</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col12\" class=\"data row17 col12\" >0.057271</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col13\" class=\"data row17 col13\" >-0.112646</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col14\" class=\"data row17 col14\" >0.066462</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col15\" class=\"data row17 col15\" >-0.030570</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col16\" class=\"data row17 col16\" >0.017968</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col17\" class=\"data row17 col17\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col18\" class=\"data row17 col18\" >-0.015066</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col19\" class=\"data row17 col19\" >-0.031238</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row17_col20\" class=\"data row17 col20\" >-0.038761</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row18\" class=\"row_heading level0 row18\" >Word PCA 7</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col0\" class=\"data row18 col0\" >-0.025746</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col1\" class=\"data row18 col1\" >-0.079250</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col2\" class=\"data row18 col2\" >0.246697</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col3\" class=\"data row18 col3\" >0.113368</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col4\" class=\"data row18 col4\" >0.029307</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col5\" class=\"data row18 col5\" >-0.015282</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col6\" class=\"data row18 col6\" >-0.006117</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col7\" class=\"data row18 col7\" >0.006719</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col8\" class=\"data row18 col8\" >-0.024625</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col9\" class=\"data row18 col9\" >-0.082403</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col10\" class=\"data row18 col10\" >-0.055824</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col11\" class=\"data row18 col11\" >-0.015050</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col12\" class=\"data row18 col12\" >-0.030078</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col13\" class=\"data row18 col13\" >-0.004260</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col14\" class=\"data row18 col14\" >0.041663</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col15\" class=\"data row18 col15\" >0.012986</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col16\" class=\"data row18 col16\" >0.002818</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col17\" class=\"data row18 col17\" >-0.015066</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col18\" class=\"data row18 col18\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col19\" class=\"data row18 col19\" >0.023010</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row18_col20\" class=\"data row18 col20\" >-0.029014</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row19\" class=\"row_heading level0 row19\" >Word PCA 8</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col0\" class=\"data row19 col0\" >-0.010917</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col1\" class=\"data row19 col1\" >0.132054</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col2\" class=\"data row19 col2\" >0.092601</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col3\" class=\"data row19 col3\" >0.014378</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col4\" class=\"data row19 col4\" >-0.012457</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col5\" class=\"data row19 col5\" >-0.014035</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col6\" class=\"data row19 col6\" >-0.010431</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col7\" class=\"data row19 col7\" >0.016518</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col8\" class=\"data row19 col8\" >-0.043820</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col9\" class=\"data row19 col9\" >-0.045089</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col10\" class=\"data row19 col10\" >-0.008408</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col11\" class=\"data row19 col11\" >-0.021964</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col12\" class=\"data row19 col12\" >-0.038790</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col13\" class=\"data row19 col13\" >0.031410</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col14\" class=\"data row19 col14\" >0.028766</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col15\" class=\"data row19 col15\" >0.015529</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col16\" class=\"data row19 col16\" >-0.019602</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col17\" class=\"data row19 col17\" >-0.031238</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col18\" class=\"data row19 col18\" >0.023010</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col19\" class=\"data row19 col19\" >1.000000</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row19_col20\" class=\"data row19 col20\" >-0.025097</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33level0_row20\" class=\"row_heading level0 row20\" >Word PCA 9</th>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col0\" class=\"data row20 col0\" >-0.035565</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col1\" class=\"data row20 col1\" >-0.165593</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col2\" class=\"data row20 col2\" >-0.257534</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col3\" class=\"data row20 col3\" >-0.011706</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col4\" class=\"data row20 col4\" >-0.030105</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col5\" class=\"data row20 col5\" >-0.003120</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col6\" class=\"data row20 col6\" >-0.010980</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col7\" class=\"data row20 col7\" >0.020400</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col8\" class=\"data row20 col8\" >0.015584</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col9\" class=\"data row20 col9\" >0.039649</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col10\" class=\"data row20 col10\" >-0.017853</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col11\" class=\"data row20 col11\" >0.076682</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col12\" class=\"data row20 col12\" >-0.029573</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col13\" class=\"data row20 col13\" >0.008068</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col14\" class=\"data row20 col14\" >-0.126698</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col15\" class=\"data row20 col15\" >-0.064166</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col16\" class=\"data row20 col16\" >-0.043366</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col17\" class=\"data row20 col17\" >-0.038761</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col18\" class=\"data row20 col18\" >-0.029014</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col19\" class=\"data row20 col19\" >-0.025097</td>\n",
       "                        <td id=\"T_172fcb5b_3cb0_11eb_b8bd_00e04c6b8f33row20_col20\" class=\"data row20 col20\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c7bfa04160>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation Matrix for Features\n",
    "corr = features.corr()\n",
    "cmap = cmap = sns.diverging_palette(0,2, as_cmap=True)\n",
    "\n",
    "corr.style.background_gradient(cmap, axis=1)\\\n",
    "    .set_properties(**{'max-width': '100px', 'font-size': '12pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
