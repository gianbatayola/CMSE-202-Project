{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Homework 4 (Individual)\n",
    "\n",
    "## Using SVM and PCA to predict the outcome of chess games\n",
    "\n",
    "### Goals for this homework assignment\n",
    "\n",
    "By the end of this assignment, you should be able to:\n",
    "\n",
    "* Use `git` to track your work and turn in your assignment\n",
    "* Read and impute data to prepare it for modeling\n",
    "* Build, fit, and evaluate an SVC model of data\n",
    "* Use PCA to reduce the number of important features\n",
    "* Build, fit, and evaluate an SVC model of pca transformed data\n",
    "* Systematically investigate the effects of the number of components on an SVC model of data\n",
    "\n",
    "\n",
    "### Assignment instructions:\n",
    "\n",
    "Work through the following assignment, making sure to follow all of the directions and answer all of the questions.\n",
    "\n",
    "There are 25 points possible on this assignment. Point values for each part are included in the section headers.\n",
    "\n",
    "This assignment is due at 11:59 pm on Friday, November 13th. It should be pushed to your repo (See Part 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Adding notebook to your turn-in repository\n",
    "\n",
    "Like you did for Homework 3, you're going to add it to the CMSE202 repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to:\n",
    "\n",
    "* Navigate to your /CMSE202/repos repository and create a new directory called hw-04.\n",
    "* Move this notebook into that new directory in your repository, then add it and commit it to your repository.\n",
    "   * Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "Important: Make sure you've added your TA as a collaborators to your respository with \"Read\" access so that we can see your assignment. (*If you did this for Homework 3, you do not need to do it again*)\n",
    "\n",
    "* Section 001: tuethan\n",
    "* Section 002: Luis-Polanco\n",
    "* Section 003: DavidRimel\n",
    "\n",
    "Also important: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the notebook, none of your changes will be tracked.\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account CMSE202 repository under the hw-04 directory that you just created. Periodically, you'll be asked to commit your changes to the repository and push them to the remote GitHub location. Of course, you can always commit your changes more often than that, if you wish. It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Chess Game Data\n",
    "\n",
    "The data you will work are configurations of a chess end game. It assumes that a pawn is one move away from [\"queening\"](https://en.wikipedia.org/wiki/Promotion_(chess)) and \n",
    "the other pieces can be moved to perform different offensive or defensive actions. For each of the 36 potential features, there are several potential values for each (entries in a given column). **The details of the data matter a bit less for our purposes, but we are attempting to predict the won/loss by a given side.** If you really want to know about the data, you can look into a [classic text on Artificial Intelligence by Shapiro](https://www.amazon.com/Encyclopedia-Artificial-Intelligence-Stuart-Shapiro/dp/0471807486).\n",
    "\n",
    "You will first do this with a full model, then investigate how well the model works after a PCA has been done on the data.\n",
    "\n",
    "### 2.1 Read in the data\n",
    "\n",
    "First you need to read in the data from `kr-vs-kp.data`. You can look at `kr-vs-kp.names` to see how the data is structured. But we give you the code for the column naming as there are so many features and they are unlabeled in the `.data` file.\n",
    "\n",
    "```cols = [\"bkblk\",\"bknwy\",\"bkon8\",\"bkona\",\"bkspr\",\"bkxbq\",\"bkxcr\",\"bkxwp\",\"blxwp\",\"bxqsq\",\"cntxt\",\"dsopp\",\"dwipd\",\n",
    " \"hdchk\",\"katri\",\"mulch\",\"qxmsq\",\"r2ar8\",\"reskd\",\"reskr\",\"rimmx\",\"rkxwp\",\"rxmsq\",\"simpl\",\"skach\",\"skewr\",\n",
    " \"skrxp\",\"spcop\",\"stlmt\",\"thrsk\",\"wkcti\",\"wkna8\",\"wknck\",\"wkovl\",\"wkpos\",\"wtoeg\",\"won\"]```\n",
    " \n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Read in the data from `kr-vs-kp.data` using the columns listed above. Print the `.head()` of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bkblk</th>\n",
       "      <th>bknwy</th>\n",
       "      <th>bkon8</th>\n",
       "      <th>bkona</th>\n",
       "      <th>bkspr</th>\n",
       "      <th>bkxbq</th>\n",
       "      <th>bkxcr</th>\n",
       "      <th>bkxwp</th>\n",
       "      <th>blxwp</th>\n",
       "      <th>bxqsq</th>\n",
       "      <th>...</th>\n",
       "      <th>spcop</th>\n",
       "      <th>stlmt</th>\n",
       "      <th>thrsk</th>\n",
       "      <th>wkcti</th>\n",
       "      <th>wkna8</th>\n",
       "      <th>wknck</th>\n",
       "      <th>wkovl</th>\n",
       "      <th>wkpos</th>\n",
       "      <th>wtoeg</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>won</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>won</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bkblk bknwy bkon8 bkona bkspr bkxbq bkxcr bkxwp blxwp bxqsq  ... spcop  \\\n",
       "0     f     f     f     f     f     f     f     f     f     f  ...     f   \n",
       "1     f     f     f     f     t     f     f     f     f     f  ...     f   \n",
       "2     f     f     f     f     t     f     t     f     f     f  ...     f   \n",
       "3     f     f     f     f     f     f     f     f     t     f  ...     f   \n",
       "4     f     f     f     f     f     f     f     f     f     f  ...     f   \n",
       "\n",
       "  stlmt thrsk wkcti wkna8 wknck wkovl wkpos wtoeg  won  \n",
       "0     f     f     f     f     f     t     t     n  won  \n",
       "1     f     f     f     f     f     t     t     n  won  \n",
       "2     f     f     f     f     f     t     t     n  won  \n",
       "3     f     f     f     f     f     t     t     n  won  \n",
       "4     f     f     f     f     f     t     t     n  won  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code here\n",
    "cols = [\"bkblk\",\"bknwy\",\"bkon8\",\"bkona\",\"bkspr\",\"bkxbq\",\"bkxcr\",\"bkxwp\",\"blxwp\",\"bxqsq\",\"cntxt\",\"dsopp\",\"dwipd\",\n",
    " \"hdchk\",\"katri\",\"mulch\",\"qxmsq\",\"r2ar8\",\"reskd\",\"reskr\",\"rimmx\",\"rkxwp\",\"rxmsq\",\"simpl\",\"skach\",\"skewr\",\n",
    " \"skrxp\",\"spcop\",\"stlmt\",\"thrsk\",\"wkcti\",\"wkna8\",\"wknck\",\"wkovl\",\"wkpos\",\"wtoeg\",\"won\"]\n",
    "\n",
    "df = pd.read_csv(\"kr-vs-kp.data\", names = cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Imputing the data\n",
    "\n",
    "There are no missing data in this data file, but there are some other issues. \n",
    "\n",
    "When you print the head of this data set, you probably noticed that all the features and labels are strings. We need to replace them with numerical values for modeling. For the `won` column replace winning with a 1 and losing with a 0. For the other columns, there are seven strings. Replace them using the following table:\n",
    "\n",
    "| raw data | replaced |\n",
    "| -------- | -------- |\n",
    "| f | 1 |\n",
    "| l | 2 |\n",
    "| n | 3 |\n",
    "| t | 4 |\n",
    "| w | 5 |\n",
    "| b | 6 |\n",
    "| g | 7 |\n",
    "\n",
    "**Note:** this choice really matters and for the models we have learned can really influence the results of our model. We do this because we need to for the model, but we haven't critically thought about the mapping that makes the most sense. There are other models (e.g., [tree-based alogrithms](https://en.wikipedia.org/wiki/Random_forest)) that can handle these categorical data without this mapping.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Replace the entries in the columns as indicated above. Print the `.head()` of the dataframe to show you have succesfull done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bkblk</th>\n",
       "      <th>bknwy</th>\n",
       "      <th>bkon8</th>\n",
       "      <th>bkona</th>\n",
       "      <th>bkspr</th>\n",
       "      <th>bkxbq</th>\n",
       "      <th>bkxcr</th>\n",
       "      <th>bkxwp</th>\n",
       "      <th>blxwp</th>\n",
       "      <th>bxqsq</th>\n",
       "      <th>...</th>\n",
       "      <th>spcop</th>\n",
       "      <th>stlmt</th>\n",
       "      <th>thrsk</th>\n",
       "      <th>wkcti</th>\n",
       "      <th>wkna8</th>\n",
       "      <th>wknck</th>\n",
       "      <th>wkovl</th>\n",
       "      <th>wkpos</th>\n",
       "      <th>wtoeg</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bkblk  bknwy  bkon8  bkona  bkspr  bkxbq  bkxcr  bkxwp  blxwp  bxqsq  ...  \\\n",
       "0      1      1      1      1      1      1      1      1      1      1  ...   \n",
       "1      1      1      1      1      4      1      1      1      1      1  ...   \n",
       "2      1      1      1      1      4      1      4      1      1      1  ...   \n",
       "3      1      1      1      1      1      1      1      1      4      1  ...   \n",
       "4      1      1      1      1      1      1      1      1      1      1  ...   \n",
       "\n",
       "   spcop  stlmt  thrsk  wkcti  wkna8  wknck  wkovl  wkpos  wtoeg  won  \n",
       "0      1      1      1      1      1      1      4      4      3    1  \n",
       "1      1      1      1      1      1      1      4      4      3    1  \n",
       "2      1      1      1      1      1      1      4      4      3    1  \n",
       "3      1      1      1      1      1      1      4      4      3    1  \n",
       "4      1      1      1      1      1      1      4      4      3    1  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code here\n",
    "df = df.replace({\"f\":1, \"l\":2, \"n\":3, \"t\":4, \"w\":5, \"b\":6, \"g\":7, \"won\":1, \"nowin\":0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Separate features and class labels\n",
    "\n",
    "As we have seen in our analyses using `sklearn` it is advantageous to separate our dataframes into `features` and `labels` for the analysis we are intending to do.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Separate the data frame into two: a features dataframe and a labels dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bkblk</th>\n",
       "      <th>bknwy</th>\n",
       "      <th>bkon8</th>\n",
       "      <th>bkona</th>\n",
       "      <th>bkspr</th>\n",
       "      <th>bkxbq</th>\n",
       "      <th>bkxcr</th>\n",
       "      <th>bkxwp</th>\n",
       "      <th>blxwp</th>\n",
       "      <th>bxqsq</th>\n",
       "      <th>...</th>\n",
       "      <th>skrxp</th>\n",
       "      <th>spcop</th>\n",
       "      <th>stlmt</th>\n",
       "      <th>thrsk</th>\n",
       "      <th>wkcti</th>\n",
       "      <th>wkna8</th>\n",
       "      <th>wknck</th>\n",
       "      <th>wkovl</th>\n",
       "      <th>wkpos</th>\n",
       "      <th>wtoeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bkblk  bknwy  bkon8  bkona  bkspr  bkxbq  bkxcr  bkxwp  blxwp  bxqsq  ...  \\\n",
       "0      1      1      1      1      1      1      1      1      1      1  ...   \n",
       "1      1      1      1      1      4      1      1      1      1      1  ...   \n",
       "2      1      1      1      1      4      1      4      1      1      1  ...   \n",
       "3      1      1      1      1      1      1      1      1      4      1  ...   \n",
       "4      1      1      1      1      1      1      1      1      1      1  ...   \n",
       "\n",
       "   skrxp  spcop  stlmt  thrsk  wkcti  wkna8  wknck  wkovl  wkpos  wtoeg  \n",
       "0      1      1      1      1      1      1      1      4      4      3  \n",
       "1      1      1      1      1      1      1      1      4      4      3  \n",
       "2      1      1      1      1      1      1      1      4      4      3  \n",
       "3      1      1      1      1      1      1      1      4      4      3  \n",
       "4      1      1      1      1      1      1      1      4      4      3  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## your code here\n",
    "features = df.drop(columns = 'won')\n",
    "labels = df['won']\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How balanced is your outcome variable? Why does it matter for the outcome to be balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522215269086358\n"
     ]
    }
   ],
   "source": [
    "ones, zeros = labels.value_counts()\n",
    "print(ones/(ones+zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> They seem to be balanced. There are slightly more wins (1's), but overall the split is 52%-48%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Building an SVC model\n",
    "\n",
    "For this classification problem, we will use an support vector machine. As you learned in the midterm review, we could easily replace this with any `sklearn` classifier we choose. We will use a linear kernel.\n",
    "\n",
    "### 3.1 Splitting the data\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Split your data into a training and testing set with a train size representing 75% of your data. Print the lengths to show you have the right number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train features: 2397\n",
      "Num train labels: 2397\n",
      "Num test features: 799\n",
      "Num test labels: 799\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, train_size = 0.75, random_state = 0)\n",
    "print(f\"Num train features: {len(train_features)}\\nNum train labels: {len(train_labels)}\\nNum test features: {len(test_features)}\\nNum test labels: {len(test_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Modeling the data and evaluting the fit\n",
    "\n",
    "As you have done this a number of times, we ask you to do most of the analysis in one cell.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Build a linear SVC model (`C=100`), fit it to the training set, use the test features to predict the outcomes. Evaluate the fit using the confusion matrix and classification report.\n",
    "\n",
    " **Note:** You should look at the documentation on the confusion matrix because the way `sklearn` outputs false positives and false negatives is different from what most images on the web indicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[371  19]\n",
      " [ 16 393]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       390\n",
      "           1       0.95      0.96      0.96       409\n",
      "\n",
      "    accuracy                           0.96       799\n",
      "   macro avg       0.96      0.96      0.96       799\n",
      "weighted avg       0.96      0.96      0.96       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C = 100, kernel = 'linear')\n",
    "svc.fit(train_features, train_labels)\n",
    "pred_labels = svc.predict(test_features)\n",
    "\n",
    "conf_mat = confusion_matrix(test_labels, pred_labels)\n",
    "class_rep = classification_report(test_labels, pred_labels)\n",
    "\n",
    "print(f'Confusion Matrix: \\n {conf_mat}')\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How accurate is your model? What eveidence are you using to determine that? How many false positives and false negatives does it predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> It is accurate based on the precision scores for both labels (win is 0.95 and lose is 0.96) and the accuracy score, which is 0.96. The were 19 false positives and 16 false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Finding and using the best hyperparameters\n",
    "\n",
    "We have fit one model and determined it's performance, but is it the best model? We can use `GridSearchCV` to find the best model (given our choices of parameters). Once we do that, we will use that best model going forward. **Note:** you would typically rerun this grid search in a production environment to continue to verify the best model, but we are not for the sake of speed.\n",
    "\n",
    "### 4.1 Grid search\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Using the following parameters (`C` = 1, 10, 100, 1000 and `gamma` = 1e-4, 1e-3, 0.01, 0.1) for both a `linear` and `rbf` kernel use `GridSearchCV` with the `SVC()` model to find the best fit parameters. Print the \"best estimators\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'kernel':('linear', 'rbf'),\n",
    "              'C': [1, 10, 100, 1000],\n",
    "              'gamma': [0.0001, 0.001, 0.01, 0.1],}\n",
    "\n",
    "clf = GridSearchCV(SVC(), param_grid)\n",
    "\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Evaluating the best fit model\n",
    "\n",
    "Now that we have found the \"best estimators\", let's determine how good the fit is.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Use the test features to predict the outcomes for the best model. Evaluate the fit using the confusion matrix and classification report. \n",
    "\n",
    "**Note:** You should look at the documentation on the confusion matrix because the way `sklearn` outputs false positives and false negatives is different from what most images on the web indicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = clf.predict(test_features)\n",
    "\n",
    "conf_mat = confusion_matrix(test_labels, pred_labels)\n",
    "class_rep = classification_report(test_labels, pred_labels)\n",
    "\n",
    "print(f'Confusion Matrix: \\n {conf_mat}')\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How accurate is this best model? What evidence are you using to determine that? How many false positives and false negatives does it predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> This model is even more accurate than the last. It predicts only 2 false positives and 3 false negatives. All scored are 0.99 or 1.00. It has a very high probability of guessing the outcome correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Using Principal Components\n",
    "\n",
    "The full model uses 36 features to predict the results. And you likely found that the model is incredibly accurate. But in some cases, we might have even more features (which means much more computational time), and we might not need nearly the level of accuracy we can achieve with the full data set. So, we will see how close we can get with fewer features. But instead of simply removing features, we will use a PCA to determine the featurse that contribute the most the model (through their accounted variance) and use those to build our SVC model.\n",
    "\n",
    "### 5.1 Building a PCA\n",
    "\n",
    "We will start with a small number of components (say, 4) to see how well we can predict the outcomes of the games.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Using `PCA()`, fit a pca to your training features with 4 components. Transform both the test and training features using this pca. Plot the `explained_variance_` versus component number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 4\n",
    "\n",
    "pca = PCA(n_components=n_components, whiten=True)\n",
    "\n",
    "_ = pca.fit(train_features)\n",
    "\n",
    "pca_train_features = pca.transform(train_features)\n",
    "pca_test_features = pca.transform(test_features)\n",
    "\n",
    "plt.plot(pca.explained_variance_, \"o-\")\n",
    "plt.xlabel(\"Num Components\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.ylim(-0.5, 8)\n",
    "plt.xlim(-0.5,3.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the total explained variance captured by this PCA (we will use this later, just quote the number)? How well do you think a model with this many featuers will perform? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.579343948871895"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> The total explained variance is 19.58. This model will not perform well. All four features only account for 19.58% of the outcome. We'd like the number to be closer to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Fit and Evaluate an SVC model\n",
    "\n",
    "Using the pca transformed features, we will train and test an SVC model using the \"best estimators\".\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Using the pca transformed training data, build and train an SVC model. Predict the classes using the pca transformed test data. Evaluate the model using the classfication report, and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[266 124]\n",
      " [162 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65       390\n",
      "           1       0.67      0.60      0.63       409\n",
      "\n",
      "    accuracy                           0.64       799\n",
      "   macro avg       0.64      0.64      0.64       799\n",
      "weighted avg       0.64      0.64      0.64       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.fit(pca_train_features, train_labels)\n",
    "pred_labels_svc = clf.predict(pca_test_features)\n",
    "\n",
    "conf_mat_svc = confusion_matrix(test_labels, pred_labels_svc)\n",
    "class_rep_svc = classification_report(test_labels, pred_labels_svc)\n",
    "\n",
    "print(f'Confusion Matrix: \\n {conf_mat_svc}')\n",
    "print(class_rep_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How accurate is this model? What evidence are you using to determine that? How many false positives and false negatives does it predict? How does it compare to the full model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> It is not very accurate. It predicts 124 false positives and 162 false negatives. All of the scores displayed on the classification report are in the 0.61-0.69 range. It is only slightly more accurate than it would be to randomly guess if a match will result in a win or loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Repeat your analysis with more components\n",
    "\n",
    "You probably found that the model with 4 features didn't work so well. What if we increase the number of components (say to 30, which is still 6 fewer than the full data set). What happens now?\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Repeat your analysis from 5.1 and 5.2 using 30 components instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xcZbX/8c9KmjRJ0ya9pm1SKRQo0rSlNKIWlQZFiqgg3kWPoj8reAO5KXo4iIqgWBE9iCKiqEgOlwLl1oLQgpweLr1f6EUoBZqUlpambdqkSZP1+2N2aprMJDNJdiYz832/XvPKzJ7Ze6+HoWvPfp5nr23ujoiIZI6sZAcgIiJ9S4lfRCTDKPGLiGQYJX4RkQyjxC8ikmGU+EVEMkyoid/MvmNma81sjZndaWZ5Ye5PRES6FlriN7NS4NtAhbuXA9nAZ8Lan4iIxCfsrp4BQL6ZDQAKgJqQ9yciIl0YENaG3b3azH4BvAbUA4+5+2PtP2dms4HZAPn5+dPHjRt32PstLS1kZaXnUITalprUttSTru0C2Lhx4w53H5nQSu4eygMYCjwJjARygPuBz3e2zvTp0729hQsXdliWLtS21KS2pZ50bZe7O7DEE8zPYR4CPwC84u5vunsTMBeYEeL+REQkDmEm/teAd5lZgZkZ8H5gXYj7ExGROISW+N39OeAeYBmwOtjXLWHtT0RE4hPa4C6Au18FXBXmPkREJDHpOcwtIiIxKfGLiGQYJX4RkQyjxC8ikmGU+EVEMowSv4hIhlHiFxHJMEr8IiIZRolfRCTDKPGLiGQYJX4RkQyjxC8ikmGU+EVEMowSv4hIhlHiFxHJMEr8IiIZJtQbsfTE/curuX7BBqpr6yl99kkuO30iZ08rTXZYIiIpL7Rf/GY20cxWtHnsMbOL4ln3/uXVXDF3NdW19QBU19ZzxdzV3L+8OqxwRUQyRpj33N3g7ie4+wnAdGA/cF88616/YAP1Tc2HLatvaub6BRt6P1ARkQzTV3387wdedvdX4/lwTfBLP97lIiISP3P38HdidhuwzN3/O8p7s4HZACUlJdOrqqq4ZNF+djZ0jGt4njFnZkHo8faVuro6CgsLkx1GKNS21JSubUvXdgFUVlYudfeKRNYJPfGbWS5QA0xy922dfbaiosKXLFlyqI+/bXdPfk42154zOa0GeBctWsTMmTOTHUYo1LbUlK5tS9d2AZhZwom/L2b1nEHk136nSb+t1uT+8wXrqaltYFBuNtd8LL2SvohIsvRFH/9ngTsTXensaaUs/t77OW5YFkeXDFbSFxHpJaEmfjMrAE4D5nZ3G+OHZLOuZg+NB1t6LzARkQwWauJ39/3uPtzdd3d3G0cVZdHY3MLGbXt7MzQRkYzV70s2HFkUCXHlltokRyIikh76feIfkW8MLchh9ZZunzSIiEgb/T7xmxmTy4pZqcQvItIr+n3iB5hSWsTGbXupb2zu+sMiItKp1Ej8ZUU0tzgvbt2T7FBERFJeiiT+YgBWaYBXRKTHUiLxjy7KY9TggRrgFRHpBSmR+CHS3aMpnSIiPZdCib+YTTv2sbehKdmhiIiktJRJ/JPLinCHNdUa4BUR6YmUSfxTSosAWF2t7h4RkZ5ImcQ/vHAgpcX5upBLRKSHUibxA0wdV6SZPSIiPZRSiX9KWTGvvbWfXfsakx2KiEjKSq3EH/Tzr6rWr34Rke5KqcRfXhYM8Go+v4hIt4V9B65iM7vHzNab2Toze3dPtjckL4ejRgzSAK+ISA+EfbP1G4H57v4JM8sFCnq6wSllRTy76a2eRyYikqFC+8VvZkOA9wF/BHD3RnfvcR/N5LJi3tjTwPY9DT3dlIhIRgqzq+co4E3gT2a23MxuNbNBPd3o1KCff5W6e0REusXcPZwNm1UAzwInu/tzZnYjsMfdr2z3udnAbICSkpLpVVVVh22nrq6OwsLCQ68PHHTO/8d+PjIhh3OOyQ0l9r7Svm3pRG1LTenatnRtF0BlZeVSd69IaCV3D+UBjAY2t3n9XuDhztaZPn26t7dw4cIOy06/4Sn/4m3PdVieaqK1LV2obakpXduWru1ydweWeIL5ObSuHnd/A3jdzCYGi94PvNgb255cWsSqLbtbDygiIpKAsOfxfwu4w8xWAScAP+2NjU4ZV8xb+xqprq3vjc2JiGSUUKdzuvsKILG+pzi0HeAtG9rjGaIiIhklpa7cbTVx9GBysk135BIR6YaUTPwDB2Tz9jFDVKlTRKQbUjLxQ2SAd/WW3bS0aIBXRCQRKZv4p5YVs/fAQTbv3JfsUEREUkrKJv7JuoJXRKRbUjbxHzOqkLycLCV+EZEExZ34e6POTm8akJ3FpLFFrNLMHhGRhHSZ+M1shpm9CKwLXk81s9+GHlkcppQVsbZmDwebW5IdiohIyojnF/8NwOnATgB3X0mk3HLSTSkror6pmZferEt2KCIiKSOurh53f73douYQYknYlLJiAFa9rn5+EZF4xZP4XzezGYCbWa6ZXUrQ7ZNsRw4fxOCBA1hVrX5+EZF4xZP4zwe+AZQCW4gUW/tGmEHFKyvLKA8qdYqISHy6LNLm7juAc/sglm6ZMq6I2555hQMHmxk4IDvZ4YiI9HvxzOq53cyK27weama3hRtW/KaUFtPU7Gx4Y2+yQxERSQnxdPVM8TY3SXf3XcC08EJKzBRdwSsikpB4En+WmQ1tfWFmwwi5jn8iyobmM7QgRxdyiYjEKZ4EPgdYbGb3BK8/CVwTXkiJMTOmlBXrF7+ISJziGdz9i5ktBSoBA85x97junWtmm4G9ROb9H/RE7wQfpyllRfx20Q7qG5vJz9UAr4hIZ+LtslkP7Gr9vJm9zd1fi3PdymBmUGj2NzbT3OIc/1/zGVucz2WnT+TsaaVh7lJEJGV1mfjN7FvAVcA2Ir/cDXBgSrihxef+5dXc8eyrQCSo6tp6rpi7GkDJX0QkCnPv/A5WZvYS8E5335nwxs1eIXKm4MDv3f2WKJ+ZDcwGKCkpmV5VVXXY+3V1dRQWFsbcxyWL9rOzoWMbhucZc2b27xuxd9W2VKa2paZ0bVu6tgugsrJyaaLd6PF09bwOdHfk9GR3rzGzUcDjZrbe3Z9u+4HgYHALQEVFhc+cOfOwDSxatIj2y9p6a/7D0Zc3eKfr9QddtS2VqW2pKV3blq7t6q54Ev8mYJGZPQwcaF3o7r/sakV3rwn+bjez+4CTgKc7XysxY4vzqa6tj7pcREQ6imce/2vA40AuMLjNo1NmNsjMBrc+Bz4IrOl+qNFddvpE8nMOn8ljwAUzJ/T2rkRE0kI80zmv7ua2S4D7zKx1P3939/nd3FZMrQO41y/YQE1tPcMLc9m1r5H7l1fziell5OVoeqeISFvxzOoZCVwOTALyWpe7+6mdrefum4CpPQ0wHmdPKz1sBs9Dq2r45t+Xc9k9q7jx0yeQlWV9EYaISEqIp6vnDiLz+I8ErgY2Ay+EGFOPfXjKWC6fNZEHV9Yw5/ENyQ5HRKRfiSfxD3f3PwJN7v6Uu38ZeFfIcfXYBadM4LMnjeOmhS/zPy/Ee62ZiEj6i2dWT1Pwd6uZnQnUAGXhhdQ7zIwfnVXOll31fP++NYwtzue9x4xMdlgiIkkXzy/+n5hZEXAJcClwK/CdUKPqJTnZWfz23BM5ZlQhX//bMtXsFxEhjsTv7g+5+253X+Pule4+3d3n9UVwvWFwXg63fekd5Odmc96fnmf7noZkhyQiklQxu3rM7HJ3/7mZ/YZIyYXDuPu3Q42sF40tzue2L72DT/3+/zjnt4tpdueN3Q0q6CYiGamzPv51wd8lfRFI2MpLizj3nW/jD/985dAyFXQTkUwUM/G7+4Nmlg2Uu/tlfRhTaB5Z/UaHZfVNzVy/YIMSv4hkjE77+N29GZjeR7GEriZKTZ/OlouIpKN4pnMuN7N5wN3AvtaF7j43tKhCooJuIiLxTeccBuwETgU+Ejw+HGZQYYlW0C0/J5vLTp+YpIhERPpePEXazuuLQPpC24Ju1bX1ZBlcc/Yk9e+LSEaJp0hbHvAVOhZp+3KIcYWmtaDbo6u3csEdyxitbh4RyTDxdPX8FRgNnA48RaRcQ8pfAnvKxJHk5WQxf03HmT4iIuksnsR/tLtfCexz99uBM4HJ4YYVvoLcAZxy7EgWrH2DlpbO7zssIpJO4kn8rUXaas2sHCgCxocWUR86o3wM2/YcYPnrtckORUSkz8ST+G8xs6HAlcA84EXgZ6FG1UdOffsocrKN+Wu2JjsUEZE+EzPxm9mLZvYDYKG77wpq8R/l7qPc/ffx7sDMss1suZk91CsR96IheTmcfPQI5q99A3d194hIZujsF/9ngULgMTN7zswuMrMx3djHhfy77k+/c0b5aF5/q561NXuSHYqISJ+ImfjdfaW7X+HuE4gk7yOA58zsSTP7ajwbN7MyIoPBt/ZKtCE47fjRZBma3SMiGcMS6eIws5nADcDx7j4wjs/fA1wLDAYudfcOV/ya2WxgNkBJScn0qqqqw96vq6ujsLAw7hi742fP17P7gPPT9xaEup/2+qJtyaK2paZ0bVu6tgugsrJyqbtXJLSSu3f6AN4B/BJ4lcg8/guAEXGs92Hgt8HzmcBDXa0zffp0b2/hwoUdlvW22xe/4kd89yH/17Y9oe+rrb5oW7KobakpXduWru1ydweWeBe5tf2js8Hdn5rZy8DNRO6ze7K7n+LuN7v7jjiOKScDHzWzzUAVcKqZ/S2ho1If+eDxowF4NErZZhGRdNPZ4O4B4Ax3r3D3X7j7lkQ27JHxgTJ3Hw98BnjS3T/fg1hDM7oojxPfVsz8tUr8IpL+OhvcvdrdN/ZlMMl0RvkY1tbs4bWd+5MdiohIqOK5gKvH3H2RRxnY7U9mlUe6e+av1cVcIpLe+iTxp4JxwwqYNHaIpnWKSNqLWZbZzE7sbEV3X9b74STXGeWj+cVjG3ljdwOji/K6XkFEJAV19ot/TvC4CXgOuAX4Q/D81+GH1vdau3sWaJBXRNJYZ4O7le5eSWT+/onB7J7pwDTgpb4KsC8dPWowR48qVHePiKS1ePr4j3P31a0v3H0NcEJ4ISXXGeWjee6VneysO5DsUEREQhFP4l9nZrea2UwzO8XM/kA/LrrWU6dPGk2Lw+Mvbkt2KCIioYgn8Z8HrCVSqO0iIvX40+YG7O1NGjuEccPydTGXiKStLm+27u4NZvY74BF339AHMSWVmTFr0mj+vHgzu+ubKMrPSXZIIiK9qstf/Gb2UWAFMD94fYKZzQs7sGSaVT6GpmbnyfXq7hGR9BNPV89VwElALYC7ryBN7rkby7RxxZQMGajZPSKSluJJ/AfdfXfokfQjWVnG6ZNG89TGN9nfeDDZ4YiI9Kp4Ev8aM/sckG1mx5jZb4DFIceVdLPKR9PQ1MKiDW8mOxQRkV4VT+L/FjCJSJnmO4E9RGb3pLWTxg9j2KBcdfeISNqJZ1bPfuAHwSNjDMjO4thRhTy4soYHV9Ywtjify06fyNnTSpMdmohIj3SZ+M3sWOBSIgO6hz7v7qeGF1by3b+8mmWv1dJ6R+Lq2nqumBu5gFnJX0RSWZeJH7gb+B1wK9Acbjj9x/ULNtDY3HLYsvqmZq5fsEGJX0RSWjyJ/6C735zohs0sD3gaGBjs5x53vyrR7SRLTW19QstFRFJFPIO7D5rZ181sjJkNa33Esd4B4FR3n0qkqNssM3tXj6LtQ2OL8xNaLiKSKuJJ/F8ELiMyhXNp8FjS1UoeURe8zAke3skq/cplp08kPye7w/Izp4xOQjQiIr3H3MPLxWaWTeRAcTRwk7t/N8pnZgOzAUpKSqZXVVUd9n5dXR2FhYWhxdiZxTVN3LuxiZ0NzrA8A3fqDsJ335HHhOKOB4VEJbNtYVPbUlO6ti1d2wVQWVm51N0rElknZuI3s1Pd/UkzOyfa++4+N+6dmBUD9wHfCur5R1VRUeFLlhx+MrFo0SJmzpwZ765CtX1vA5+4+f/Y09DEPee/m6NHDe7R9vpT23qb2paa0rVt6douADNLOPF31tVzSvD3I1EeH05kJ+5eCywCZiWyXn8zanAef/3KSQzIMv7jj8+zdbcGekUk9XR268Wrgr/nRXl8uasNm9nI4Jc+ZpYPfABY31uBJ8sRwwfx5/NOYk/DQb542/Ps3t+U7JBERBISz+AuZnammV1uZv/V+ohjtTHAQjNbBbwAPO7uD/Uk2P6ivLSIW74wnc079vOV21+goSljLm8QkTQQTz3+3wGfJlKzx4BPAkd0tZ67r3L3ae4+xd3L3f1HPY62H5lx9Ahu+PQJLH1tF9/8+zIOtrvYS0Skv4rnAq4Z7j7FzFa5+9VmNgeIe2A3nZ05ZQxv7ZvElQ+s5dxbn2XLrnpqahtU10dE+rV4En/rCOZ+MxsL7ASODC+k1PKFd4/nmX+9yYIXtx9apro+ItKfxdPH/1AwSHs9sAzYDFR1ukaGWVOzp8Oy1ro+IiL9TTxlmX8cPL3XzB4C8jLtjlxdqaltiLFc0z1FpP+JmfhjXbgVvJfQBVzpbmxxPtVRknx+bja1+xspLshNQlQiItF11tUT7cKtbl3Ale6i1fUZkGXUNzZz6pynuGfpFsIsjSEikoiYv/jd/by+DCSVtQ7gXr9gAzW19Ydm9UwcPZgf3LeaS+9eyV1LXucnZ5dzbEnPyjyIiPRUPHfgGg5cBbyHSHXNZ4AfufvOkGNLKWdPK406g+ee82dw15LXuW7+ej504z/56vuO4sjhg7jxiX9RXVtP6bNPauqniPSpeKZzVhG5ocrHg9fnAv9DpASDdCEry/jMSW/jtONLuPbR9dy86GUMdEtHEUmaeKZzDnP3H7v7K8HjJ0Bx2IGlm+GFA/nFJ6cyojC3w00JNPVTRPpSPIl/oZl9xsyygsengIfDDixd7axrjLq8urae3z/1Mq/t3H/Y8vuXV3PydU9y5Pce5uTrnuT+5dV9EaaIpLF4unq+BlwM/DV4nQ3sM7OLidxoa0hYwaWjWFM/c7KNax9dz7WPruf4MUM4o3w0uQOMX/3jJeqDInDqFhKR3hDPBVyahtKLLjt9IlfMXX0omQPk52Rz7TmTmX7EUOaveYNH12xlzuMbo67f2i2kxC8i3RVPdc6vtHudbWZXhRdSejt7WinXnjOZ0uCm7aXF+Vx7zmTOnlbKuGEFfPV9RzH36yfz7BXvj7kNXREsIj0RT1fP+83s48BXgBHAbcBToUaV5lqnfnZ2O7jRRXmUxugWGjVkYMgRikg66/IXv7t/DrgdWE1kUPcid7807MAk+hXBALX7GnU1sIh0WzxdPccAFwL3EqnM+QUzKwg5LuHwbiEj0i105ZlvZ+q4oVx690q++pelbN8bvUCciEgs8XT1PAh8w92fMDMjMsPnBWBSZyuZ2TjgL8BooAW4xd1v7GG8GSfaFcHnnXwkt/3vK/x8wQZOv+FprvnYZD40eUySIhSRVBNP4j/J3fdAZO4mMMfM5sWx3kHgEndfZmaDgaVm9ri7v9iDeIXI1cD/771HMXPiSC6+ayVfv2MZH506lncdNYybFr58WL0gzf4RkfZidvWY2eUA7r7HzD7Z7u0uC7i5+1Z3XxY83wusA5SFetHRowYz94IZXHLasTy4sobv37eG6tp6nH/P+dcFXyLSnsUaIDSzZe5+Yvvn0V53uROz8UTq/ZS3nj20eW82MBugpKRkelXV4Tf3qquro7CwMN5dpZTebNuFC/ex+0DH5cPzjDkz+35IRt9bakrXtqVruwAqKyuXuntFIut01tVjMZ5Hex17I2aFRAaGL2qf9AHc/RbgFoCKigpvP72xsymPqa4327ZnfvQqGjsbHB99PO85ZgQ52fFU6Ogd+t5SU7q2LV3b1V2dJX6P8Tza66jMLIdI0r9Dd+wKV6xSEGZw3p9fYGhBDh+aPIazTiil4oihzFtZ0+H+ARoPEMkMnSX+qWa2h8iv+/zgOcHrvK42HMwA+iOwzt1/2eNIpVOxSkH8+KxJFBfk8sDKGuYuq+aO516jOH8AdQeaOdgSOX6rBpBIZunsDlwdrxxKzMnAF4DVZrYiWPZ9d3+kh9uVKGLdBax1+QeOL2HfgYP8Y902Lr9n1aGk30o1gEQyRzzTObvF3Z8hgbEA6blYdwFrNWjgAM46oZSLqlZEfV81gEQyQ9+N9km/MTYoENde7oAstu3RlcAi6U6JPwNFqwGUk200t7TwwRue5oEV1aoDJJLGlPgzULQaQNd/YiqPXzyTCSMHcWHVCi742zJ21EW5MEBEUl5offzSv8UaD7j7/Bn84Z+b+OVjG4M6QOU0NLVo6qdIGlHil8NkZxnnnzKBU48bxSV3reT8vy0j24xm19RPkXShrh6J6tiSwcz9+gwG5w04lPRbtU79FJHUpMQvMeVkZ1HXcDDqe5r6KZK6lPilU7Gmfg4ckMWGN/b2cTQi0huU+KVT0aZ+DsgyHGfWjU9z6d0ro9YIEpH+S4O70qlYpSBmThzJTQtf4vbFrzJvZQ3nzRjPBTMnsGjDm1y/YAPVtfWUPvukZgCJ9ENK/NKlWFM/f3Dm8XxxxnhuePxf3PLPTdy++BUOtqDibyL9nLp6pEfKhhYw51NTefTC9+JYzOJvItJ/KPFLrzhu9BAaD7ZEfU8zgET6FyV+6TWxZgBlZxkPrKimuUX1f0T6AyV+6TXRZgDlZhsjC3O5sGoFs371NA+v2kqLDgAiSaXBXek1bWcAVdfWUxrMAPro1LE8smYrNzy+kW/8fRnHjR7Md047lv0HDvKLxzaqBpBIHwst8ZvZbcCHge3uXh7WfqR/aZ0B1P7m1h+eMpYzyscwb2U1N/7jX3ztr0sxg9ZqEF3NALp/ebUKxYn0kjC7ev4MzApx+5JisrOMj00r4x8Xn0JxQQ7tS/7XNzVz5QNreGBFNau37KbuQKRcxP3Lq7li7mqqa+tx/n2QuH95dd83QiQNhHnrxafNbHxY25fUNSA7i937m6K+t7fhIBe2uTXkqMEDqd3fRGPz4TOGOrtHsM4ORDpnYd5pKUj8D3XW1WNms4HZACUlJdOrqqoOe7+uro7CwsLQYkymTG7bJYv2s7Oh4/97w/KMi6fnsXVfC9v2tfDGfueZ6uiF4gAmDc+ipCCLUQVZlAwyaupaeOClJhrbHCdys+BL5bnMGJvToza1yuTvLVWla7sAKisrl7p7RSLrJD3xt1VRUeFLliw5bFn7vuJ0kslta+2+qW9qPrQsPyeba8+Z3OHX+cnXPRm1HlB+TjbHjh7M5h372F0f/QyiVWlxHv/7vfcn1ogYMvl7S1Xp2i4AM0s48WtWjyRFrBpA0bpkLjt9YpcHidr9jbyyYx8f++3iqPurrm3gsrtXMuPo4cyYMIKSIXmAuoUkMynxS9LEqgEU7XPQ+UGiuCCXaW/LpbQ4P+rZQV5OFo+v28bdS7cAcPSoQkYPGcjzr7xFY3N8tYVaDxIqQCepLszpnHcCM4ERZrYFuMrd/xjW/iS9xXuQ6Ozs4KNTx/Li1j0sfnkHi1/eyVMb3qR9R2frzKKm5hbKhhZQNjSfMUV5PLRq62Hb1fRTSWVhzur5bFjbFomlq7OD8tIiykuLmP2+CRz5vYejbmNvw0Euu2fVodfZWQbQoeREfVMzP37oRY4pKWRE4UCGFuSSOyCrw/iFqpRKf6OuHkk78Z4djI3RLTS2KI87Z7+LLbvq2bJrP1t21fObJ1+Kuo2d+xo589fPHHo9JG8A+xubo1YpvfbRdZw5ZQw52YdfPqOzA+lrSvySsWJ1C10+6ziOGD6II4YPOrR87rLqqAeJEYW5/OTscnbUNfLWvkZ21h3g9v97Ner+tu05wHFXzqe0OJ8jhhdwxPAC6hoO8sjqrXGPM4j0BiV+yVi9MbPoP888nlnlYw777D/WbY96kCguyOHz7zyCzTv38dpb+5m3ooY9UW5mX9/UzNUPrmVKWRHjhw8iK+hqAp0dSO9Q4peM1p2ZRW0L0CVykPjhRyZ1+PyR33u4wwAzwK79TZw65ykG5w1galkxU8qKqG9q5s7nXqMhuO9Bbw4wa8ZSZlHiF4lTrAJ00T4H8Z1JxBpnGDV4IJd88FhWbtnNqi213PL0pg7jBhA5O/jhvLUUF+RQNjSfscX5FOQOSGiAWYPRmUeJXyQEPZ1++v0PvZ2zp5Xy6XdEljU0NfP2K+dHPTuorW/iS3964dDroQU51B04SFNzxwHmK+9fw6Y36zAzsswwg1v/uemw/bd+9ucL1vfamYS6pvoXJX6RJIr37CAvJzvm2UHJkIHc9LkTqa6tZ8uuempq67njudei7m/vgYP8ZuFLHSqjRlNT28C7r32CscX5lBZHziZ27G1g3sqth4rm6UwiNSnxiyRZT88Orjjj7VSMH0bbYi2LNrwZ9SBRWpzP/37vVNwdd2hx530/X0jN7oYOnx2cN4AZE0ZQU1vPyi21zF/zRocqqRA5O7jk7pX8afFmhhXkMHRQLkMLcrl7yetRzyRUVTX5lPhFUkRvzEK67PSJAFjQzZOFcfms46J+9sdnlR+27ZYWZ8L3H4na3dTc4hTl57CjrpGN2+rYtb+R/Y3NUT4Z+eX/3XtWMX7EIMYPL2D8iEGs3rKbq+at1dlBH1HiF0khvVnfKNpnO5uxlJVlMbubSovz+cuXTzps2Yxrn4h6JpGbncUT67exo66x0zb01jiDdKTEL5Km4j1ItP1sVzOWujqTaCvWmURrVdW9DU1s3rGfV3bu49t3Lo+6v5raBj5+82LKxw45VG7jxZrd/Of98Z0daJpqdEr8IhK37p5JRPvs4LwcJpcVMbmsiJ89uj7qmcSggdlkGdy9dEvMK6Ihcnbw00fWUTlxFEPyB2BmCQ8uZ9JZhBK/iCSkO2cSXYl1JnHN2ZGzg+YW55Ud+1hbs/uwW3O2tX3vAab+6DHycrIoGZLH1tqGqLfsvOaRdcyYMJyhg3IP1U3KtIOEEr+IJF1XZwfZWcbRowo5elQhP5+/IerZwdCCHL5ReTTb9jSwbc8BXt1ZE3Vfb+49wEk/fQKIlNEYUTiQ13buj3qQ+Okj6/jA8SUUDvx3qkyHg4QSv4j0Cz09O7iqXUmMpZ51/EUAAAliSURBVK/uinqAGDYoh4tPm8iOugPsrGtk574DvLS9Luq+tu89QPlVCxg8cACji/IYXZTH0ld3RZ2met2j6zlj8mgGDsg+tLy/HiSU+EUkpcQ7zhDrAPFfH+5YMynWfZ2HFuRw/ikT2Lq7gTd2N7B1T0PMaapv7Glg4n/OJy8ni6L8HIryc9i8I/qZxI8fepHjxgxmZHAfh6ysxMckekKJX0RSTjxnB71RWK/9WQTEPkgU5efw1fceye76pkOPjduin0ns3NfIrF/9E4ABWcbIwQPZUXcgapmNWBe89USoid/MZgE3AtnAre5+XZj7ExFpK4zCerEOEld/NP6DxIjCXK7+aDnb9zawfe8Btu85wL3LtkSNrSbK+j0V5j13s4GbgNOALcALZjbP3V8Ma58iIt0VxsVxnd3H4cwph9/H4dlNO6PfEa44P9GmdCnMX/wnAS+5+yYAM6sCzgKU+EUkpfXlQSLaxXE9ZR5Pmb7ubNjsE8Asd/9/wesvAO9092+2+9xsYDZASUnJ9KqqqsO2U1dXR2FhYSgxJpvalprUttSTKu1aXNPEvRub2NngDM8zPn5sDjPG5nS6TmVl5VJ3r+j0Q+2E+YvfoizrcJRx91uAWwAqKiq8fT9cV31zqUxtS01qW+pJlXbNBL7fB/vJCnHbW4BxbV6XAdGvqBARkT4TZuJ/ATjGzI40s1zgM8C8EPcnIiJxCK2rx90Pmtk3gQVEpnPe5u5rw9qfiIjEJ9R5/O7+CPBImPsQEZHEhNnVIyIi/ZASv4hIhlHiFxHJMEr8IiIZRolfRCTDKPGLiGQYJX4RkQwTWpG27jCzN4FX2y0eAexIQjh9QW1LTWpb6knXdgFMdPfBiazQr+7A5e4j2y8zsyWJVp5LFWpbalLbUk+6tgsibUt0HXX1iIhkGCV+EZEMkwqJ/5ZkBxAitS01qW2pJ13bBd1oW78a3BURkfClwi9+ERHpRUr8IiIZpl8nfjObZWYbzOwlM/tesuPpTWa22cxWm9mK7kzH6k/M7DYz225ma9osG2Zmj5vZv4K/Q5MZY3fEaNcPzaw6+N5WmNmHkhljd5nZODNbaGbrzGytmV0YLE+H7y1W21L+uzOzPDN73sxWBm27Olie0PfWb/v4zSwb2AicRuT+vS8An3X3F5MaWC8xs81Ahbun/EUlZvY+oA74i7uXB8t+Drzl7tcFB+2h7v7dZMaZqBjt+iFQ5+6/SGZsPWVmY4Ax7r7MzAYDS4GzgS+R+t9brLZ9ihT/7szMgEHuXmdmOcAzwIXAOSTwvfXnX/wnAS+5+yZ3bwSqgLOSHJNE4e5PA2+1W3wWcHvw/HYi//BSSox2pQV33+ruy4Lne4F1QCnp8b3FalvK84i64GVO8HAS/N76c+IvBV5v83oLafLlBRx4zMyWmtnsZAcTghJ33wqRf4jAqCTH05u+aWargq6glOsKac/MxgPTgOdIs++tXdsgDb47M8s2sxXAduBxd0/4e+vPid+iLOuf/VLdc7K7nwicAXwj6FaQ/u9mYAJwArAVmJPccHrGzAqBe4GL3H1PsuPpTVHalhbfnbs3u/sJQBlwkpmVJ7qN/pz4twDj2rwuA2qSFEuvc/ea4O924D4iXVvpZFvQ19ra57o9yfH0CnffFvzDawH+QAp/b0Ef8b3AHe4+N1icFt9btLal03cH4O61wCJgFgl+b/058b8AHGNmR5pZLvAZYF6SY+oVZjYoGHTCzAYBHwTWdL5WypkHfDF4/kXggSTG0mta/3EFPkaKfm/BIOEfgXXu/ss2b6X89xarbenw3ZnZSDMrDp7nAx8A1pPg99ZvZ/UABNOtfgVkA7e5+zVJDqlXmNlRRH7lQ6RC6t9TuW1mdicwk0jp223AVcD9wF3A24DXgE+6e0oNlMZo10wiXQUObAa+1tq3mkrM7D3AP4HVQEuw+PtE+sJT/XuL1bbPkuLfnZlNITJ4m03kh/td7v4jMxtOAt9bv078IiLS+/pzV4+IiIRAiV9EJMMo8YuIZBglfhGRDKPELyKSYZT4JSnMzM1sTpvXlwYF0MLY1xlmtiSo1rjezFK2SFcrM7vIzAqSHYekJiV+SZYDwDlmNiLMnQSXs/838Hl3fztQDmwKc5995CJAiV+6RYlfkuUgkXuFfqf9G2b2ZzP7RJvXdcHfmWb2lJndZWYbzew6Mzs3qE++2swmRNnP5cA17r4ewN0Puvtvg+0dYWZPBEW7njCzt7XZ/81BTfdNZnZKUNRrnZn9uW1cZjbHzJYF648Mlp9gZs8G272vtRiYmS0ys58F8W40s/cGy7PN7HozeyFY52tt2rvIzO4JzlTusIhvA2OBhUGM2UHMa4L/Dh3+m4q0pcQvyXQTcK6ZFSWwzlQi9ccnA18AjnX3k4BbgW9F+Xw5kXrs0fw3kVr7U4A7gF+3eW8ocCqRA9ODwA3AJGCymZ0QfGYQsCwotvcUkSt7Af4CfDfY7uo2ywEGBPFe1Gb5V4Dd7v4O4B3AV83syOC9acFnjweOIlLc79dE6lZVunslkatRS9293N0nA3+K0V4RQIlfkiiomPgX4NsJrPZCUG/9APAy8FiwfDUwPsEQ3g38PXj+V+A9bd570COXta8Gtrn76qC419o2+2kB/id4/jfgPcFBrNjdnwqW3w60rbzaWgxtaZvtfBD4j6DU7nPAcOCY4L3n3X1LsO8VMdq4CTjKzH5jZrOAtKqyKb1PiV+S7VdEfvEOarPsIMH/m0HBrdw27x1o87ylzesWInWP2lsLTI8zlrb1S9put/0+o+2n/fqxtG6ruc12DPiWu58QPI5098fafb79Ov/eqfsuImdCi4BvEDn7EYlJiV+SKigkdReR5N9qM/9O1mcRuctQd10PfN/MjgUwsywzuzh4bzGRqq8A5xK5jV0isoDWsYjPAc+4+25gV2v/PZHuqKeirdzGAuCCoJQwZnZsULW1M3uB1gqvI4Asd78XuBI4McF2SIaJ9ctFpC/NAb7Z5vUfgAfM7HngCWBfdzfs7qvM7CLgzmD6owMPB29/G7jNzC4D3gTOS3Dz+4BJZrYU2A18Olj+ReB3wf42xbHdW4l04SwLznDepOtbHt4CPGpmW4mMAfzJzFp/yF2RYDskw6g6p0g3mVmduxcmOw6RRKmrR0Qkw+gXv4hIhtEvfhGRDKPELyKSYZT4RUQyjBK/iEiGUeIXEckw/x/BL14ejRh5agAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 30\n",
    "\n",
    "pca = PCA(n_components=n_components, whiten=True)\n",
    "\n",
    "_ = pca.fit(train_features)\n",
    "\n",
    "pca_train_features = pca.transform(train_features)\n",
    "pca_test_features = pca.transform(test_features)\n",
    "\n",
    "plt.plot(pca.explained_variance_, \"o-\")\n",
    "plt.xlabel(\"Num Components\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.ylim(-0.5, 8)\n",
    "plt.xlim(-0.5,30)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-247dc0876b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_train_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred_labels_svc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_test_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconf_mat_svc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels_svc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclass_rep_svc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels_svc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit(pca_train_features, train_labels)\n",
    "pred_labels_svc = clf.predict(pca_test_features)\n",
    "\n",
    "conf_mat_svc = confusion_matrix(test_labels, pred_labels_svc)\n",
    "class_rep_svc = classification_report(test_labels, pred_labels_svc)\n",
    "\n",
    "print(f'Confusion Matrix: \\n {conf_mat_svc}')\n",
    "print(class_rep_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the total explained variance captured by this PCA? How accurate is this model? What evidence are you using to determine that? How many false positives and false negatives does it predict? How does it compare to the 4 component model? To the full model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> The total explained variance is 43.71. Based on the classification report, it is accurate and precision, recall, and f1 scores are all 0.99. It predicts only 4 false positives and only 4 false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. How well does a PCA work?\n",
    "\n",
    "Clearly, the number of components we use in our PCA matters. Let's investigate how they matter by systematically building a model for any number of selected components.\n",
    "\n",
    "### 6.1 Accuracy vs. Components\n",
    "\n",
    "We will do this by writing a function that creates the PCA, the SVC model, fits the training data, predict the labels using test data, and returns the accuracy scores and the explained variance. So your function will take as input:\n",
    "* the number of components\n",
    "* the training features\n",
    "* the test features\n",
    "* the training labels\n",
    "* the test labels\n",
    "\n",
    "and it will return:\n",
    "* the accuracy scores for an SVC model fit to pca transformed features \n",
    "* the total explained variance.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Create this function, which you will use in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_model(n_components, train_features, test_features, train_labels, test_labels):\n",
    "    \n",
    "    #Best estimators found by grid search in 4.1:\n",
    "    svc = SVC(kernel = 'rbf', C = 100, gamma = 0.01)\n",
    "\n",
    "    clf = svc.fit(train_features, train_labels)\n",
    "    \n",
    "    pca = PCA(n_components=n_components, whiten=True)\n",
    "    \n",
    "    _ = pca.fit(train_features)\n",
    "\n",
    "    pca_train_features = pca.transform(train_features)\n",
    "    pca_test_features = pca.transform(test_features)\n",
    "    \n",
    "    clf.fit(pca_train_features, train_labels) \n",
    "    \n",
    "    pred_labels = clf.predict(pca_test_features)\n",
    "\n",
    "    acc_score = accuracy_score(test_labels, pred_labels)\n",
    "    total_explained_variance = sum(pca.explained_variance_)\n",
    "    \n",
    "    return (acc_score, total_explained_variance)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Compute accuracies\n",
    "\n",
    "Now that you have created a function that returns the accuracy for a given number of components, we will use that to plot the how the accuracy of your SVC model changes when we increase the number of components used in the PCA.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - For 1 to 36 components, use your function above to compute and store (as a list) the accuracy of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores = []\n",
    "for i in range(1, 37):\n",
    "    acc_scores.append(svc_model(i, train_features, test_features, train_labels, test_labels)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Plot accuracy vs number of components\n",
    "\n",
    "Now that we have those numbers, it makes sense to look at the accuracy vs components.\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Plot the accuracy vs components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_components = [i for i in range(1, 37)]\n",
    "plt.plot(n_components, acc_scores, '.-')\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Where does it seem like we have diminishing returns, that is, no major increase in accuracy as we add additional components to the PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> At around 22 components, there is very little increase in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Plot total explained variance vs number of components\n",
    "\n",
    "<font size=8 color=\"#009600\">&#9998;</font> Do this - Plot the total explained variance vs components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_var = []\n",
    "for i in range(1, 37):\n",
    "    tot_var.append(svc_model(i, train_features, test_features, train_labels, test_labels)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_components, tot_var, '.-')\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Total Explained Variance (%)\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Where does it seem like we have diminishing returns, that is, no major increase in explained variance as we add additional components to the PCA? How does that number of components compare to the diminishing returns for accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=8 color=\"#009600\">&#9998;</font> Around 25 components is when there is no major increase in explained variance. It is similar to, but slightly higher than the number of components for accuracy's diminishing returns. This is relatively speaking however. Both appeat to approach an asymptote. It depends what constitutes a \"major increase\". To me, this is when the total variance is within 2.5 % of the asymptote at 45% and within 0.01 of accuracy score's asymptote at 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Assignment wrap-up¶\n",
    "Please fill out the form that appears when you run the code below. **You must completely fill this out in order to receive credit for the assignment!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<iframe \n",
       "\tsrc=\"https://docs.google.com/forms/d/e/1FAIpQLSc0IBD2mdn4TcRyi-KNXVtS3aEg6U4mOFq2MOciLQyEP4bg1w/viewform?usp=sf_link\" \n",
       "\twidth=\"800px\" \n",
       "\theight=\"600px\" \n",
       "\tframeborder=\"0\" \n",
       "\tmarginheight=\"0\" \n",
       "\tmarginwidth=\"0\">\n",
       "\tLoading...\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe \n",
    "\tsrc=\"https://docs.google.com/forms/d/e/1FAIpQLSc0IBD2mdn4TcRyi-KNXVtS3aEg6U4mOFq2MOciLQyEP4bg1w/viewform?usp=sf_link\" \n",
    "\twidth=\"800px\" \n",
    "\theight=\"600px\" \n",
    "\tframeborder=\"0\" \n",
    "\tmarginheight=\"0\" \n",
    "\tmarginwidth=\"0\">\n",
    "\tLoading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations, you're done!\n",
    "Submit this assignment by uploading it to the course Desire2Learn web page. Go to the \"Homework Assignments\" folder, find the dropbox link for Homework 4, and upload your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
